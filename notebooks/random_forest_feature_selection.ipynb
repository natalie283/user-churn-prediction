{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalie/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, accuracy_score,confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "   \n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet('/Users/natalie/Desktop/DS Thesis/Code/data/test.parquet')\n",
    "train = pd.read_parquet('/Users/natalie/Desktop/DS Thesis/Code/data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET ='churn_user'\n",
    "CATEGORICAL_FEATURES  = ['os_name', 'age_group','gender', 'country', 'region', 'province_type',\n",
    "                         'province']\n",
    "DATETIME_FEATURES  = ['first_date', 'lastest_active_day']\n",
    "SEARCH_CC_FEATURES = [ 'clicks', 'search_volume', 'dating_search', 'videoclip_search', 'technical_search', 'housekeeping_family_search', 'marketing_search', 'other_search']\n",
    "SEARCH_GG_FEATURES = [ 'serp_click', 'search_volume_gg', 'search_clicks_gg', 'other_search_gg','housekeeping_family_search_gg','videoclip_search_gg', 'dating_search_gg', 'marketing_search_gg', 'technical_search_gg']\n",
    "ACTIVE_FEATURES = ['active_day', 'life_time',  'not_active_day', 'total_active_time']\n",
    "ADS_FEATURES =  ['ads_impression', 'ads_click', 'ads_revenue']\n",
    "OTHERS_FEATURES =['newtab_count', 'download_count', 'pip_count', 'sidebar_count', 'incognito_count', 'signin_count', 'youtube_count',\n",
    "                    'work_count', 'social_count', 'news_count', 'entertainment_count', 'ecommerce_count']\n",
    "NUMERICAL_FEATURES = SEARCH_CC_FEATURES + SEARCH_GG_FEATURES + ACTIVE_FEATURES + ADS_FEATURES + OTHERS_FEATURES\n",
    "\n",
    "MODEL_NAMES = ['log_reg', 'randomforest','lightgbm', 'xgboost', 'mlp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_f1_score(train_labels, oofs, average='macro'):\n",
    "    scores = []\n",
    "    thresholds = []\n",
    "    best_score = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "        print(f'{threshold:.02f}, ', end='')\n",
    "        preds = (oofs > threshold).astype('int')\n",
    "        m = f1_score(train_labels, preds, average=average)\n",
    "        scores.append(m)\n",
    "        thresholds.append(threshold)\n",
    "        if m > best_score:\n",
    "            best_score = m\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df):\n",
    "    df['total_active_time'] = df['total_active_time'].fillna(0)\n",
    "    df['ads_impression'] = df['ads_impression'].fillna(0)\n",
    "    df['ads_click'] = df['ads_click'].fillna(0)\n",
    "    df['ads_revenue'] = df['ads_revenue'].fillna(0)\n",
    "    df['clicks'] = df['clicks'].fillna(0)\n",
    "    for c in OTHERS_FEATURES:\n",
    "        df[c] = df[c].fillna(0)\n",
    "    return df\n",
    "\n",
    "def process_data(df,oh_encoder=None, robust_scaler=None,agg_features=None):\n",
    "    if not oh_encoder:\n",
    "        print(\"fit train OneHotEncoder\")\n",
    "        oh_encoder = OneHotEncoder()\n",
    "        oh_encoder.fit(df[CATEGORICAL_FEATURES])\n",
    "    else:\n",
    "        print(\"loadd onehot encoder\")\n",
    "    if not robust_scaler:\n",
    "        print(\"fit train RobustScaler\")\n",
    "        robust_scaler = RobustScaler()\n",
    "        robust_scaler.fit(df[NUMERICAL_FEATURES])\n",
    "    else:\n",
    "        print(\"loadd robust scaler\")\n",
    "    df_cat = pd.DataFrame(oh_encoder.transform(df[CATEGORICAL_FEATURES]).toarray())\n",
    "    new_cat_cols = oh_encoder.get_feature_names_out(CATEGORICAL_FEATURES)\n",
    "    df_cat.columns = new_cat_cols\n",
    "    df_num = pd.DataFrame(robust_scaler.transform(df[NUMERICAL_FEATURES]))\n",
    "    df_num.columns = NUMERICAL_FEATURES\n",
    "    new_df = pd.concat([df_cat.reset_index(drop=True), df_num.reset_index(drop=True)], axis=1)\n",
    "    new_df = fillna(new_df)\n",
    "    return new_df, oh_encoder, robust_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESTIMATORS = 200\n",
    "SEED=42\n",
    "\n",
    "RF_Hyperparameters = {\n",
    "    'n_estimators': N_ESTIMATORS,\n",
    "    'max_depth':8,\n",
    "    'random_state':SEED,\n",
    "    'max_features': 'sqrt', \n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "models = []\n",
    "def cross_validate_get_feature_importance(train,FEATURES=None,USE_SMOTE=False, USE_CLASS_WEIGHT=False, USE_UNDER_SAMPLING=False):\n",
    "    oofs = np.zeros((train.shape[0], len(MODEL_NAMES)))\n",
    "    for i, (train_index, valid_index) in enumerate(kfold.split(train, train[TARGET])):\n",
    "        print(f\"===========fold {i}================\")\n",
    "        X_train, oh_encoder, robust_scaler = process_data(train.iloc[train_index])\n",
    "        X_valid, _, _  = process_data(train.iloc[valid_index], oh_encoder,robust_scaler)\n",
    "        if FEATURES is not None:\n",
    "            X_train = X_train[FEATURES]\n",
    "            X_valid = X_valid[FEATURES]\n",
    "        print(X_train.isnull().sum())\n",
    "        y_train = train.iloc[train_index][TARGET].values\n",
    "        y_valid = train.iloc[valid_index][TARGET].values\n",
    "        rf_hyperparameters = RF_Hyperparameters.copy()\n",
    "        if USE_SMOTE:\n",
    "            print(\"SMOTEEEE\")\n",
    "            sm = SMOTE(random_state=42)\n",
    "            X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        elif USE_CLASS_WEIGHT:\n",
    "            print(\"CLASS_WEIGHTTTT\")\n",
    "           \n",
    "            class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train)\n",
    "            class_weights =  {0: class_weights[0], 1: class_weights[1]}\n",
    "            rf_hyperparameters['class_weight'] = class_weights\n",
    "        elif USE_UNDER_SAMPLING:\n",
    "            print(\"UNDER SAMPLING\")\n",
    "            rus = RandomUnderSampler(random_state=42)\n",
    "            X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "        print(\"Random Forest--------------\")\n",
    "        rf_model = RandomForestClassifier(**rf_hyperparameters)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_y_pred_proba = rf_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, rf_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in rf_y_pred_proba]\n",
    "\n",
    "        print(roc_auc_score(y_valid, rf_y_pred_proba))\n",
    "\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index,1] = rf_y_pred_proba\n",
    "        models.append(rf_model)\n",
    "        \n",
    "    return oofs, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n"
     ]
    }
   ],
   "source": [
    "X_train,oh_encoder,robust_scaler = process_data(train)\n",
    "X_test, _,_ = process_data(test,oh_encoder,robust_scaler)\n",
    "y_train = train[TARGET].values\n",
    "y_test = test[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========fold 0================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "os_name_macos          0\n",
      "os_name_windows        0\n",
      "age_group_15-17        0\n",
      "age_group_18-24        0\n",
      "age_group_25-34        0\n",
      "                      ..\n",
      "work_count             0\n",
      "social_count           0\n",
      "news_count             0\n",
      "entertainment_count    0\n",
      "ecommerce_count        0\n",
      "Length: 123, dtype: int64\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.7659885653034679\n",
      "0.8881492939313849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9029    0.8489    0.8751    151135\n",
      "           1     0.6056    0.7177    0.6569     48865\n",
      "\n",
      "    accuracy                         0.8168    200000\n",
      "   macro avg     0.7543    0.7833    0.7660    200000\n",
      "weighted avg     0.8303    0.8168    0.8218    200000\n",
      "\n",
      "===========fold 1================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "os_name_macos          0\n",
      "os_name_windows        0\n",
      "age_group_15-17        0\n",
      "age_group_18-24        0\n",
      "age_group_25-34        0\n",
      "                      ..\n",
      "work_count             0\n",
      "social_count           0\n",
      "news_count             0\n",
      "entertainment_count    0\n",
      "ecommerce_count        0\n",
      "Length: 123, dtype: int64\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.7632543206946587\n",
      "0.8862878288280366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8964    0.8577    0.8766    151135\n",
      "           1     0.6116    0.6933    0.6499     48865\n",
      "\n",
      "    accuracy                         0.8175    200000\n",
      "   macro avg     0.7540    0.7755    0.7633    200000\n",
      "weighted avg     0.8268    0.8175    0.8212    200000\n",
      "\n",
      "===========fold 2================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "os_name_macos          0\n",
      "os_name_windows        0\n",
      "age_group_15-17        0\n",
      "age_group_18-24        0\n",
      "age_group_25-34        0\n",
      "                      ..\n",
      "work_count             0\n",
      "social_count           0\n",
      "news_count             0\n",
      "entertainment_count    0\n",
      "ecommerce_count        0\n",
      "Length: 123, dtype: int64\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.7624118750010482\n",
      "0.8866384214656152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9001    0.8488    0.8737    151134\n",
      "           1     0.6024    0.7085    0.6512     48866\n",
      "\n",
      "    accuracy                         0.8145    200000\n",
      "   macro avg     0.7512    0.7786    0.7624    200000\n",
      "weighted avg     0.8273    0.8145    0.8193    200000\n",
      "\n",
      "===========fold 3================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "os_name_macos          0\n",
      "os_name_windows        0\n",
      "age_group_15-17        0\n",
      "age_group_18-24        0\n",
      "age_group_25-34        0\n",
      "                      ..\n",
      "work_count             0\n",
      "social_count           0\n",
      "news_count             0\n",
      "entertainment_count    0\n",
      "ecommerce_count        0\n",
      "Length: 123, dtype: int64\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.7651268112550789\n",
      "0.8876101246941097\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8971    0.8591    0.8777    151134\n",
      "           1     0.6147    0.6953    0.6526     48866\n",
      "\n",
      "    accuracy                         0.8191    200000\n",
      "   macro avg     0.7559    0.7772    0.7651    200000\n",
      "weighted avg     0.8281    0.8191    0.8227    200000\n",
      "\n",
      "===========fold 4================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "os_name_macos          0\n",
      "os_name_windows        0\n",
      "age_group_15-17        0\n",
      "age_group_18-24        0\n",
      "age_group_25-34        0\n",
      "                      ..\n",
      "work_count             0\n",
      "social_count           0\n",
      "news_count             0\n",
      "entertainment_count    0\n",
      "ecommerce_count        0\n",
      "Length: 123, dtype: int64\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.764844199957932\n",
      "0.887387956619709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8974    0.8582    0.8773    151134\n",
      "           1     0.6135    0.6964    0.6524     48866\n",
      "\n",
      "    accuracy                         0.8186    200000\n",
      "   macro avg     0.7555    0.7773    0.7648    200000\n",
      "weighted avg     0.8280    0.8186    0.8224    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nothing_oofs, rf_models = cross_validate_get_feature_importance(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = []\n",
    "for i, model in enumerate(rf_models):\n",
    "    feat = pd.DataFrame({ 'features': model.feature_names_in_,f'score_{i}': rf_models[0].feature_importances_})\n",
    "    feats.append(feat)\n",
    "f = feats[0].merge(feats[1], on='features').merge(feats[2], on='features')\n",
    "f['score'] = (f['score_0'] + f['score_1'] + f['score_2'])/3\n",
    "f.sort_values('score',ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = []\n",
    "for i, model in enumerate(rf_models):\n",
    "    feat = pd.DataFrame({ 'features': model.feature_names_in_, f'score_{i}': model.feature_importances_})\n",
    "    feats.append(feat)\n",
    "\n",
    "# Assuming you want to merge all features, not just the first three\n",
    "f = feats[0]\n",
    "for i in range(1, len(feats)):\n",
    "    f = f.merge(feats[i], on='features')\n",
    "\n",
    "# Calculate the average feature importance\n",
    "score_columns = [f'score_{i}' for i in range(len(feats))]\n",
    "f['score'] = f[score_columns].mean(axis=1)\n",
    "\n",
    "# Sort by the average score\n",
    "f.sort_values('score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(30, 10))\n",
    "\n",
    "# Plotting the feature importances for each fold\n",
    "for i in range(5):\n",
    "    sns.barplot(y='features', x=f'score_{i}', data=f.sort_values(f'score_{i}', ascending=False).head(30), ax=axes[i])\n",
    "    axes[i].set_title(f'Fold {i+1} Feature Importances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAPdCAYAAACXzguGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVhV1fv38c8BZB4UBKdInFAEcSINJ3Ao55xHHFDTzMycssx5SjM1S9PKVMwcGjSzMs1UzFkc0FJMI0n7hjmkoJaosJ8/fNg/TyDicMLy/bqufclZe+217rUBL+6z1l7HYhiGIQAAAAAAcN/Z5XUAAAAAAAD8V5F0AwAAAABgIyTdAAAAAADYCEk3AAAAAAA2QtINAAAAAICNkHQDAAAAAGAjJN0AAAAAANgISTcAAAAAADZC0g0AAAAAgI2QdAMAHlpvvfWWLBaLQkJC8jqUB05kZKQsFku2xw8//GCTPpcuXaqZM2fapO17NXbsWFksFp09ezavQ7lrc+bMUUxMTF6HkSfOnj0rJycnWSwW7dmzJ6/DsYmYmJhb/s4OHTr0rtpKSkq6bd3IyEhFRkbeXdDAQ8IhrwMAACCvLFiwQJJ06NAh7dq1S9WrV8/jiB4sJUuW1JIlS7KUlypVyib9LV26VD/88IMGDhxok/YfdnPmzFHBggUVHR2d16H84xYvXqyrV69KkubPn6+wsLA8jsh2Fi5cqHLlylmVFS1aNI+iASCRdAMAHlJ79uzRgQMH1LRpU3311VeaP3/+P550G4ahK1euyMXF5R/tN7dcXFz0+OOP53UY9+zPP/+Uq6trXoeRZx728Us33mDz8/NT8eLFtWzZMs2YMeO+/d799ddfD9TvcEhIyH/6TQXg34jl5QCAh9L8+fMlSVOmTFGNGjW0fPly/fnnn5Kka9euyc/PT127ds1y3YULF+Ti4qLBgwebZampqRo6dKhKlCghR0dHFStWTAMHDtTly5etrrVYLOrfv7/eeecdBQUFycnJSYsWLZIkjRs3TtWrV5e3t7c8PT1VpUoVzZ8/X4ZhWLWRlpamIUOGqHDhwnJ1dVWdOnW0d+9eBQQEZJnBPHXqlJ555hk98sgjcnR0VIkSJTRu3Dhdv379nu/fnYz77bffVp06deTn5yc3NzdVqFBBU6dO1bVr18w6kZGR+uqrr/TLL79YLYuVpNjYWFksFsXGxlq1m5SUJIvFYrVkOjo6Wu7u7vr+++/15JNPysPDQ/Xr15ckXb16VRMnTlS5cuXk5OQkX19f9ejRQ2fOnLmr8UdGRiokJEQ7duxQjRo15OLiooCAAC1cuFCS9NVXX6lKlSpydXVVhQoVtHbtWqvrM5es79+/X61bt5anp6e8vLzUpUuXLDFlZGRo6tSpZux+fn7q1q2bfv3112xj+u6771SjRg25urqqZ8+eCggI0KFDh7R582bz3gYEBEiSrly5oiFDhqhSpUry8vKSt7e3wsPD9fnnn2cZc+bP8OLFixUUFCRXV1dVrFhRX375ZZa6R44cUadOnVSoUCE5OTnp0UcfVbdu3ZSWlmbWye3P6Ny5c1WxYkW5u7vLw8ND5cqV0yuvvJKr79OuXbv0ww8/qGvXrurdu7dSUlK0YsWKLPUyMjI0a9YsVapUSS4uLsqfP78ef/xxrV692qwTEBCgZs2aaeXKlapcubKcnZ01btw4SdIPP/ygFi1aqECBAnJ2dlalSpXM3++b+5g4caLKli1r9hEaGqo333zTrHPmzBn16dNH/v7+5s9pzZo19e233+ZqvLezevVqhYeHy9XVVR4eHnriiSe0Y8eO215nGIamTp2q4sWLy9nZWVWqVNHXX3+dpV5uxgg8bJjpBgA8dP766y8tW7ZMjz32mEJCQtSzZ089/fTT+uSTT9S9e3fly5dPXbp00TvvvKO3335bnp6e5rXLli3TlStX1KNHD0k3ZhEjIiL066+/6pVXXlFoaKgOHTqk0aNH6/vvv9e3335rJo+StGrVKm3ZskWjR49W4cKF5efnJ+lGAvnMM8/o0UcflSTt3LlTzz//vP73v/9p9OjR5vU9evTQRx99pGHDhqlevXo6fPiwWrVqpdTUVKsxnjp1StWqVZOdnZ1Gjx6tUqVKaceOHZo4caKSkpLMxPB2/p782NnZyc7O7o7GnZiYqM6dO5vJ+YEDBzRp0iQdOXLEXOI/Z84c9enTR4mJifrss89yFdutXL16VU899ZSeeeYZvfzyy7p+/boyMjLUokULbdmyRcOGDVONGjX0yy+/aMyYMYqMjNSePXvuarby1KlT6tGjh4YNG6ZHHnlEs2bNUs+ePXXy5El9+umneuWVV+Tl5aXx48erZcuW+vnnn7Ms9W3VqpXat2+vvn376tChQxo1apQOHz6sXbt2KV++fJKkZ599Vu+995769++vZs2aKSkpSaNGjVJsbKz27dunggULmu0lJyerS5cuGjZsmF599VXZ2dnppZdeUtu2beXl5aU5c+ZIkpycnCTdeCPnjz/+0NChQ1WsWDFdvXpV3377rVq3bq2FCxeqW7duVvF+9dVXiouL0/jx4+Xu7q6pU6eqVatW+vHHH1WyZElJ0oEDB1SrVi0VLFhQ48ePV5kyZZScnKzVq1fr6tWrcnJyyvXP6PLly9WvXz89//zzmjZtmuzs7PTTTz/p8OHDufoeZb7B1rNnT/n7+2vgwIGaP3++unTpYlUvOjpaH374oXr16qXx48fL0dFR+/bty/Jc8759+5SQkKCRI0eqRIkScnNz048//qgaNWrIz89Pb731lnx8fPThhx8qOjpav//+u4YNGyZJmjp1qsaOHauRI0eqTp06unbtmo4cOaILFy6Y7Xft2lX79u3TpEmTFBgYqAsXLmjfvn06d+5crsabnp6e5ffWweHGn/xLly5VVFSUnnzySS1btkxpaWmaOnWqIiMjtWHDBtWqVeuW7Y4bN07jxo1Tr1691LZtW508eVK9e/dWenq6ypYta9bLzRiBh44BAMBD5oMPPjAkGe+8845hGIZx8eJFw93d3ahdu7ZZ5+DBg4Yk47333rO6tlq1akbVqlXN15MnTzbs7OyMuLg4q3qffvqpIclYs2aNWSbJ8PLyMv74448c40tPTzeuXbtmjB8/3vDx8TEyMjIMwzCMQ4cOGZKMl156yar+smXLDElG9+7dzbJnnnnGcHd3N3755RerutOmTTMkGYcOHcoxhoiICENSliMqKuqOx53d2D744APD3t7e6l40bdrUKF68eJZrNm3aZEgyNm3aZFV+/PhxQ5KxcOFCs6x79+6GJGPBggVWdTPv0YoVK6zK4+LiDEnGnDlzcrwfY8aMMSQZZ86cMcsy79GePXvMsnPnzhn29vaGi4uL8b///c8sj4+PNyQZb731VpY2Bw0aZNXXkiVLDEnGhx9+aBiGYSQkJBiSjH79+lnV27VrlyHJeOWVV7LEtGHDhixjCA4ONiIiInIcp2EYxvXr141r164ZvXr1MipXrmx1TpJRqFAhIzU11Sw7deqUYWdnZ0yePNksq1evnpE/f37j9OnTt+wntz+j/fv3N/Lnz3/buLNz+fJlw9PT03j88cfNsu7duxsWi8X46aefzLLvvvvOkGSMGDEix/aKFy9u2NvbGz/++KNVeceOHQ0nJyfjxIkTVuWNGzc2XF1djQsXLhiGYRjNmjUzKlWqlGMf7u7uxsCBA3M1vpstXLgw299ZSca1a9eM9PR0o2jRokaFChWM9PR087qLFy8afn5+Ro0aNbK0dfz4ccMwDOP8+fOGs7Oz0apVK6s+t23bZkiy+rnKzRiBhw3LywEAD5358+fLxcVFHTt2lCS5u7urXbt22rJli44dOyZJqlChgqpWrWo1I5yQkKDdu3erZ8+eZtmXX36pkJAQVapUSdevXzePhg0bZrskul69eipQoECWmDZu3KgGDRrIy8tL9vb2ypcvn0aPHq1z587p9OnTkqTNmzdLktq3b291bdu2bc2ZrJvjqlu3rooWLWoVV+PGja3aykmpUqUUFxdndUyYMOGOx71//3499dRT8vHxMcfWrVs3paen6+jRo7eN4260adPG6vWXX36p/Pnzq3nz5lbxVqpUSYULF87yfcqtIkWKqGrVquZrb29v+fn5qVKlSlYz2kFBQZKkX375JUsbUVFRVq/bt28vBwcHbdq0SZLMf//++EC1atUUFBSkDRs2WJUXKFBA9erVu6NxfPLJJ6pZs6bc3d3l4OCgfPnyaf78+UpISMhSt27duvLw8DBfFypUSH5+fubY/vzzT23evFnt27eXr6/vLfvM7c9otWrVdOHCBXXq1Emff/75He0g//HHHys1NdXqd7Znz54yDMPqdztzmfRzzz132zZDQ0MVGBhoVbZx40bVr19f/v7+VuXR0dH6888/zeXb1apV04EDB9SvXz+tW7cuywqVzDoxMTGaOHGidu7cafUYRm588MEHWX5vHRwc9OOPP+q3335T165dZWf3fymAu7u72rRpo507d5qP2Pzdjh07dOXKlSw/qzVq1FDx4sWzxH+7MQIPG5JuAMBD5aefftJ3332npk2byjAMXbhwQRcuXFDbtm0l/d+O5tKNP8537NihI0eOSLqxK7CTk5M6depk1vn999918OBB5cuXz+rw8PCQYRhZEoQiRYpkiWn37t168sknJUnz5s3Ttm3bFBcXpxEjRki6sRxekrm8tFChQlbXOzg4yMfHx6rs999/1xdffJElruDgYEnKVeLi7OyssLAwq6NEiRJ3NO4TJ06odu3a+t///qc333xTW7ZsUVxcnN5++22rsd1Prq6uVo8EZMZ74cIFOTo6Zon51KlTd/1RYN7e3lnKHB0ds5Q7OjpKuvH89N8VLlzY6nXm9zPz+535b3Y/O0WLFs2y7Di7ejlZuXKl2rdvr2LFiunDDz/Ujh07FBcXp549e2Yb799/1qQbS9Uzv5fnz59Xenq6HnnkkRz7ze3PaNeuXbVgwQL98ssvatOmjfz8/FS9enWtX7/+tmObP3++nJ2d1ahRI/N3PTQ0VAEBAYqJiVF6erqkG89R29vbZ/leZCe7+3vu3Llbfn8yz0vS8OHDNW3aNO3cuVONGzeWj4+P6tevb/UxZh999JG6d++u999/X+Hh4fL29la3bt106tSp28Ym3XiD5++/tzfHcKs4MzIydP78+WzbzLw2u/vz97LcjBF42PBMNwDgobJgwQIZhqFPP/1Un376aZbzixYt0sSJE2Vvb69OnTpp8ODBiomJ0aRJk7R48WK1bNnSaqa6YMGCcnFxsUrWb3bzs7aSrJ7vzrR8+XLly5dPX375pZydnc3yVatWWdXLTHZ+//13FStWzCy/fv16lsSrYMGCCg0N1aRJk7KN614/Qii34161apUuX76slStXWs2IxcfH57qvzHty8wZc0q3fOMjuHhcsWFA+Pj5ZNjPLdPPM7T/t1KlT2X4/M7/fmf8mJydnSWR/++23XP2M5eTDDz9UiRIl9NFHH1ld+/f7nVve3t6yt7fPssnb393Jz2iPHj3Uo0cPXb58Wd99953GjBmjZs2a6ejRo1lmWjMdPXpUW7dulSRzr4S/W7dunZo0aSJfX1+lp6fr1KlTt33TIrv76+Pjo+Tk5Czlv/32mzlW6cYbKoMHD9bgwYN14cIFffvtt3rllVfUsGFDnTx5Uq6uripYsKBmzpypmTNn6sSJE1q9erVefvllnT59+pY/v7lx889RdnHa2dlluwrn5muzS/xPnTplbsqX2zECDxuSbgDAQyM9PV2LFi1SqVKl9P7772c5/+WXX2r69On6+uuv1axZMxUoUEAtW7bUBx98oPDwcJ06dcpqmaokNWvWTK+++qp8fHzMWeA7ZbFY5ODgIHt7e7Psr7/+0uLFi63q1alTR9KNmbAqVaqY5Z9++mmWjZOaNWumNWvWqFSpUrf8Q/pe5HbcmQlK5qZd0o1dkOfNm5el7s2zpTfL/IP+4MGDatiwoVl+867SuYl3+fLlSk9Pf+A+j33JkiVWS9Q//vhjXb9+XZGRkZJkLhX/8MMP9dhjj5n14uLilJCQYK6IuJ1b3V+LxSJHR0erZPLUqVPZ7l6eGy4uLoqIiNAnn3yiSZMmZXlTINPd/Iy6ubmpcePGunr1qlq2bKlDhw7dMunO3EBt3rx5Kl26tNW5v/76Sy1atNCCBQvUpEkTNW7cWJMnT9bcuXM1fvz4OxjtDfXr19dnn32m3377zerNgg8++ECurq7ZfvRe/vz51bZtW/3vf//TwIEDlZSUpPLly1vVefTRR9W/f39t2LBB27Ztu+O4bla2bFkVK1ZMS5cu1dChQ83v9+XLl7VixQpzR/PsPP7443J2dtaSJUusHt3Yvn27fvnlF6uk+07HCDwMSLoBAA+Nr7/+Wr/99ptee+01M6G5WUhIiGbPnq358+erWbNmkm4sMf/oo4/Uv39/PfLII2rQoIHVNQMHDtSKFStUp04dDRo0SKGhocrIyNCJEyf0zTffaMiQIbdN8po2baoZM2aoc+fO6tOnj86dO6dp06ZZJaqSFBwcrE6dOmn69Omyt7dXvXr1dOjQIU2fPl1eXl5Wz2mOHz9e69evV40aNTRgwACVLVtWV65cUVJSktasWaN33nnntst/c5LbcT/xxBNydHRUp06dNGzYMF25ckVz587NdhlrhQoVtHLlSs2dO1dVq1aVnZ2dwsLCVLhwYTVo0ECTJ09WgQIFVLx4cW3YsEErV67MdbwdO3bUkiVL1KRJE73wwguqVq2a8uXLp19//VWbNm1SixYt1KpVq7u+H/di5cqVcnBw0BNPPGHuXl6xYkXz2f2yZcuqT58+mjVrluzs7NS4cWNz93J/f38NGjQoV/1UqFBBy5cv10cffaSSJUvK2dlZFSpUMD8Cq1+/fuau1BMmTFCRIkXMPQ7u1IwZM1SrVi1Vr15dL7/8skqXLq3ff/9dq1ev1rvvvisPD49c/4z27t1bLi4uqlmzpooUKaJTp05p8uTJ8vLysnoT4mbXr1/XBx98oKCgID399NPZ1mnevLlWr16tM2fOqHbt2uratasmTpyo33//Xc2aNZOTk5P2798vV1dXPf/88zmOd8yYMeYz6qNHj5a3t7eWLFmir776SlOnTpWXl5fZZ+bnaPv6+uqXX37RzJkzVbx4cZUpU0YpKSmqW7euOnfurHLlysnDw0NxcXFau3atWrdufVffi0x2dnaaOnWqoqKi1KxZMz3zzDNKS0vT66+/rgsXLmjKlCm3vLZAgQIaOnSoJk6cqKefflrt2rXTyZMnNXbs2CzLy283RuChlJe7uAEA8E9q2bKl4ejomOOOyh07djQcHByMU6dOGYZxY7dtf3//HHc2vnTpkjFy5EijbNmyhqOjo+Hl5WVUqFDBGDRokNmOYdzY+fm5557Lto0FCxYYZcuWNZycnIySJUsakydPNubPn2+1g7BhGMaVK1eMwYMHG35+foazs7Px+OOPGzt27DC8vLyy7IJ95swZY8CAAUaJEiWMfPnyGd7e3kbVqlWNESNGGJcuXcrxXkVERBjBwcE51sntuL/44gujYsWKhrOzs1GsWDHjxRdfNL7++ussO5L/8ccfRtu2bY38+fMbFovFuPnPlOTkZKNt27aGt7e34eXlZXTp0sXYs2dPtruXu7m5ZRvvtWvXjGnTppmxuLu7G+XKlTOeeeYZ49ixYzmO9Va7l2d3j4oXL240bdo0S/nfv/+Zbe7du9do3ry54e7ubnh4eBidOnUyfv/9d6tr09PTjddee80IDAw08uXLZxQsWNDo0qWLcfLkSat6OX3fkpKSjCeffNLw8PAwJFntFD9lyhQjICDAcHJyMoKCgox58+aZ8eU0hpvHfPPu+YZhGIcPHzbatWtn+Pj4GI6Ojsajjz5qREdHG1euXDHr5OZndNGiRUbdunWNQoUKGY6OjkbRokWN9u3bGwcPHsx2nIZhGKtWrTIkGTNnzrxlnbVr1xqSjOnTpxuGceMev/HGG0ZISIj58xweHm588cUXVuPM7ntrGIbx/fffG82bNze8vLwMR0dHo2LFilY/m4ZhGNOnTzdq1KhhFCxY0LwnvXr1MpKSkgzDuPH73bdvXyM0NNTw9PQ0XFxcjLJlyxpjxowxLl++fMuxGMb/7Tj+908UyO7eVK9e3XB2djbc3NyM+vXrG9u2bcu2rZv/78nIyDAmT55s+Pv7G46OjkZoaKjxxRdfGBEREVa7l99ujMDDyGIYhvHPp/oAAOB+2b59u2rWrKklS5aoc+fOeR0Ocmns2LEaN26czpw5c8sl2ACAfz+WlwMA8C+yfv167dixQ1WrVpWLi4sOHDigKVOmqEyZMve8/BQAANx/JN0AAPyLeHp66ptvvtHMmTN18eJFFSxY0NwE6uadzwEAwIOB5eUAAAAAANiI3e2rAAAAAACAu0HSDQAAAACAjfBMN4BsZWRk6LfffpOHh4csFktehwMAAAA8UAzD0MWLF1W0aFHZ2d16PpukG0C2fvvtN/n7++d1GAAAAMAD7eTJk3rkkUdueZ6kG0C2PDw8JN34T8TT0zOPowEAAAAeLKmpqfL39zf/br4Vkm4A2cpcUu7p6UnSDQAAANzC7R7FJOkGkKOz73+kNBeXvA4DAAAAMPk+2yWvQ8g1di8HAAAAAMBGSLoBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QYAAAAAwEZIugEAAAAAsBGSbgAAAAAAbISkG8gFi8WiVatW5Vn/MTExyp8/f571DwAAAODukHQDNxk7dqwqVaqUpTw5OVmNGzf+5wMCAAAA8K/mkNcBAP8GhQsXzusQAAAAAPwLMdON/5y1a9eqVq1ayp8/v3x8fNSsWTMlJiaa53/99Vd17NhR3t7ecnNzU1hYmHbt2qWYmBiNGzdOBw4ckMVikcViUUxMjCTr5eXh4eF6+eWXrfo8c+aM8uXLp02bNkmSrl69qmHDhqlYsWJyc3NT9erVFRsbm+sxxMTE6NFHH5Wrq6tatWqlc+fOWZ1PTExUixYtVKhQIbm7u+uxxx7Tt99+a54fP368KlSokKXdqlWravTo0dn2mZaWptTUVKsDAAAAwL0h6cZ/zuXLlzV48GDFxcVpw4YNsrOzU6tWrZSRkaFLly4pIiJCv/32m1avXq0DBw5o2LBhysjIUIcOHTRkyBAFBwcrOTlZycnJ6tChQ5b2o6KitGzZMhmGYZZ99NFHKlSokCIiIiRJPXr00LZt27R8+XIdPHhQ7dq1U6NGjXTs2LHbxr9r1y717NlT/fr1U3x8vOrWrauJEyda1bl06ZKaNGmib7/9Vvv371fDhg3VvHlznThxQpLUs2dPHT58WHFxceY1Bw8e1P79+xUdHZ1tv5MnT5aXl5d5+Pv73zZWAAAAADmzGDdnDsB/0JkzZ+Tn56fvv/9e27dv19ChQ5WUlCRvb+8sdceOHatVq1YpPj7eqtxiseizzz5Ty5YtdebMGRUtWlQbN25U7dq1JUk1atRQrVq1NHXqVCUmJqpMmTL69ddfVbRoUbONBg0aqFq1anr11VdzjLdz5846f/68vv76a7OsY8eOWrt2rS5cuHDL64KDg/Xss8+qf//+kqQmTZooICBAc+bMkSQNGjRI8fHx5mz836WlpSktLc18nZqaKn9/fyVOf08eLi45xgwAAAD8k3yf7ZLXISg1NVVeXl5KSUmRp6fnLesx043/nMTERHXu3FklS5aUp6enSpQoIUk6ceKE4uPjVbly5WwT7tzy9fXVE088oSVLlkiSjh8/rh07digqKkqStG/fPhmGocDAQLm7u5vH5s2brZa530pCQoLCw8Otyv7++vLlyxo2bJjKly+v/Pnzy93dXUeOHDFnuiWpd+/eWrZsma5cuaJr165pyZIl6tmz5y37dXJykqenp9UBAAAA4N6wkRr+c5o3by5/f3/NmzdPRYsWVUZGhkJCQnT16lW53KcZ26ioKL3wwguaNWuWli5dquDgYFWsWFGSlJGRIXt7e+3du1f29vZW17m7u9+27dwsPnnxxRe1bt06TZs2TaVLl5aLi4vatm2rq1evmnWaN28uJycnffbZZ3JyclJaWpratGlzhyMFAAAAcC9IuvGfcu7cOSUkJOjdd981l35v3brVPB8aGqr3339ff/zxR7az3Y6OjkpPT79tPy1bttQzzzyjtWvXaunSperatat5rnLlykpPT9fp06fNGO5E+fLltXPnTquyv7/esmWLoqOj1apVK0k3nvFOSkqyquPg4KDu3btr4cKFcnJyUseOHeXq6nrH8QAAAAC4eywvx39KgQIF5OPjo/fee08//fSTNm7cqMGDB5vnO3XqpMKFC6tly5batm2bfv75Z61YsUI7duyQJAUEBOj48eOKj4/X2bNnrZ5xvpmbm5tatGihUaNGKSEhQZ07dzbPBQYGKioqSt26ddPKlSt1/PhxxcXF6bXXXtOaNWtuO4YBAwZo7dq1mjp1qo4eParZs2dr7dq1VnVKly6tlStXKj4+XgcOHFDnzp2VkZGRpa2nn35aGzdu1Ndff53j0nIAAAAAtkHSjf8UOzs7LV++XHv37lVISIgGDRqk119/3Tzv6Oiob775Rn5+fmrSpIkqVKigKVOmmMvA27Rpo0aNGqlu3bry9fXVsmXLbtlXVFSUDhw4oNq1a+vRRx+1Ordw4UJ169ZNQ4YMUdmyZfXUU09p165dudoR/PHHH9f777+vWbNmqVKlSvrmm280cuRIqzpvvPGGChQooBo1aqh58+Zq2LChqlSpkqWtMmXKqEaNGipbtqyqV69+274BAAAA3F/sXg78hxmGoXLlyumZZ56xmvHPjczdGNm9HAAAAA+af9Pu5TzTDfxHnT59WosXL9b//vc/9ejRI6/DAQAAAB5KLC8H/mGNGze2+iixm4/bfYb3nShUqJCmTJmi9957TwUKFLhv7QIAAADIPWa6gX/Y+++/r7/++ivbc/fy+eF/x5MjAAAAQN4j6Qb+YcWKFcvrEAAAAAD8Q1heDgAAAACAjTDTDSBHBZ/ukONujAAAAABujZluAAAAAABshKQbAAAAAAAbIekGAAAAAMBGSLoBAAAAALARkm4AAAAAAGyE3csB5OjM/Hd0xcU5r8MAAAD4V/HrOyCvQ8ADgpluAAAAAABshKQbAAAAAAAbIekGAAAAAMBGSLoBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QZuIzY2VhaLRRcuXMizGKKjo9WyZcs86x8AAADA3SHpxgNr7NixqlSp0j/aZ2RkpAYOHGhVVqNGDSUnJ8vLy+sfjQUAAADAv59DXgcAPOgcHR1VuHDhvA4DAAAAwL8QM92wmcjISA0YMEDDhg2Tt7e3ChcurLFjx5rnT5w4oRYtWsjd3V2enp5q3769fv/9d0lSTEyMxo0bpwMHDshischisSgmJua2fc6YMUMVKlSQm5ub/P391a9fP126dMmqzrZt2xQRESFXV1cVKFBADRs21Pnz5xUdHa3NmzfrzTffNPtMSkqyWl6ekpIiFxcXrV271qrNlStXys3Nzezrf//7nzp06KACBQrIx8dHLVq0UFJSUq7uW3p6ugYPHqz8+fPLx8dHw4YNk2EYVnXWrl2rWrVqmXWaNWumxMRE83y9evXUv39/q2vOnTsnJycnbdy4MVdxAAAAALh3JN2wqUWLFsnNzU27du3S1KlTNX78eK1fv16GYahly5b6448/tHnzZq1fv16JiYnq0KGDJKlDhw4aMmSIgoODlZycrOTkZPNcTuzs7PTWW2/phx9+0KJFi7Rx40YNGzbMPB8fH6/69esrODhYO3bs0NatW9W8eXOlp6frzTffVHh4uHr37m326e/vb9W+l5eXmjZtqiVLlliVL1261HwD4c8//1TdunXl7u6u7777Tlu3bpW7u7saNWqkq1ev3nYM06dP14IFCzR//nxt3bpVf/zxhz777DOrOpcvX9bgwYMVFxenDRs2yM7OTq1atVJGRoYk6emnn9bSpUuVlpZmXrNkyRIVLVpUdevWzbbftLQ0paamWh0AAAAA7g3Ly2FToaGhGjNmjCSpTJkymj17tjZs2CBJOnjwoI4fP24mtosXL1ZwcLDi4uL02GOPyd3dXQ4ODne0tPvm57FLlCihCRMm6Nlnn9WcOXMkSVOnTlVYWJj5WpKCg4PNrx0dHeXq6ppjn1FRUerWrZv+/PNPubq6KjU1VV999ZVWrFghSVq+fLns7Oz0/vvvy2KxSJIWLlyo/PnzKzY2Vk8++WSOY5g5c6aGDx+uNm3aSJLeeecdrVu3zqpO5rlM8+fPl5+fnw4fPqyQkBC1adNGzz//vD7//HO1b9/ejCE6OtqM6e8mT56scePG5RgbAAAAgDvDTDdsKjQ01Op1kSJFdPr0aSUkJMjf399qJrl8+fLKnz+/EhIS7rq/TZs26YknnlCxYsXk4eGhbt266dy5c7p8+bKk/5vpvhdNmzaVg4ODVq9eLUlasWKFPDw8zGR67969+umnn+Th4SF3d3e5u7vL29tbV65csVoCnp2UlBQlJycrPDzcLHNwcFBYWJhVvcTERHXu3FklS5aUp6enSpQoIenGkn1JcnJyUpcuXbRgwQJz3AcOHFB0dPQt+x4+fLhSUlLM4+TJk3d2YwAAAABkwUw3bCpfvnxWry0WizIyMmQYRrYzrrcqz41ffvlFTZo0Ud++fTVhwgR5e3tr69at6tWrl65duyZJcnFxuau2b+bo6Ki2bdtq6dKl6tixo5YuXaoOHTrIweHGr1NGRoaqVq2aZQm6JPn6+t5z/5LUvHlz+fv7a968eSpatKgyMjIUEhJitXz96aefVqVKlfTrr79qwYIFql+/vooXL37LNp2cnOTk5HRf4gMAAABwAzPdyBPly5fXiRMnrGZTDx8+rJSUFAUFBUm6kdymp6fnus09e/bo+vXrmj59uh5//HEFBgbqt99+s6oTGhpqLm/PTm77jIqK0tq1a3Xo0CFt2rRJUVFR5rkqVaro2LFj8vPzU+nSpa2O233smJeXl4oUKaKdO3eaZdevX9fevXvN1+fOnVNCQoJGjhyp+vXrKygoSOfPn8/SVoUKFRQWFqZ58+Zp6dKl6tmz523HBQAAAOD+IulGnmjQoIFCQ0MVFRWlffv2affu3erWrZsiIiLMpdQBAQE6fvy44uPjdfbsWatNwbJTqlQpXb9+XbNmzdLPP/+sxYsX65133rGqM3z4cMXFxalfv346ePCgjhw5orlz5+rs2bNmn7t27VJSUpLOnj1rbkz2dxERESpUqJCioqIUEBCgxx9/3DwXFRWlggULqkWLFtqyZYuOHz+uzZs364UXXtCvv/5623vzwgsvaMqUKfrss8905MgR9evXTxcuXDDPZ+6I/t577+mnn37Sxo0bNXjw4GzbevrppzVlyhSlp6erVatWt+0bAAAAwP1F0o08YbFYtGrVKhUoUEB16tRRgwYNVLJkSX300UdmnTZt2qhRo0aqW7eufH19tWzZshzbrFSpkmbMmKHXXntNISEhWrJkiSZPnmxVJzAwUN98840OHDigatWqKTw8XJ9//rm5NHzo0KGyt7dX+fLl5evraz4jnV38nTp10oEDB6xmuSXJ1dVV3333nR599FG1bt1aQUFB6tmzp/766y95enre9t4MGTJE3bp1U3R0tMLDw+Xh4WGVMNvZ2Wn58uXau3evQkJCNGjQIL3++uvZttWpUyc5ODioc+fOcnZ2vm3fAAAAAO4vi/H3DwAG8J9x8uRJBQQEKC4uTlWqVLmja1NTU+Xl5aWfZrwmDxcSdgAAgDvh13dAXocAG8v8ezklJSXHyTU2UgP+g65du6bk5GS9/PLLevzxx+844QYAAABwf7C8HP8aS5YsMT+C6+/HzZ+1/aC71Rjc3d21ZcuW+9LHtm3bVLx4ce3duzfLc+0AAAAA/jnMdONf46mnnlL16tWzPff3jyZ7kMXHx9/yXLFixe5LH5GRkeLJEQAAACDvkXTjX8PDw0MeHh55HcY9K126dF6HAAAAAOAfwvJyAAAAAABshJluADny7dU3Vx91BgAAACArZroBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QYAAAAAwEZIugEAAAAAsBF2LweQo+T3huuSi1NehwEA+A8q+tyMvA4BAGyOmW4AAAAAAGyEpBsAAAAAABsh6QYAAAAAwEZIugEAAAAAsBGSbgAAAAAAbISkGwAAAAAAGyHpBgAAAADARki6gfsgMjJSAwcOzOswAAAAADxgSLoBAAAAALARkm7kiatXr+Z1CAAAAABgcyTd/wFr165VrVq1lD9/fvn4+KhZs2ZKTEw0z2/fvl2VKlWSs7OzwsLCtGrVKlksFsXHx5t1Dh8+rCZNmsjd3V2FChVS165ddfbs2Vz1f/HiRUVFRcnNzU1FihTRG2+8kWW5dUBAgCZOnKjo6Gh5eXmpd+/ekqQVK1YoODhYTk5OCggI0PTp063atlgsWrVqlVVZ/vz5FRMTI0lKSkqSxWLR8uXLVaNGDTk7Oys4OFixsbG5ij0mJkb58+e3Ksu8P5nGjh2rSpUqafHixQoICJCXl5c6duyoixcv3rLdtWvXysvLSx988IEkKTo6Wi1bttS0adNUpEgR+fj46LnnntO1a9fMa86fP69u3bqpQIECcnV1VePGjXXs2DFJkmEY8vX11YoVK8z6lSpVkp+fn/l6x44dypcvny5dumTeu/fff1+tWrWSq6urypQpo9WrV98y5rS0NKWmplodAAAAAO4NSfd/wOXLlzV48GDFxcVpw4YNsrOzU6tWrZSRkaGLFy+qefPmqlChgvbt26cJEybopZdesro+OTlZERERqlSpkvbs2aO1a9fq999/V/v27XPV/+DBg7Vt2zatXr1a69ev15YtW7Rv374s9V5//XWFhIRo7969GjVqlPbu3av27durY8eO+v777zV27FiNGjXKTKjvxIsvvqghQ4Zo//79qlGjhp566imdO3fujtu5lcTERK1atUpffvmlvvzyS23evFlTpkzJtu7y5cvVvn17ffDBB+rWrZtZvmnTJiUmJmrTpk1atGiRYmJirMYaHR2tPXv2aPXq1dqxY4cMw1CTJk107do1WSwW1alTx3wz4fz58zp8+LCuXbumw4cPS5JiY2NVtWpVubu7m22OGzdO7du318GDB9WkSRNFRUXpjz/+yDbuyZMny8vLyzz8/f3v8a4BAAAAcMjrAHDv2rRpY/V6/vz58vPz0+HDh7V161ZZLBbNmzdPzs7OKl++vP73v/+ZM82SNHfuXFWpUkWvvvqqWbZgwQL5+/vr6NGjCgwMvGXfFy9e1KJFi7R06VLVr19fkrRw4UIVLVo0S9169epp6NCh5uuoqCjVr19fo0aNkiQFBgbq8OHDev311xUdHX1H96B///7mfZg7d67Wrl2r+fPna9iwYXfUzq1kZGQoJiZGHh4ekqSuXbtqw4YNmjRpklW9OXPm6JVXXtHnn3+uunXrWp0rUKCAZs+eLXt7e5UrV05NmzbVhg0b1Lt3bx07dkyrV6/Wtm3bVKNGDUnSkiVL5O/vr1WrVqldu3aKjIzUe++9J0n67rvvVLFiRT366KOKjY1V+fLlFRsbq8jISKs+o6Oj1alTJ0nSq6++qlmzZmn37t1q1KhRljEOHz5cgwcPNl+npqaSeAMAAAD3iJnu/4DExER17txZJUuWlKenp0qUKCFJOnHihH788UeFhobK2dnZrF+tWjWr6/fu3atNmzbJ3d3dPMqVK2e2nZOff/5Z165ds2rTy8tLZcuWzVI3LCzM6nVCQoJq1qxpVVazZk0dO3ZM6enpuRj5/wkPDze/dnBwUFhYmBISEu6ojZwEBASYCbckFSlSRKdPn7aqs2LFCg0cOFDffPNNloRbkoKDg2Vvb59tGwkJCXJwcFD16tXN8z4+Pipbtqw5jsjISB06dEhnz57V5s2bFRkZqcjISG3evFnXr1/X9u3bFRERYdVnaGio+bWbm5s8PDyyxJ3JyclJnp6eVgcAAACAe8NM939A8+bN5e/vr3nz5qlo0aLKyMhQSEiIrl69KsMwrJ5Plm48H3yzjIwMNW/eXK+99lqWtosUKZJj35lt3a4P6UbS9/c6t7vOYrFkKbv5Oeic/L3t7NjZ2eWq/Xz58mVpOyMjw6qsUqVK2rdvnxYuXKjHHnssS/85tZHd/cosz2wnJCREPj4+2rx5szZv3qzx48fL399fkyZNUlxcnP766y/VqlXrjuMGAAAAYDvMdP/LnTt3TgkJCRo5cqTq16+voKAgnT9/3jxfrlw5HTx4UGlpaWbZnj17rNqoUqWKDh06pICAAJUuXdrq+Hui/HelSpVSvnz5tHv3brMsNTXV3AAsJ+XLl9fWrVutyrZv367AwEBzRtjX11fJycnm+WPHjunPP//M0tbOnTvNr69fv669e/eas/U58fX11cWLF3X58mWz7OYN5u5EqVKltGnTJn3++ed6/vnn7+ja8uXL6/r169q1a5dZdu7cOR09elRBQUGSZD7X/fnnn+uHH35Q7dq1VaFCBV27dk3vvPOOqlSpYjUbDwAAACDvkXT/yxUoUEA+Pj5677339NNPP2njxo1Wz+V27txZGRkZ6tOnjxISErRu3TpNmzZN0v/NBD/33HP6448/1KlTJ+3evVs///yzvvnmG/Xs2fO2y7w9PDzUvXt3vfjii9q0aZMOHTqknj17ys7O7rYzzUOGDNGGDRs0YcIEHT16VIsWLdLs2bOtnvuuV6+eZs+erX379mnPnj3q27dvltlbSXr77bf12Wef6ciRI3ruued0/vx59ezZ87b3r3r16nJ1ddUrr7yin376SUuXLr2rjdwyBQYGatOmTeZS89wqU6aMWrRood69e2vr1q06cOCAunTpomLFiqlFixZmvcjISC1dulShoaHy9PQ0E/ElS5ZkeZ4bAAAAQN4j6f6Xs7Oz0/Lly7V3716FhIRo0KBBev31183znp6e+uKLLxQfH69KlSppxIgRGj16tCSZz3kXLVpU27ZtU3p6uho2bKiQkBC98MIL8vLykp3d7X9EZsyYofDwcDVr1kwNGjRQzZo1FRQUZPUceXaqVKmijz/+WMuXL1dISIhGjx6t8ePHW22iNn36dPn7+6tOnTrq3Lmzhg4dKldX1yxtTZkyRa+99poqVqyoLVu26PPPP1fBggVvG7u3t7c+/PBDrVmzRhUqVNCyZcs0duzY216Xk7Jly2rjxo1atmyZhgwZkuvrFi5cqKpVq6pZs2YKDw+XYRhas2aN1ZsMdevWVXp6ulWCHRERofT09CzPcwMAAADIexbjVg+T4j9ryZIl6tGjh1JSUuTi4nLf2798+bKKFSum6dOnq1evXve9/ZslJSWpRIkS2r9/vypVqmTTvh42qamp8vLy0pHX+8nDxSmvwwEA/AcVfW5GXocAAHct8+/llJSUHDchZiO1h8AHH3ygkiVLqlixYjpw4IBeeukltW/f/r4l3Pv379eRI0dUrVo1paSkaPz48ZJktSwaAAAAAB5GLC9/CJw6dUpdunRRUFCQBg0apHbt2pmf93w7J06csPoosb8fJ06ckCRNmzZNFStWVIMGDXT58mVt2bIlV8u7ba1v3763jL1v3755HR4AAACA/ziWlyNH169fV1JS0i3PBwQEyMHhwV0wcfr0aaWmpmZ7ztPTU35+fv9wRP8eLC8HANgay8sB/JuxvBz3hYODg0qXLp3XYdw1Pz8/EmsAAAAAeYakG0COivSZnOM7dwAAAABujWe6AQAAAACwEZJuAAAAAABshKQbAAAAAAAbIekGAAAAAMBGSLoBAAAAALARdi8HkKOj73WUu0u+vA4DAHAb5Z77PK9DAABkg5luAAAAAABshKQbAAAAAAAbIekGAAAAAMBGSLoBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QYAAAAAwEZIuvHAio6OVsuWLfM6jFyxWCxatWpVXocBAAAA4AFD0g0AAAAAgI2QdOM/yzAMXb9+Pa/DAAAAAPAQI+nGbV28eFFRUVFyc3NTkSJF9MYbbygyMlIDBw6UJF29elXDhg1TsWLF5ObmpurVqys2Nta8PiYmRvnz59e6desUFBQkd3d3NWrUSMnJyWad9PR0DR48WPnz55ePj4+GDRsmwzCs4jAMQ1OnTlXJkiXl4uKiihUr6tNPPzXPx8bGymKxaN26dQoLC5OTk5O2bNmS49iyW8I+cOBARUZGmq8jIyM1YMAADRs2TN7e3ipcuLDGjh2bY7vjx49XoUKFFB8fL0kKCAjQq6++qp49e8rDw0OPPvqo3nvvPatrvv/+e9WrV08uLi7y8fFRnz59dOnSJfOcnZ2dzp49K0k6f/687Ozs1K5dO/P6yZMnKzw83OpebNiwQWFhYXJ1dVWNGjX0448/3jLmtLQ0paamWh0AAAAA7g1JN25r8ODB2rZtm1avXq3169dry5Yt2rdvn3m+R48e2rZtm5YvX66DBw+qXbt2atSokY4dO2bW+fPPPzVt2jQtXrxY3333nU6cOKGhQ4ea56dPn64FCxZo/vz52rp1q/744w999tlnVnGMHDlSCxcu1Ny5c3Xo0CENGjRIXbp00ebNm63qDRs2TJMnT1ZCQoJCQ0Pvyz1YtGiR3NzctGvXLk2dOlXjx4/X+vXrs9QzDEMvvPCCOY5KlSpZjTEsLEz79+9Xv3799Oyzz+rIkSPm/WnUqJEKFCiguLg4ffLJJ/r222/Vv39/SVJISIh8fHzMsX733Xfy8fHRd999Z7YfGxuriIgIq3hGjBih6dOna8+ePXJwcFDPnj1vOcbJkyfLy8vLPPz9/e/6fgEAAAC4gaQbObp48aIWLVqkadOmqX79+goJCdHChQuVnp4uSUpMTNSyZcv0ySefqHbt2ipVqpSGDh2qWrVqaeHChWY7165d0zvvvKOwsDBVqVJF/fv314YNG8zzM2fO1PDhw9WmTRsFBQXpnXfekZeXl3n+8uXLmjFjhhYsWKCGDRuqZMmSio6OVpcuXfTuu+9axTx+/Hg98cQTKlWqlHx8fO7LfQgNDdWYMWNUpkwZdevWTWFhYVbxS9L169fVrVs3ffPNN9q2bZvKlCljdb5Jkybq16+fSpcurZdeekkFCxY0VwQsWbJEf/31lz744AOFhISoXr16mj17thYvXqzff/9dFotFderUMevHxsaqe/fuysjI0OHDh3X9+nVt377daoZekiZNmqSIiAiVL19eL7/8srZv364rV65kO8bhw4crJSXFPE6ePHlf7h0AAADwMHPI6wDwYPv555917do1VatWzSzz8vJS2bJlJUn79u2TYRgKDAy0ui4tLc0q4XV1dVWpUqXM10WKFNHp06clSSkpKUpOTjaXRkuSg4ODwsLCzCXmhw8f1pUrV/TEE09Y9XP16lVVrlzZqiwsLOxehpytv8+Y3xx/pkGDBsnJyUk7d+5UwYIFc2zDYrGocOHCZhsJCQmqWLGi3NzczDo1a9ZURkaGfvzxRxUqVEiRkZHmkvTNmzdrwoQJOn78uDZv3qyUlBT99ddfqlmz5i37LFKkiCTp9OnTevTRR7PE5+TkJCcnp1zdDwAAAAC5Q9KNHGUmvRaLJdvyjIwM2dvba+/evbK3t7eq4+7ubn6dL18+q3MWiyXLM9s5ycjIkCR99dVXKlasmNW5vyeKNyeut2NnZ5cljmvXrmWpl138mTFleuKJJ7Rs2TKtW7dOUVFRd9SGYRhZ7vHN9aQbz5a/8MIL+umnn/TDDz+odu3aSkxM1ObNm3XhwgVVrVpVHh4et+wzs52/xw0AAADAdlhejhyVKlVK+fLl0+7du82y1NRU83ntypUrKz09XadPn1bp0qWtjsKFC+eqDy8vLxUpUkQ7d+40y65fv669e/ear8uXLy8nJyedOHEiSz/38uyxr6+v1YZukszNz+7UU089paVLl+rpp5/W8uXL7+ja8uXLKz4+XpcvXzbLtm3bJjs7O3MVQeZz3RMnTlTFihXl6empiIgIbd68OdvnuQEAAADkPZJu5MjDw0Pdu3fXiy++qE2bNunQoUPq2bOn7OzsZLFYFBgYqKioKHXr1k0rV67U8ePHFRcXp9dee01r1qzJdT8vvPCCpkyZos8++0xHjhxRv379dOHCBas4hg4dqkGDBmnRokVKTEzU/v379fbbb2vRokV3Pb569eppz549+uCDD3Ts2DGNGTNGP/zww12316pVKy1evFg9evSw2ln9dqKiouTs7Kzu3bvrhx9+0KZNm/T888+ra9euKlSokCSZz3V/+OGH5rPboaGhunr1qjZs2JDleW4AAAAAeY+kG7c1Y8YMhYeHq1mzZmrQoIFq1qypoKAgOTs7S5IWLlyobt26aciQISpbtqyeeuop7dq1645moIcMGaJu3bopOjpa4eHh8vDwUKtWrazqTJgwQaNHj9bkyZMVFBSkhg0b6osvvlCJEiXuemwNGzbUqFGjNGzYMD322GO6ePGiunXrdtftSVLbtm21aNEide3aVStXrszVNa6urlq3bp3++OMPPfbYY2rbtq3q16+v2bNnW9WrW7eu0tPTzQTbYrGodu3akqRatWrdU9wAAAAA7j+LcScP1gK6sZN4sWLFNH36dPXq1Suvw4GNpKamysvLS3GvN5a7S77bXwAAyFPlnvs8r0MAgIdK5t/LKSkp8vT0vGU9NlLDbe3fv19HjhxRtWrVlJKSovHjx0uSWrRokceRAQAAAMCDjeXlyJVp06apYsWKatCggS5fvqwtW7Zk+7FYD5rg4GC5u7tneyxZsiSvwwMAAADwH8dMN26rcuXKVjuJ/5usWbMm248Ak2RuUAYAAAAAtkLSjf+04sWL53UIAAAAAB5iJN0AchTYZ3mOG0MAAAAAuDWe6QYAAAAAwEZIugEAAAAAsBGSbgAAAAAAbISkGwAAAAAAGyHpBgAAAADARti9HECOdi9sJzeXfHkdBoB/WHifL/M6BAAA/hOY6QYAAAAAwEZIugEAAAAAsBGSbgAAAAAAbISkGwAAAAAAGyHpBgAAAADARki6AQAAAACwEZJuAAAAAABshKQb/1rR0dFq2bLlfW0zKSlJFotF8fHx97VdAAAAAA8nh7wOALhbb775pgzDuK9t+vv7Kzk5WQULFryv7ea1gIAADRw4UAMHDszrUAAAAICHCkk3/rW8vLzue5v29vYqXLjwfW8XAAAAwMOJ5eV44H366aeqUKGCXFxc5OPjowYNGujy5ctZlpdfvHhRUVFRcnNzU5EiRfTGG28oMjLSanY3ICBAr776qnr27CkPDw89+uijeu+998zzf19eHhsbK4vFog0bNigsLEyurq6qUaOGfvzxx1zHv3r1aoWFhcnZ2VkFCxZU69atzXPnz59Xt27dVKBAAbm6uqpx48Y6duyYeX7s2LGqVKmSVXszZ85UQECA+TrzPkybNk1FihSRj4+PnnvuOV27dk2SFBkZqV9++UWDBg2SxWKRxWLJNs60tDSlpqZaHQAAAADuDUk3HmjJycnq1KmTevbsqYSEBMXGxqp169bZLisfPHiwtm3bptWrV2v9+vXasmWL9u3bl6Xe9OnTFRYWpv3796tfv3569tlndeTIkRzjGDFihKZPn649e/bIwcFBPXv2zFX8X331lVq3bq2mTZtq//79ZvKeKTo6Wnv27NHq1au1Y8cOGYahJk2amAlzbm3atEmJiYnatGmTFi1apJiYGMXExEiSVq5cqUceeUTjx49XcnKykpOTs21j8uTJ8vLyMg9/f/87igEAAABAViwvxwMtOTlZ169fV+vWrVW8eHFJUoUKFbLUu3jxohYtWqSlS5eqfv36kqSFCxeqaNGiWeo2adJE/fr1kyS99NJLeuONNxQbG6ty5crdMo5JkyYpIiJCkvTyyy+radOmunLlipydnXOMf9KkSerYsaPGjRtnllWsWFGSdOzYMa1evVrbtm1TjRo1JElLliyRv7+/Vq1apXbt2uXY9s0KFCig2bNny97eXuXKlVPTpk21YcMG9e7dW97e3rK3t5eHh0eOS+eHDx+uwYMHm69TU1NJvAEAAIB7xEw3HmgVK1ZU/fr1VaFCBbVr107z5s3T+fPns9T7+eefde3aNVWrVs0s8/LyUtmyZbPUDQ0NNb+2WCwqXLiwTp8+nWMcN19TpEgRSbrtNZIUHx9vvgnwdwkJCXJwcFD16tXNMh8fH5UtW1YJCQm3bftmwcHBsre3t4oxN/HdzMnJSZ6enlYHAAAAgHtD0o0Hmr29vdavX6+vv/5a5cuX16xZs1S2bFkdP37cql7mcvO/P6+c3TL0fPnyWb22WCzKyMjIMY6br8ns43bXSJKLi8stz91q53XDMMw+7OzsstTLbun53YwJAAAAgO2RdOOBZ7FYVLNmTY0bN0779++Xo6OjPvvsM6s6pUqVUr58+bR7926zLDU11WpTsrwQGhqqDRs2ZHuufPnyun79unbt2mWWnTt3TkePHlVQUJAkydfXV6dOnbJKvO/mM8QdHR2Vnp5+x9cBAAAAuDck3Xig7dq1S6+++qr27NmjEydOaOXKlTpz5oyZlGby8PBQ9+7d9eKLL2rTpk06dOiQevbsKTs7u1vu1v1PGDNmjJYtW6YxY8YoISFB33//vaZOnSpJKlOmjFq0aKHevXtr69atOnDggLp06aJixYqpRYsWkm7sPH7mzBlNnTpViYmJevvtt/X111/fcRwBAQH67rvv9L///U9nz569r2MEAAAAcGsk3XigeXp66rvvvlOTJk0UGBiokSNHavr06WrcuHGWujNmzFB4eLiaNWumBg0aqGbNmgoKCrrtZme2FBkZqU8++USrV69WpUqVVK9ePauZ7YULF6pq1apq1qyZwsPDZRiG1qxZYy4XDwoK0pw5c/T222+rYsWK2r17t4YOHXrHcYwfP15JSUkqVaqUfH1979v4AAAAAOTMYtzqwVLgX+7y5csqVqyYpk+frl69euV1OP86qamp8vLy0vqZT8rNJd/tLwDwnxLe58u8DgEAgAda5t/LKSkpOW5CzEeG4T9j//79OnLkiKpVq6aUlBSNHz9eksyl2gAAAADwT2N5Of5Tpk2bpooVK6pBgwa6fPmytmzZooIFC9qsv+DgYLm7u2d7LFmyxGb9AgAAAPh3YKYb/xmVK1fW3r17/9E+16xZk+1HeElSoUKF/tFYAAAAADx4SLqBe1C8ePG8DgEAAADAA4ykG0COqvX4JMeNIQAAAADcGs90AwAAAABgIyTdAAAAAADYCEk3AAAAAAA2QtINAAAAAICNkHQDAAAAAGAj7F4OIEffftBGbi758joMAPeoYa81eR0CAAAPJWa6AQAAAACwEZJuAAAAAABshKQbAAAAAAAbIekGAAAAAMBGSLoBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QZyYLFYtGrVqrwOAwAAAMC/FEk3/vOSkpJksVgUHx+f16HkibFjx6pSpUp5HQYAAADwUCLpBgAAAADARki6kSciIyM1YMAADRs2TN7e3ipcuLDGjh1rnk9JSVGfPn3k5+cnT09P1atXTwcOHDDP2dvba+/evZIkwzDk7e2txx57zLx+2bJlKlKkiCSpRIkSkqTKlSvLYrEoMjJSkhQXF6cnnnhCBQsWlJeXlyIiIrRv374ssSYnJ6tx48ZycXFRiRIl9Mknn+R6nL/++qs6duwob29vubm5KSwsTLt27TLPz507V6VKlZKjo6PKli2rxYsXm+eym6G/cOGCLBaLYmNjJUmxsbGyWCzasGGDwsLC5Orqqho1aujHH3+UJMXExGjcuHE6cOCALBaLLBaLYmJich0/AAAAgHtD0o08s2jRIrm5uWnXrl2aOnWqxo8fr/Xr18swDDVt2lSnTp3SmjVrtHfvXlWpUkX169fXH3/8IS8vL1WqVMlMPA8ePGj+m5qaKulGMhoRESFJ2r17tyTp22+/VXJyslauXClJunjxorp3764tW7Zo586dKlOmjJo0aaKLFy9axTlq1Ci1adNGBw4cUJcuXdSpUyclJCTcdnyXLl1SRESEfvvtN61evVoHDhzQsGHDlJGRIUn67LPP9MILL2jIkCH64Ycf9Mwzz6hHjx7atGnTHd/LESNGaPr06dqzZ48cHBzUs2dPSVKHDh00ZMgQBQcHKzk5WcnJyerQoUO2baSlpSk1NdXqAAAAAHBvHPI6ADy8QkNDNWbMGElSmTJlNHv2bG3YsEH29vb6/vvvdfr0aTk5OUmSpk2bplWrVunTTz9Vnz59FBkZqdjYWA0ZMkSxsbGqX7++fv75Z23dulVNmjRRbGysBg0aJEny9fWVJPn4+Khw4cJm//Xq1bOK591331WBAgW0efNmNWvWzCxv166dnn76aUnShAkTtH79es2aNUtz5szJcXxLly7VmTNnFBcXJ29vb0lS6dKlzfPTpk1TdHS0+vXrJ0kaPHiwdu7cqWnTpqlu3bp3dC8nTZpkvsnw8ssvq2nTprpy5YpcXFzk7u4uBwcHq7FnZ/LkyRo3btwd9QsAAAAgZ8x0I8+EhoZavS5SpIhOnz6tvXv36tKlS/Lx8ZG7u7t5HD9+XImJiZJuLE/fsmWLMjIytHnzZkVGRioyMlKbN2/WqVOndPToUTMJvZXTp0+rb9++CgwMlJeXl7y8vHTp0iWdOHHCql54eHiW17mZ6Y6Pj1flypXNhPvvEhISVLNmTauymjVr5qrtv7v5XmYuqz99+vQdtTF8+HClpKSYx8mTJ+84DgAAAADWmOlGnsmXL5/Va4vFooyMDGVkZKhIkSLm8vGb5c+fX5JUp04dXbx4Ufv27dOWLVs0YcIE+fv769VXX1WlSpXk5+enoKCgHPuPjo7WmTNnNHPmTBUvXlxOTk4KDw/X1atXbxu7xWK5bR0XF5c7bscwDLPMzs7OLMt07dq1bNu5+V5mXp+5jD23nJyczJUFAAAAAO4PZrrxwKlSpYpOnTolBwcHlS5d2uooWLCgJJnPdc+ePVsWi0Xly5dX7dq1tX//fn355ZdWs9yOjo6SpPT0dKt+tmzZogEDBqhJkyYKDg6Wk5OTzp49myWenTt3Znldrly5244jNDRU8fHx+uOPP7I9HxQUpK1bt1qVbd++3XyzIHNZfHJysnn+bj72zNHRMcvYAQAAAPwzSLrxwGnQoIHCw8PVsmVLrVu3TklJSdq+fbtGjhypPXv2mPUiIyP14YcfKiIiQhaLRQUKFFD58uX10UcfmTuUS5Kfn59cXFy0du1a/f7770pJSZF04/nqxYsXKyEhQbt27VJUVFS2s9OffPKJFixYoKNHj2rMmDHavXu3+vfvf9txdOrUSYULF1bLli21bds2/fzzz1qxYoV27NghSXrxxRcVExOjd955R8eOHdOMGTO0cuVKDR06VNKNmfLHH39cU6ZM0eHDh/Xdd99p5MiRd3w/AwICdPz4ccXHx+vs2bNKS0u74zYAAAAA3B2SbjxwLBaL1qxZozp16qhnz54KDAxUx44dlZSUpEKFCpn16tatq/T0dKsEOyIiQunp6VYz3Q4ODnrrrbf07rvvqmjRomrRooUkacGCBTp//rwqV66srl27asCAAfLz88sSz7hx47R8+XKFhoZq0aJFWrJkicqXL3/bcTg6Ouqbb76Rn5+fmjRpogoVKmjKlCmyt7eXJLVs2VJvvvmmXn/9dQUHB+vdd9/VwoULrcazYMECXbt2TWFhYXrhhRc0ceLEO72datOmjRo1aqS6devK19dXy5Ytu+M2AAAAANwdi3HzA6MA8P+lpqbKy8tLK2Y1kJtLvttfAOCB1rDXmrwOAQCA/5TMv5dTUlLk6el5y3rMdAMAAAAAYCMk3cBdevXVV60+0uzmo3HjxnkdHgAAAIAHAB8ZBtylvn37qn379tmey83HhQEAAAD47yPpBu6St7e3vL298zoMAAAAAA8wlpcDAAAAAGAjzHQDyFGDbity3I0RAAAAwK0x0w0AAAAAgI2QdAMAAAAAYCMk3QAAAAAA2AhJNwAAAAAANkLSDQAAAACAjbB7OYAcrfqwtVxd+K8C+Ldq22NtXocAAMBDjZluAAAAAABshKQbAAAAAAAbIekGAAAAAMBGSLoBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6UaeS0pKksViUXx8/APRzoMoOjpaLVu2zOswAAAAANwhPnwX/xn+/v5KTk5WwYIF8zqU++7NN9+UYRh5HQYAAACAO0TSjf8Me3t7FS5cOE/6vnr1qhwdHW3WvpeXl83aBgAAAGA7LC/Hfbd27VrVqlVL+fPnl4+Pj5o1a6bExETz/O7du1W5cmU5OzsrLCxM+/fvt7r+/PnzioqKkq+vr1xcXFSmTBktXLjwtv3+fXl5bGysLBaL1q1bp8qVK8vFxUX16tXT6dOn9fXXXysoKEienp7q1KmT/vzzT7OdyMhI9e/fX/379zfHMHLkSKuZ5oCAAE2cOFHR0dHy8vJS7969JUnbt29XnTp15OLiIn9/fw0YMECXL182r5szZ47KlCkjZ2dnFSpUSG3btjXPffrpp6pQoYJcXFzk4+OjBg0amNf+fXl5WlqaBgwYID8/Pzk7O6tWrVqKi4szz2eOfcOGDQoLC5Orq6tq1KihH3/88bb3EQAAAMD9Q9KN++7y5csaPHiw4uLitGHDBtnZ2alVq1bKyMjQ5cuX1axZM5UtW1Z79+7V2LFjNXToUKvrR40apcOHD+vrr79WQkKC5s6de09LxseOHavZs2dr+/btOnnypNq3b6+ZM2dq6dKl+uqrr7R+/XrNmjXL6ppFixbJwcFBu3bt0ltvvaU33nhD77//vlWd119/XSEhIdq7d69GjRql77//Xg0bNlTr1q118OBBffTRR9q6dav69+8vSdqzZ48GDBig8ePH68cff9TatWtVp04dSVJycrI6deqknj17KiEhQbGxsWrduvUtl5QPGzZMK1as0KJFi7Rv3z6VLl1aDRs21B9//GFVb8SIEZo+fbr27NkjBwcH9ezZ85b3KS0tTampqVYHAAAAgHvD8nLcd23atLF6PX/+fPn5+enw4cPavn270tPTtWDBArm6uio4OFi//vqrnn32WbP+iRMnVLlyZYWFhUm6Mat8LyZOnKiaNWtKknr16qXhw4crMTFRJUuWlCS1bdtWmzZt0ksvvWRe4+/vrzfeeEMWi0Vly5bV999/rzfeeMOc0ZakevXqWb1h0K1bN3Xu3FkDBw6UJJUpU0ZvvfWWIiIiNHfuXJ04cUJubm5q1qyZPDw8VLx4cVWuXFnSjaT7+vXrat26tYoXLy5JqlChQrbjuXz5subOnauYmBg1btxYkjRv3jytX79e8+fP14svvmjWnTRpkiIiIiRJL7/8spo2baorV67I2dk5S7uTJ0/WuHHj7uzmAgAAAMgRM9247xITE9W5c2eVLFlSnp6eKlGihKQbyXRCQoIqVqwoV1dXs354eLjV9c8++6yWL1+uSpUqadiwYdq+ffs9xRMaGmp+XahQIbm6upoJd2bZ6dOnra55/PHHZbFYrGI8duyY0tPTzbLMNwUy7d27VzExMXJ3dzePhg0bKiMjQ8ePH9cTTzyh4sWLq2TJkuratauWLFliLmuvWLGi6tevrwoVKqhdu3aaN2+ezp8/n+14EhMTde3aNfONBEnKly+fqlWrpoSEhFuOvUiRIpKUZayZhg8frpSUFPM4efJktvUAAAAA5B5JN+675s2b69y5c5o3b5527dqlXbt2Sbqx2VhuduBu3LixfvnlFw0cOFC//fab6tevn2UJ+p3Ily+f+bXFYrF6nVmWkZFxx+26ublZvc7IyNAzzzyj+Ph48zhw4ICOHTumUqVKycPDQ/v27dOyZctUpEgRjR49WhUrVtSFCxdkb2+v9evX6+uvv1b58uU1a9YslS1bVsePH8/Sb+Y9vPlNgczyv5f9feyZcWbHyclJnp6eVgcAAACAe0PSjfvq3LlzSkhI0MiRI1W/fn0FBQVZzdiWL19eBw4c0F9//WWW7dy5M0s7vr6+io6O1ocffqiZM2fqvffe+0fiv1VMO3fuVJkyZWRvb3/La6pUqaJDhw6pdOnSWY7Mnc0dHBzUoEEDTZ06VQcPHlRSUpI2btwo6UZSXLNmTY0bN0779++Xo6OjPvvssyz9ZLa3detWs+zatWvas2ePgoKC7sfwAQAAANwnPNON+6pAgQLy8fHRe++9pyJFiujEiRN6+eWXzfOdO3fWiBEj1KtXL40cOVJJSUmaNm2aVRujR49W1apVFRwcrLS0NH355Zf/eDJ58uRJDR48WM8884z27dunWbNmafr06Tle89JLL+nxxx/Xc889p969e8vNzU0JCQnmRm1ffvmlfv75Z9WpU0cFChTQmjVrlJGRobJly2rXrl3asGGDnnzySfn5+WnXrl06c+ZMtuN2c3PTs88+qxdffFHe3t569NFHNXXqVP3555/q1auXrW4JAAAAgLtA0o37ys7OTsuXL9eAAQMUEhKismXL6q233lJkZKQkyd3dXV988YX69u2rypUrq3z58nrttdesNl9zdHTU8OHDlZSUJBcXF9WuXVvLly//R8fRrVs3/fXXX6pWrZrs7e31/PPPq0+fPjleExoaqs2bN2vEiBGqXbu2DMNQqVKl1KFDB0lS/vz5tXLlSo0dO1ZXrlxRmTJltGzZMgUHByshIUHfffedZs6cqdTUVBUvXlzTp083N0r7uylTpigjI0Ndu3bVxYsXFRYWpnXr1qlAgQL3/V4AAAAAuHsWIzcP2QIPkcjISFWqVEkzZ87M61DyVGpqqry8vLTo7fpydeH9OeDfqm2PtXkdAgAA/0mZfy+npKTkuB8Sz3QDAAAAAGAjJN3413j11VetPo7r5uNWy7ABAAAAIC+xZhT/Gn379lX79u2zPefi4nLf+omNjb1vbQEAAAB4uJF041/D29tb3t7eeR0GAAAAAOQay8sBAAAAALARZroB5Khll5U57sYIAAAA4NaY6QYAAAAAwEZIugEAAAAAsBGSbgAAAAAAbISkGwAAAAAAGyHpBgAAAADARti9HECOPlzaUi4u/FcB5KRH92/yOgQAAPCAYqYbAAAAAAAbIekGAAAAAMBGSLoBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QYAAAAAwEZIuoE8lJSUJIvFovj4eElSbGysLBaLLly4kKvrIyMjNXDgQJvFBwAAAODekHQDD5AaNWooOTlZXl5eeR0KAAAAgPvAIa8DAPB/HB0dVbhw4bwOAwAAAMB9wkw38A/IyMjQa6+9ptKlS8vJyUmPPvqoJk2alKVedsvLt23bpoiICLm6uqpAgQJq2LChzp8/n20/a9eulZeXlz744AOzvWrVqsnNzU358+dXzZo19csvv9hkjAAAAACyYqYb+AcMHz5c8+bN0xtvvKFatWopOTlZR44cue118fHxql+/vnr27Km33npLDg4O2rRpk9LT07PUXb58ufr06aPFixerRYsWun79ulq2bKnevXtr2bJlunr1qnbv3i2LxZJtX2lpaUpLSzNfp6am3v2AAQAAAEgi6QZs7uLFi3rzzTc1e/Zsde/eXZJUqlQp1apVS0lJSTleO3XqVIWFhWnOnDlmWXBwcJZ6c+bM0SuvvKLPP/9cdevWlXQjaU5JSVGzZs1UqlQpSVJQUNAt+5o8ebLGjRt3p8MDAAAAkAOWlwM2lpCQoLS0NNWvX/+Or82c6c7JihUrNHDgQH3zzTdmwi1J3t7eio6OVsOGDdW8eXO9+eabSk5OvmU7w4cPV0pKinmcPHnyjuMFAAAAYI2kG7AxFxcXm15bqVIl+fr6auHChTIMw+rcwoULtWPHDtWoUUMfffSRAgMDtXPnzmzbcXJykqenp9UBAAAA4N6QdAM2VqZMGbm4uGjDhg13fG1oaOhtrytVqpQ2bdqkzz//XM8//3yW85UrV9bw4cO1fft2hYSEaOnSpXccBwAAAIC7wzPdgI05OzvrpZde0rBhw+To6KiaNWvqzJkzOnTo0G2Xjg8fPlwVKlRQv3791LdvXzk6OmrTpk1q166dChYsaNYLDAzUpk2bFBkZKQcHB82cOVPHjx/Xe++9p6eeekpFixbVjz/+qKNHj6pbt262HjIAAACA/4+kG/gHjBo1Sg4ODho9erR+++03FSlSRH379r3tdYGBgfrmm2/0yiuvqFq1anJxcVH16tXVqVOnLHXLli2rjRs3KjIyUvb29ho2bJiOHDmiRYsW6dy5cypSpIj69++vZ555xhZDBAAAAJANi/H3h0ABQDd2P/fy8tLbc+vKxYX354Cc9Oj+TV6HAAAA/mGZfy+npKTkuB8Sz3QDAAAAAGAjJN0AAAAAANgISTcAAAAAADZC0g0AAAAAgI2QdAMAAAAAYCNsSQwgR106r8pxN0YAAAAAt8ZMNwAAAAAANkLSDQAAAACAjZB0AwAAAABgIyTdAAAAAADYCEk3AAAAAAA2wu7lAHL0zket5OzKfxX47xkQtS6vQwAAAA8BZroBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QYAAAAAwEZIugEAAAAAsBGSbgAAAAAAbISkGwAAAAAAGyHpBm4SGRmpgQMHSpICAgI0c+ZM89ypU6f0xBNPyM3NTfnz57dZDBaLRatWrbJZ+wAAAAD+OQ55HQDwoIqLi5Obm5v5+o033lBycrLi4+Pl5eV1z+2PHTtWq1atUnx8vFV5cnKyChQocM/tAwAAAMh7JN3ALfj6+lq9TkxMVNWqVVWmTBmb9lu4cGGbtg8AAADgn8PycuAWbl5eHhAQoBUrVuiDDz6QxWJRdHS0JCklJUV9+vSRn5+fPD09Va9ePR04cOC2bcfExGjcuHE6cOCALBaLLBaLYmJiJFkvL09KSpLFYtHHH3+s2rVry8XFRY899piOHj2quLg4hYWFyd3dXY0aNdKZM2es+li4cKGCgoLk7OyscuXKac6cOTnGlJaWptTUVKsDAAAAwL1hphvIhbi4OHXr1k2enp5688035eLiIsMw1LRpU3l7e2vNmjXy8vLSu+++q/r16+vo0aPy9va+ZXsdOnTQDz/8oLVr1+rbb7+VpByXrI8ZM0YzZ87Uo48+qp49e6pTp05mLK6urmrfvr1Gjx6tuXPnSpLmzZunMWPGaPbs2apcubL279+v3r17y83NTd27d8+2j8mTJ2vcuHH3cJcAAAAA/B1JN5ALvr6+cnJykouLi7n8e+PGjfr+++91+vRpOTk5SZKmTZumVatW6dNPP1WfPn1u2Z6Li4vc3d3l4OCQq+XkQ4cOVcOGDSVJL7zwgjp16qQNGzaoZs2akqRevXqZM+WSNGHCBE2fPl2tW7eWJJUoUUKHDx/Wu+++e8uke/jw4Ro8eLD5OjU1Vf7+/reNDQAAAMCtkXQDd2nv3r26dOmSfHx8rMr/+usvJSYm3te+QkNDza8LFSokSapQoYJV2enTpyVJZ86c0cmTJ9WrVy/17t3brHP9+vUcZ9OdnJzMNw8AAAAA3B8k3cBdysjIUJEiRRQbG5vl3P3+SLF8+fKZX1sslmzLMjIyzLikG0vMq1evbtWOvb39fY0LAAAAQM5IuoG7VKVKFZ06dUoODg4KCAi44+sdHR2Vnp5+3+MqVKiQihUrpp9//llRUVH3vX0AAAAAuUfSDdylBg0aKDw8XC1bttRrr72msmXL6rffftOaNWvUsmVLhYWF5Xh9QECAjh8/rvj4eD3yyCPy8PC4b8u7x44dqwEDBsjT01ONGzdWWlqa9uzZo/Pnz1s9tw0AAADAtvjIMOAuWSwWrVmzRnXq1FHPnj0VGBiojh07KikpyXzuOidt2rRRo0aNVLduXfn6+mrZsmX3Lbann35a77//vmJiYlShQgVFREQoJiZGJUqUuG99AAAAALg9i2EYRl4HAeDBk5qaKi8vL732Xj05u7IoBv89A6LW5XUIAADgXyzz7+WUlBR5enresh4z3QAAAAAA2AhJN2AjwcHBcnd3z/ZYsmRJXocHAAAA4B/AmlHARtasWaNr165ley43z3wDAAAA+Pcj6QZspHjx4nkdAgAAAIA8RtINIEd9O3yW48YQAAAAAG6NZ7oBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QYAAAAAwEZIugEAAAAAsBF2LweQo8krW8nJlf8q8OAY235dXocAAACQa8x0AwAAAABgIyTdAAAAAADYCEk3AAAAAAA2QtINAAAAAICNkHQDAAAAAGAjJN0AAAAAANgISTcAAAAAADZC0o3/lKSkJFksFsXHx+d1KAAAAABA0g0AAAAAgK2QdAO5dO3atbwOAQAAAMC/DEk3Hmhr165VrVq1lD9/fvn4+KhZs2ZKTEw0z+/evVuVK1eWs7OzwsLCtH//fqvrz58/r6ioKPn6+srFxUVlypTRwoULb9tv5jL1jz/+WJGRkXJ2dtaHH34oSVq4cKGCgoLk7OyscuXKac6cOeZ14eHhevnll63aOnPmjPLly6dNmzZJkq5evaphw4apWLFicnNzU/Xq1RUbG2vWj4mJUf78+bVu3ToFBQXJ3d1djRo1UnJyslknMjJSAwcOtOqnZcuWio6ONl/frp+/S0tLU2pqqtUBAAAA4N6QdOOBdvnyZQ0ePFhxcXHasGGD7Ozs1KpVK2VkZOjy5ctq1qyZypYtq71792rs2LEaOnSo1fWjRo3S4cOH9fXXXyshIUFz585VwYIFc93/Sy+9pAEDBighIUENGzbUvHnzNGLECE2aNEkJCQl69dVXNWrUKC1atEiSFBUVpWXLlskwDLONjz76SIUKFVJERIQkqUePHtq2bZuWL1+ugwcPql27dmrUqJGOHTtmXvPnn39q2rRpWrx4sb777judOHEiy9huJzf93Gzy5Mny8vIyD39//zvqDwAAAEBWDnkdAJCTNm3aWL2eP3++/Pz8dPjwYW3fvl3p6elasGCBXF1dFRwcrF9//VXPPvusWf/EiROqXLmywsLCJEkBAQF31P/AgQPVunVr8/WECRM0ffp0s6xEiRI6fPiw3n33XXXv3l0dOnTQoEGDtHXrVtWuXVuStHTpUnXu3Fl2dnZKTEzUsmXL9Ouvv6po0aKSpKFDh2rt2rVauHChXn31VUk3lrK/8847KlWqlCSpf//+Gj9+fK7jzm0/Nxs+fLgGDx5svk5NTSXxBgAAAO4RSTceaImJiRo1apR27typs2fPKiMjQ9KNZDohIUEVK1aUq6urWT88PNzq+meffVZt2rTRvn379OSTT6ply5aqUaNGrvvPTNalG8vET548qV69eql3795m+fXr1+Xl5SVJ8vX11RNPPKElS5aodu3aOn78uHbs2KG5c+dKkvbt2yfDMBQYGGjVT1pamnx8fMzXrq6uZsItSUWKFNHp06dzHXdu+7mZk5OTnJycct0HAAAAgNsj6cYDrXnz5vL399e8efNUtGhRZWRkKCQkRFevXrVawn0rjRs31i+//KKvvvpK3377rerXr6/nnntO06ZNy1X/bm5u5teZCf+8efNUvXp1q3r29vbm11FRUXrhhRc0a9YsLV26VMHBwapYsaLZhr29vfbu3Wt1jSS5u7ubX+fLl8/qnMVisRqvnZ1dlvHfvNFbbvsBAAAAYFsk3XhgnTt3TgkJCXr33XfNpdpbt241z5cvX16LFy/WX3/9JRcXF0nSzp07s7Tj6+ur6OhoRUdHq3bt2nrxxRdznXTfrFChQipWrJh+/vlnRUVF3bJey5Yt9cwzz2jt2rVaunSpunbtap6rXLmy0tPTdfr0aXNMd8PX19dqY7X09HT98MMPqlu37n3tBwAAAMC9IenGA6tAgQLy8fHRe++9pyJFiujEiRNWO4N37txZI0aMUK9evTRy5EglJSVlSaZHjx6tqlWrKjg4WGlpafryyy8VFBR01zGNHTtWAwYMkKenpxo3bqy0tDTt2bNH58+fN5+HdnNzU4sWLTRq1CglJCSoc+fO5vWBgYGKiopSt27dNH36dFWuXFlnz57Vxo0bVaFCBTVp0iRXcdSrV0+DBw/WV199pVKlSumNN97QhQsX7ns/AAAAAO4Nu5fjgWVnZ6fly5dr7969CgkJ0aBBg/T666+b593d3fXFF1/o8OHDqly5skaMGKHXXnvNqg1HR0cNHz5coaGhqlOnjuzt7bV8+fK7junpp5/W+++/r5iYGFWoUEERERGKiYlRiRIlrOpFRUXpwIEDql27th599FGrcwsXLlS3bt00ZMgQlS1bVk899ZR27dp1R5uW9ezZU927d1e3bt0UERGhEiVKmLPc97MfAAAAAPfGYuTmwVgAD53U1FR5eXnp5YX15OTKohg8OMa2X5fXIQAAAJh/L6ekpMjT0/OW9ZjpBgAAAADARki68VB69dVX5e7unu3RuHHjvA4PAAAAwH8Ea0bxUOrbt6/at2+f7bnMndABAAAA4F6RdOOh5O3tLW9v77wOAwAAAMB/HEk3gBwNb/1ZjhtDAAAAALg1nukGAAAAAMBGSLoBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QYAAAAAwEbYvRxAjp79orUcXfmvAvfXwlZr8zoEAACAfwQz3QAAAAAA2AhJNwAAAAAANkLSDQAAAACAjZB0AwAAAABgIyTdAAAAAADYCEk3AAAAAAA2QtINAAAAAICNkHTjgREdHa2WLVvmaQwWi0WrVq3K0xgCAgI0c+bMPI0BAAAAwP1B0o0cRUZGauDAgTa/5p82duxYVapUKUt5cnKyGjdu/I/EEBMTo/z582cpj4uLU58+ff6RGAAAAADYlkNeBwA8SAoXLpzXIcjX1zevQwAAAABwnzDTjVuKjo7W5s2b9eabb8pischisSgpKUmbN29WtWrV5OTkpCJFiujll1/W9evXc7wmPT1dvXr1UokSJeTi4qKyZcvqzTffvOvY1q5dq1q1ail//vzy8fFRs2bNlJiYaFXn119/VceOHeXt7S03NzeFhYVp165diomJ0bhx43TgwAEzxpiYGEnWy8vDw8P18ssvW7V55swZ5cuXT5s2bZIkXb16VcOGDVOxYsXk5uam6tWrKzY29rbxx8bGqkePHkpJSTFjGDt2rKSsy8stFoveffddNWvWTK6urgoKCtKOHTv0008/KTIyUm5ubgoPD88y/i+++EJVq1aVs7OzSpYsqXHjxpnfJwAAAAD/DJJu3NKbb76p8PBw9e7dW8nJyUpOTla+fPnUpEkTPfbYYzpw4IDmzp2r+fPna+LEibe8xt/fXxkZGXrkkUf08ccf6/Dhwxo9erReeeUVffzxx3cV2+XLlzV48GDFxcVpw4YNsrOzU6tWrZSRkSFJunTpkiIiIvTbb79p9erVOnDggIYNG6aMjAx16NBBQ4YMUXBwsBljhw4dsvQRFRWlZcuWyTAMs+yjjz5SoUKFFBERIUnq0aOHtm3bpuXLl+vgwYNq166dGjVqpGPHjuUYf40aNTRz5kx5enqaMQwdOvSW9SdMmKBu3bopPj5e5cqVU+fOnfXMM89o+PDh2rNnjySpf//+Zv1169apS5cuGjBggA4fPqx3331XMTExmjRp0i37SEtLU2pqqtUBAAAA4N6wvBy35OXlJUdHR7m6uprLrkeMGCF/f3/Nnj1bFotF5cqV02+//aaXXnpJo0ePzvYaSbK3t9e4cePM1yVKlND27dv18ccfq3379nccW5s2baxez58/X35+fjp8+LBCQkK0dOlSnTlzRnFxcfL29pYklS5d2qzv7u4uBweHHJeTd+jQQYMGDdLWrVtVu3ZtSdLSpUvVuXNn2dnZKTExUcuWLdOvv/6qokWLSpKGDh2qtWvXauHChXr11Vdv2bajo6O8vLxksVhytaS9R48e5n166aWXFB4erlGjRqlhw4aSpBdeeEE9evQw60+aNEkvv/yyunfvLkkqWbKkJkyYoGHDhmnMmDHZ9jF58mSr7xEAAACAe8dMN+5IQkKCwsPDZbFYzLKaNWvq0qVL+vXXX3O89p133lFYWJh8fX3l7u6uefPm6cSJE3cVR2Jiojp37qySJUvK09NTJUqUkCSzvfj4eFWuXNlMuO+Gr6+vnnjiCS1ZskSSdPz4ce3YsUNRUVGSpH379skwDAUGBsrd3d08Nm/enGWp970KDQ01vy5UqJAkqUKFClZlV65cMWen9+7dq/Hjx1vFlbn64M8//8y2j+HDhyslJcU8Tp48eV/HAAAAADyMmOnGHTEMwyrhziyTlKX8Zh9//LEGDRqk6dOnKzw8XB4eHnr99de1a9euu4qjefPm8vf317x581S0aFFlZGQoJCREV69elSS5uLjcVbt/FxUVpRdeeEGzZs3S0qVLFRwcrIoVK0qSMjIyZG9vr71798re3t7qOnd39/vSf6Z8+fKZX2fe5+zKMpfXZ2RkaNy4cWrdunWWtpydnbPtw8nJSU5OTvctZgAAAAAk3bgNR0dHpaenm6/Lly+vFStWWCXf27dvl4eHh4oVK5btNZK0ZcsW1ahRQ/369TPL7nY2+Ny5c0pISNC7775rLvveunWrVZ3Q0FC9//77+uOPP7Kd7c4uxuy0bNlSzzzzjNauXaulS5eqa9eu5rnKlSsrPT1dp0+fNuO4E7mN4W5UqVJFP/74o9WSegAAAAD/PJaXI0cBAQHatWuXkpKSdPbsWfXr108nT57U888/ryNHjujzzz/XmDFjNHjwYNnZ2WV7TUZGhkqXLq09e/Zo3bp1Onr0qEaNGqW4uLi7iqlAgQLy8fHRe++9p59++kkbN27U4MGDrep06tRJhQsXVsuWLbVt2zb9/PPPWrFihXbs2GHGePz4ccXHx+vs2bNKS0vLti83Nze1aNFCo0aNUkJCgjp37myeCwwMVFRUlLp166aVK1fq+PHjiouL02uvvaY1a9bk6t5eunRJGzZs0NmzZ2+57PtujB49Wh988IHGjh2rQ4cOKSEhQR999JFGjhx53/oAAAAAcHsk3cjR0KFDZW9vr/Lly8vX11fXrl3TmjVrtHv3blWsWFF9+/ZVr169rJK5v19z4sQJ9e3bV61bt1aHDh1UvXp1nTt3zmrW+07Y2dlp+fLl2rt3r0JCQjRo0CC9/vrrVnUcHR31zTffyM/PT02aNFGFChU0ZcoUcxl4mzZt1KhRI9WtW1e+vr5atmzZLfuLiorSgQMHVLt2bT366KNW5xYuXKhu3bppyJAhKlu2rJ566int2rVL/v7+tx1HjRo11LdvX3Xo0EG+vr6aOnXqXdyN7DVs2FBffvml1q9fr8cee0yPP/64ZsyYoeLFi9+3PgAAAADcnsW4+fOQAOD/S01NlZeXlzp/WF+OrjyJgvtrYau1eR0CAADAPcn8ezklJUWenp63rMdMNwAAAAAANkLSjQfOiRMnrD7q6u/H3X7M2D+tcePGtxxDTp/hDQAAAOC/gzWjeOAULVpU8fHxOZ7/N3j//ff1119/ZXvuXj4/HAAAAMC/B0k3HjgODg7/iY+6yvwINQAAAAAPL5aXAwAAAABgI8x0A8jR3OYrc9yNEQAAAMCtMdMNAAAAAICNkHQDAAAAAGAjJN0AAAAAANgISTcAAAAAADZC0g0AAAAAgI2wezmAHLX5aogcXB3zOgzk0tct3s7rEAAAAHATZroBAAAAALARkm4AAAAAAGyEpBsAAAAAABsh6QYAAAAAwEZIugEAAAAAsBGSbgAAAAAAbISkG8hBUlKSLBaL4uPj8zoUAAAAAP9CJN3Af1xMTIzy58+f12EAAAAADyWSbuAWrl69mtchAAAAAPiXI+nGv9YXX3yh/PnzKyMjQ5IUHx8vi8WiF1980azzzDPPqFOnTpKkFStWKDg4WE5OTgoICND06dOt2gsICNDEiRMVHR0tLy8v9e7dO0ufGRkZ6t27twIDA/XLL7/cNsYLFy6oT58+KlSokJydnRUSEqIvv/zSPH+7mCwWi1atWmVVlj9/fsXExEj6v+XvK1euVN26deXq6qqKFStqx44dkqTY2Fj16NFDKSkpslgsslgsGjt27G3jBgAAAHB/kHTjX6tOnTq6ePGi9u/fL0navHmzChYsqM2bN5t1YmNjFRERob1796p9+/bq2LGjvv/+e40dO1ajRo0yk9dMr7/+ukJCQrR3716NGjXK6tzVq1fVvn177dmzR1u3blXx4sVzjC8jI0ONGzfW9u3b9eGHH+rw4cOaMmWK7O3tJSnXMeXGiBEjNHToUMXHxyswMFCdOnXS9evXVaNGDc2cOVOenp5KTk5WcnKyhg4dmm0baWlpSk1NtToAAAAA3BuHvA4AuFteXl6qVKmSYmNjVbVqVcXGxmrQoEEaN26cLl68qMuXL+vo0aOKjIzUhAkTVL9+fTORDgwM1OHDh/X6668rOjrabLNevXpWSWlSUpIk6dKlS2ratKn++usvxcbGysvL67bxffvtt9q9e7cSEhIUGBgoSSpZsqR5fsaMGbmKKTeGDh2qpk2bSpLGjRun4OBg/fTTTypXrpy8vLxksVhUuHDhHNuYPHmyxo0bd0f9AgAAAMgZM934V4uMjFRsbKwMw9CWLVvUokULhYSEaOvWrdq0aZMKFSqkcuXKKSEhQTVr1rS6tmbNmjp27JjS09PNsrCwsGz76dSpky5duqRvvvkmVwm3dGO5+yOPPGIm3H+X25hyIzQ01Py6SJEikqTTp0/fURvDhw9XSkqKeZw8efKOrgcAAACQFUk3/tUiIyO1ZcsWHThwQHZ2dipfvrwiIiK0efNmc2m5JBmGIYvFYnWtYRhZ2nNzc8u2nyZNmujgwYPauXNnrmNzcXHJ8XxuYrJYLFnKrl27lqWtfPnyWV0jyXzWPbecnJzk6elpdQAAAAC4NyTd+FfLfK575syZioiIkMViUUREhGJjY62S7vLly2vr1q1W127fvl2BgYHmM9Y5efbZZzVlyhQ99dRTVs+M5yQ0NFS//vqrjh49mu353MTk6+ur5ORk8/yxY8f0559/5qr/TI6Ojnc8cw4AAADg/uCZbvyrZT7X/eGHH+rNN9+UdCMRb9euna5du6bIyEhJ0pAhQ/TYY49pwoQJ6tChg3bs2KHZs2drzpw5ue7r+eefV3p6upo1a6avv/5atWrVyrF+RESE6tSpozZt2mjGjBkqXbq0jhw5IovFokaNGuUqpnr16mn27Nl6/PHHlZGRoZdeeslqVjs3AgICdOnSJW3YsEEVK1aUq6urXF1d76gNAAAAAHeHmW7869WtW1fp6elmgl2gQAGVL19evr6+CgoKkiRVqVJFH3/8sZYvX66QkBCNHj1a48ePv+MNywYOHKhx48apSZMm2r59+23rr1ixQo899pg6deqk8uXLa9iwYeasc25imj59uvz9/VWnTh117txZQ4cOveOEuUaNGurbt686dOggX19fTZ069Y6uBwAAAHD3LEZ2D7YCeOilpqbKy8tLDZY+LQdXx7wOB7n0dYu38zoEAACAh0Lm38spKSk57ofETDcAAAAAADZC0g3cpSVLlsjd3T3bIzg4OK/DAwAAAPAAYCM14C499dRTql69erbn7nSzMwAAAAD/TSTdwF3y8PCQh4dHXocBAAAA4AHG8nIAAAAAAGyEmW4AOVrRdHqOuzECAAAAuDVmugEAAAAAsBGSbgAAAAAAbISkGwAAAAAAGyHpBgAAAADARki6AQAAAACwEXYvB5CjNl9MVT5X57wO44G1ptXIvA4BAAAADzBmugEAAAAAsBGSbgAAAAAAbISkGwAAAAAAGyHpBgAAAADARki6AQAAAACwEZJuAAAAAABshKQbAAAAAAAbIenGAyMmJkb58+fP0xgCAgI0c+bMPI0BAAAAwH8HSTcAAAAAADZC0o1/xLVr1/I6BAAAAAD4x5F0P8Q+/fRTVahQQS4uLvLx8VGDBg10+fJlSdLChQsVFBQkZ2dnlStXTnPmzLG69qWXXlJgYKBcXV1VsmRJjRo1yiqxHjt2rCpVqqQFCxaoZMmScnJykmEYunDhgvr06aNChQrJ2dlZISEh+vLLL63aXrdunYKCguTu7q5GjRopOTn5tmNZt26dnJ2ddeHCBavyAQMGKCIiwny9YsUKBQcHy8nJSQEBAZo+ffot20xKSpLFYlF8fLxZduHCBVksFsXGxkqSYmNjZbFYtG7dOlWuXFkuLi6qV6+eTp8+ra+//lpBQUHy9PRUp06d9Oeff5rtGIahqVOnqmTJknJxcVHFihX16aef3nacmVavXq0yZcrIxcVFdevW1aJFi2SxWKzGP2/ePPn7+8vV1VWtWrXSjBkzcly+n5aWptTUVKsDAAAAwL1xyOsAkDeSk5PVqVMnTZ06Va1atdLFixe1ZcsWGYahefPmacyYMZo9e7YqV66s/fv3q3fv3nJzc1P37t0lSR4eHoqJiVHRokX1/fffq3fv3vLw8NCwYcPMPn766Sd9/PHHWrFihezt7ZWRkaHGjRvr4sWL+vDDD1WqVCkdPnxY9vb25jV//vmnpk2bpsWLF8vOzk5dunTR0KFDtWTJkhzH06BBA+XPn18rVqxQr169JEnp6en6+OOPNX78eEnS3r171b59e40dO1YdOnTQ9u3b1a9fP/n4+Cg6Ovqe7ufYsWM1e/Zsubq6qn379mrfvr2cnJy0dOlSXbp0Sa1atdKsWbP00ksvSZJGjhyplStXau7cuSpTpoy+++47denSRb6+vlZvEmQnKSlJbdu21QsvvKCnn35a+/fv19ChQ63qbNu2TX379tVrr72mp556St9++61GjRqVY7uTJ0/WuHHj7uk+AAAAALBG0v2QSk5O1vXr19W6dWsVL15cklShQgVJ0oQJEzR9+nS1bt1aklSiRAkdPnxY7777rpl0jxw50mwrICBAQ4YM0UcffWSVdF+9elWLFy+Wr6+vJOmbb77R7t27lZCQoMDAQElSyZIlreK6du2a3nnnHZUqVUqS1L9/fzNpzom9vb06dOigpUuXmkn3hg0bdP78ebVr106SNGPGDNWvX99MPgMDA3X48GG9/vrr95x0T5w4UTVr1pQk9erVS8OHD1diYqI5vrZt22rTpk166aWXdPnyZc2YMUMbN25UeHi4eR+2bt2qd99997ZJ9zvvvKOyZcvq9ddflySVLVtWP/zwgyZNmmTWmTVrlho3bmwm44GBgdq+fXuWVQU3Gz58uAYPHmy+Tk1Nlb+//13cDQAAAACZSLofUhUrVlT9+vVVoUIFNWzYUE8++aTatm2r69ev6+TJk+rVq5d69+5t1r9+/bq8vLzM159++qlmzpypn376SZcuXdL169fl6elp1Ufx4sXNhFuS4uPj9cgjj5gJd3ZcXV3NhFuSihQpotOnT+dqTFFRUQoPD9dvv/2mokWLasmSJWrSpIkKFCggSUpISFCLFi2srqlZs6Zmzpyp9PR0qxn3OxUaGmp+XahQIXPZ/c1lu3fvliQdPnxYV65c0RNPPGHVxtWrV1W5cuXb9vXjjz/qsccesyqrVq1aljqtWrXKUienpNvJyUlOTk637R8AAABA7pF0P6Ts7e21fv16bd++Xd98841mzZqlESNG6IsvvpB043ng6tWrZ7lGknbu3KmOHTtq3Lhxatiwoby8vLR8+fIsz0e7ublZvXZxcbltXPny5bN6bbFYZBhGrsZUrVo1lSpVSsuXL9ezzz6rzz77TAsXLjTPG4Yhi8VidU1ObdvZ2WWpc6sN4W6O22KxZDuOjIwMSTL//eqrr1SsWDGrerlJenMzjjsdKwAAAADbIOl+iFksFtWsWVM1a9bU6NGjVbx4cW3btk3FihXTzz//rKioqGyv27Ztm4oXL64RI0aYZb/88stt+wsNDdWvv/6qo0eP5jjbfS86d+6sJUuW6JFHHpGdnZ2aNm1qnitfvry2bt1qVX/79u0KDAzMdpY7c5Y+OTnZnIG+eVO1u1W+fHk5OTnpxIkTt11Knp1y5cppzZo1VmV79uzJUidzZv1WdQAAAADYHkn3Q2rXrl3asGGDnnzySfn5+WnXrl06c+aMgoKCNHbsWA0YMECenp5q3Lix0tLStGfPHp0/f16DBw9W6dKldeLECS1fvlyPPfaYvvrqK3322We37TMiIkJ16tRRmzZtNGPGDJUuXVpHjhyRxWJRo0aN7su4oqKiNG7cOE2aNElt27aVs7OzeW7IkCF67LHHNGHCBHXo0EE7duz4f+zdeXRO5/7//9edIHOCECJCECEhBInSlBiipramFkGJ8bQ9aoyoY4oxqKSoQ1VLHNWqQ+uDUmNTRE0hrZKaNW3FoS2JoQ1J7t8f/bp/vZsZt6DPx1p7Nfva1/DeW63lneva19bChQtz7Mx+l52dnZo0aaJZs2bJy8tLP//8s9m77PfKyclJERERGjlypLKzs/XMM88oPT1d+/btk6Ojo+m9+bz84x//UGxsrMaOHauBAwcqKSlJcXFxkmSa3X799dfVvHlzxcbG6vnnn9euXbu0ZcuWHLPfAAAAACyLT4b9TTk7O2v37t3q0KGDfHx8NGHCBMXExKh9+/YaNGiQ3nvvPcXFxcnf318hISGKi4tTtWrVJEmdOnXSyJEjNXToUAUEBGjfvn0F7ox917p16xQUFKSwsDD5+fkpMjJSWVlZD+y+atasqaCgIH3zzTc5ZuobNmyoNWvWaPXq1apbt64mTZqkqVOn5ruJ2rJly3Tnzh0FBgZq+PDhmj59+gOJc9q0aZo0aZKio6Pl6+urtm3bauPGjaZnnJ9q1app7dq1+uSTT1SvXj0tXrzYtOrg7vL04OBgvfPOO4qNjVX9+vX1+eefa+TIkWa/hAAAAABgeQYjL3oCj70ZM2bonXfe0Q8//JBnncGDB+u7777Tnj17CtVnenq6XFxcFPrBeJW0J1nPy+Yu97/6AQAAAI+fu/9eTktLy7Gp9J+xvBx4DC1atEhBQUFydXVVQkKC3nzzTQ0dOtSszty5c9WmTRs5ODhoy5YtWrFiRZ5L6QEAAABYBkk3HhuOjo55XtuyZYuaNWv2EKOxnFdeeUUffPBBrtf69Omjd955R6dPn9b06dP166+/qkqVKho9erTGjRtnVvfgwYOaM2eOrl+/rurVq2vBggUaNGjQw7gFAAAAAP8Py8vx2Dhz5kye1zw8PAr1SbLHweXLl5Wenp7rNWdnZ7m5uT2UOFheXjgsLwcAAPh7Ynk5njje3t7FHcJD4ebm9tASawAAAACWRdINIF/rno/M9zd3AAAAAPLGJ8MAAAAAALAQkm4AAAAAACyEpBsAAAAAAAsh6QYAAAAAwEJIugEAAAAAsBB2LweQrxc3vPPEfqf7s67DijsEAAAAPOGY6QYAAAAAwEJIugEAAAAAsBCSbgAAAAAALISkGwAAAAAACyHpBgAAAADAQki6AQAAAACwEJJuAAAAAAAshKQbfxtxcXEqXbp0scbg5eWlefPmFWsMAAAAAB4ekm4AAAAAACyEpBtPhDt37hR3CAAAAACQA0k3LGbt2rXy9/eXnZ2dXF1dFRoaqps3b0qSli9fLl9fX9na2qp27dpatGiRWduxY8fKx8dH9vb2ql69uiZOnGiWWEdFRSkgIEDLli1T9erVZWNjI6PRqGvXrmnIkCGqUKGCbG1tVbduXW3atMms761bt8rX11eOjo5q166dUlNTC7yXrVu3ytbWVteuXTMrHzZsmEJCQkzn69atU506dWRjYyMvLy/FxMTk2eeFCxdkMBiUlJRkKrt27ZoMBoPi4+MlSfHx8TIYDNq6dasaNGggOzs7tWrVSpcvX9aWLVvk6+srZ2dnhYWF6datW6Z+jEaj5syZo+rVq8vOzk7169fX2rVr873HjIwMpaenmx0AAAAA7k+J4g4AT6bU1FSFhYVpzpw56tKli65fv649e/bIaDRq6dKlmjx5shYuXKgGDRro6NGjGjx4sBwcHNSvXz9JkpOTk+Li4lSpUiUdO3ZMgwcPlpOTkyIjI01jnDlzRmvWrNG6detkbW2t7OxstW/fXtevX9cHH3ygGjVq6MSJE7K2tja1uXXrlubOnauVK1fKyspKffr0UUREhFatWpXv/YSGhqp06dJat26dBg4cKEnKysrSmjVrNHXqVElSYmKiunfvrqioKPXo0UP79u3Ta6+9JldXV4WHh9/X84yKitLChQtlb2+v7t27q3v37rKxsdGHH36oGzduqEuXLnr77bc1duxYSdKECRP0ySefaPHixapZs6Z2796tPn36qHz58ma/JPiz6OhoTZky5b7iBAAAAGCOpBsWkZqaqszMTHXt2lVVq1aVJPn7+0uSpk2bppiYGHXt2lWSVK1aNZ04cUJLliwxJd0TJkww9eXl5aXRo0fr448/Nku6b9++rZUrV6p8+fKSpG3btungwYNKTk6Wj4+PJKl69epmcd25c0fvvPOOatSoIUkaOnSoKWnOj7W1tXr06KEPP/zQlHTv3LlTV69e1UsvvSRJio2NVevWrTVx4kRJko+Pj06cOKE333zzvpPu6dOnKzg4WJI0cOBAjRs3TmfPnjXd34svvqgvvvhCY8eO1c2bNxUbG6tdu3apadOmpuewd+9eLVmyJM+ke9y4cRo1apTpPD09XZ6envcVNwAAAPB3R9INi6hfv75at24tf39/tW3bVs8++6xefPFFZWZm6ocfftDAgQM1ePBgU/3MzEy5uLiYzteuXat58+bpzJkzunHjhjIzM+Xs7Gw2RtWqVU0JtyQlJSWpcuXKpoQ7N/b29qaEW5Lc3d11+fLlQt1T79691bRpU128eFGVKlXSqlWr1KFDB5UpU0aSlJycrE6dOpm1CQ4O1rx585SVlWU2415U9erVM/1coUIF07L7P5cdPHhQknTixAn9/vvvatOmjVkft2/fVoMGDfIcw8bGRjY2NvccIwAAAICcSLphEdbW1tq+fbv27dunbdu26e2339b48eO1ceNGSdLSpUv11FNP5WgjSfv371fPnj01ZcoUtW3bVi4uLlq9enWO96MdHBzMzu3s7AqMq2TJkmbnBoNBRqOxUPfUuHFj1ahRQ6tXr9arr76qTz/9VMuXLzddNxqNMhgMZm3y69vKyipHnbw2hPtz3AaDIdf7yM7OliTTfz/77DN5eHiY1SOpBgAAAB4ukm5YjMFgUHBwsIKDgzVp0iRVrVpVCQkJ8vDw0Llz59S7d+9c2yUkJKhq1aoaP368qez7778vcLx69erpxx9/1KlTp/Kd7b4fvXr10qpVq1S5cmVZWVmpY8eOpmt+fn7au3evWf19+/bJx8cn11nuu7P0qampphnoP2+qdq/8/PxkY2OjlJSUPJeSAwAAAHg4SLphEQcOHNDOnTv17LPPys3NTQcOHNCVK1fk6+urqKgoDRs2TM7Ozmrfvr0yMjJ0+PBhXb16VaNGjZK3t7dSUlK0evVqBQUF6bPPPtOnn35a4JghISFq3ry5unXrptjYWHl7e+u7776TwWBQu3btHsh99e7dW1OmTNGMGTP04osvytbW1nRt9OjRCgoK0rRp09SjRw999dVXWrhwYY6d2e+ys7NTkyZNNGvWLHl5eennn382e5f9Xjk5OSkiIkIjR45Udna2nnnmGaWnp2vfvn1ydHQ0vTcPAAAAwPJIumERzs7O2r17t+bNm6f09HRVrVpVMTExat++vaQ/3q1+8803FRkZKQcHB/n7+2vEiBGSpE6dOmnkyJEaOnSoMjIy1LFjR02cOFFRUVEFjrtu3TpFREQoLCxMN2/elLe3t2bNmvXA7qtmzZoKCgrSoUOHNG/ePLNrDRs21Jo1azRp0iRNmzZN7u7umjp1ar6bqC1btkwDBgxQYGCgatWqpTlz5ujZZ5+97zinTZsmNzc3RUdH69y5cypdurQaNmyof/3rX/fdNwAAAIDCMxgL+0IrgL+V9PR0ubi4qM3K2Sppb1twg8fQZ12HFXcIAAAAeEzd/fdyWlpajk2f/8zqIcYEAAAAAMDfCkk38P84OjrmeezZs6e4wwMAAADwGOKdbuD/yW/n8L9+egsAAAAACoOkG/h/vL29izsEAAAAAE8Ykm4A+Vr7wiv5bgwBAAAAIG+80w0AAAAAgIWQdAMAAAAAYCEk3QAAAAAAWAhJNwAAAAAAFkLSDQAAAACAhbB7OYB8vfh/K1TS3q64w3igPus2qLhDAAAAwN8EM90AAAAAAFhIkZPuzz//XHv37jWd//vf/1ZAQIB69eqlq1evPtDgAAAAAAB4nBU56R4zZozS09MlSceOHdPo0aPVoUMHnTt3TqNGjXrgAQIAAAAA8Lgq8jvd58+fl5+fnyRp3bp1eu655zRz5kwdOXJEHTp0eOABAgAAAADwuCryTHepUqV069YtSdKOHTv07LPPSpLKli1rmgEHAAAAAAD3MNP9zDPPaNSoUQoODtbBgwf18ccfS5JOnTqlypUrP/AAAQAAAAB4XBV5pnvhwoUqUaKE1q5dq8WLF8vDw0OStGXLFrVr1+6BBwgAAAAAwOOqyDPdVapU0aZNm3KUv/XWWw8kIAAAAAAAnhT39J3us2fPasKECQoLC9Ply5cl/fEpsePHjz/Q4ADcv7i4OJUuXbq4wwAAAAD+loqcdH/55Zfy9/fXgQMH9Mknn+jGjRuSpG+++UaTJ09+4AECAAAAAPC4KnLS/cYbb2j69Onavn27SpUqZSpv2bKlvvrqqwcaHJCXFi1aaNiwYYqMjFTZsmVVsWJFRUVFma6npaVpyJAhcnNzk7Ozs1q1aqWvv/7adM3a2lqJiYmSJKPRqLJlyyooKMjU/qOPPpK7u7sk6fbt2xo6dKjc3d1la2srLy8vRUdHFyrOa9euaciQIapQoYJsbW1Vt25ds9cz1q1bpzp16sjGxkZeXl6KiYkxa28wGLR+/XqzstKlSysuLk6SdOHCBRkMBn3yySdq2bKl7O3tVb9+fdPfxfj4ePXv319paWkyGAwyGAxmz+nPMjIylJ6ebnYAAAAAuD9FTrqPHTumLl265CgvX768fvnllwcSFFAYK1askIODgw4cOKA5c+Zo6tSp2r59u4xGozp27KhLly5p8+bNSkxMVMOGDdW6dWv9+uuvcnFxUUBAgOLj4yX9sUrj7n/vJprx8fEKCQmRJC1YsEAbNmzQmjVrdPLkSX3wwQfy8vIqML7s7Gy1b99e+/bt0wcffKATJ05o1qxZsra2liQlJiaqe/fu6tmzp44dO6aoqChNnDjRlFAXxfjx4xUREaGkpCT5+PgoLCxMmZmZevrppzVv3jw5OzsrNTVVqampioiIyLWP6Ohoubi4mA5PT88ixwEAAADAXJE3UitdurRSU1NVrVo1s/KjR4+adjIHHoZ69eqZXmmoWbOmFi5cqJ07d8ra2lrHjh3T5cuXZWNjI0maO3eu1q9fr7Vr12rIkCFq0aKF4uPjNXr0aMXHx6t169Y6d+6c9u7dqw4dOig+Pl4jR46UJKWkpKhmzZp65plnZDAYVLVq1ULFt2PHDh08eFDJycny8fGRJFWvXt10PTY2Vq1bt9bEiRMlST4+Pjpx4oTefPNNhYeHF+lZREREqGPHjpKkKVOmqE6dOjpz5oxq164tFxcXGQwGVaxYMd8+xo0bp1GjRpnO09PTSbwBAACA+1Tkme5evXpp7NixunTpkgwGg7Kzs5WQkKCIiAj17dvXEjECuapXr57Zubu7uy5fvqzExETduHFDrq6ucnR0NB3nz5/X2bNnJf2xPH3Pnj3Kzs7Wl19+qRYtWqhFixb68ssvdenSJZ06dco00x0eHq6kpCTVqlVLw4YN07Zt2woVX1JSkipXrmxKuP8qOTlZwcHBZmXBwcE6ffq0srKy7vlZ3F0Wf3eTw8KysbGRs7Oz2QEAAADg/hR5pnvGjBkKDw+Xh4eHjEaj/Pz8lJWVpV69emnChAmWiBHIVcmSJc3O7/4SKDs7W+7u7qbl4392dxfv5s2b6/r16zpy5Ij27NmjadOmydPTUzNnzlRAQIDc3Nzk6+srSWrYsKHOnz+vLVu2aMeOHerevbtCQ0O1du3afOOzs7PL97rRaJTBYMhR9td7+mvZnTt3cvT152dxt8/s7Ox8xwcAAABgeUVKuo1Goy5evKilS5dq2rRpOnLkiLKzs9WgQQPVrFnTUjECRdKwYUNdunRJJUqUyPPd67vvdS9cuFAGg0F+fn6qVKmSjh49qk2bNplmue9ydnZWjx491KNHD7344otq166dfv31V5UtWzbPOOrVq6cff/xRp06dynW228/PT3v37jUr27dvn3x8fEzvfZcvX16pqamm66dPn9atW7cK+ygkSaVKlSryzDkAAACAB6PISXfNmjV1/Phx1axZ0+z9VOBRERoaqqZNm6pz586aPXu2atWqpYsXL2rz5s3q3LmzAgMDJf2xxHz+/Pnq0qWLDAaDypQpIz8/P3388cdasGCBqb+33npL7u7uCggIkJWVlf773/+qYsWKBX77OiQkRM2bN1e3bt0UGxsrb29vfffddzIYDGrXrp1Gjx6toKAgTZs2TT169NBXX32lhQsXatGiRaY+WrVqpYULF6pJkybKzs7W2LFjc8zwF8TLy0s3btzQzp07Vb9+fdnb28ve3r5IfQAAAAC4N0V6p9vKyko1a9Zkl3I80gwGgzZv3qzmzZtrwIAB8vHxUc+ePXXhwgVVqFDBVK9ly5bKyspSixYtTGUhISHKysoym+l2dHTU7NmzFRgYqKCgIF24cEGbN2+WlVXBf33WrVunoKAghYWFyc/PT5GRkaZZ54YNG2rNmjVavXq16tatq0mTJmnq1Klmm6jFxMTI09NTzZs3V69evRQREVHkhPnpp5/WK6+8oh49eqh8+fKaM2dOkdoDAAAAuHcG419fGC3AZ599plmzZmnx4sWqW7eupeICUMzS09Pl4uKiNv9ZoJL2+b+f/rj5rNug4g4BAAAAj7m7/15OS0vLdxPiIm+k1qdPH926dUv169dXqVKlcmwW9euvvxY9WgAAAAAAnkBFTrrnzZtngTCAx8+qVav0j3/8I9drVatW1fHjxx9yRAAAAAAeNUVOuvv162eJOIDHzgsvvKCnnnoq12tF3ewMAAAAwJOpyEl3SkpKvterVKlyz8EAjxMnJyc5OTkVdxgAAAAAHmFFTrq9vLxkMBjyvM73gAEAAAAA+EORk+6jR4+and+5c0dHjx5VbGysZsyY8cACA/BoWNupX767MQIAAADIW5GT7vr16+coCwwMVKVKlfTmm2+qa9euDyQwAAAAAAAed1YPqiMfHx8dOnToQXUHAAAAAMBjr8gz3enp6WbnRqNRqampioqKUs2aNR9YYAAAAAAAPO6KnHSXLl06x0ZqRqNRnp6eWr169QMLDAAAAACAx12Rk+4vvvjC7NzKykrly5eXt7e3SpQocncAAAAAADyxipwlGwwGPf300zkS7MzMTO3evVvNmzd/YMEBKH4vrf9YJe3tizuMB2rTi72LOwQAAAD8TRR5I7WWLVvq119/zVGelpamli1bPpCgAAAAAAB4EhQ56TYajTne6ZakX375RQ4ODg8kKAAAAAAAngSFXl5+9/vbBoNB4eHhsrGxMV3LysrSN998o6effvrBRwgAAAAAwGOq0Em3i4uLpD9mup2cnGRnZ2e6VqpUKTVp0kSDBw9+8BECAAAAAPCYKnTSvXz5ckmSl5eXIiIiWEoOAAAAAEABirx7+eTJky0RBwAAAAAAT5wib6QmSWvXrlX37t3VpEkTNWzY0OwAHgXh4eHq3Lmzxcd599135enpKSsrK82bN8/i4+XHy8ur2GMAAAAAYK7ISfeCBQvUv39/ubm56ejRo2rcuLFcXV117tw5tW/f3hIxAo+k9PR0DR06VGPHjtVPP/2kIUOGFHdIAAAAAB4xRU66Fy1apHfffVcLFy5UqVKlFBkZqe3bt2vYsGFKS0uzRIzAQ2c0GpWZmZlvnZSUFN25c0cdO3aUu7u77O3tH1J0AAAAAB4XRU66U1JSTJ8Gs7Oz0/Xr1yVJL7/8sj766KMHGx0ee9evX1fv3r3l4OAgd3d3vfXWW2rRooVGjBghSbp9+7YiIyPl4eEhBwcHPfXUU4qPjze1j4uLU+nSpbV161b5+vrK0dFR7dq1U2pqqqlOVlaWRo0apdKlS8vV1VWRkZEyGo1mcRiNRs2ZM0fVq1eXnZ2d6tevr7Vr15qux8fHy2AwaOvWrQoMDJSNjY327NmT533FxcXJ399fklS9enUZDAZduHBBkrRx40Y1atRItra2ql69uqZMmWKWwBsMBi1ZskTPPfec7O3t5evrq6+++kpnzpxRixYt5ODgoKZNm+rs2bOmNmfPnlWnTp1UoUIFOTo6KigoSDt27Mj32aelpWnIkCFyc3OTs7OzWrVqpa+//jrfNgAAAAAerCIn3RUrVtQvv/wiSapatar2798vSTp//nyORAcYNWqUEhIStGHDBm3fvl179uzRkSNHTNf79++vhIQErV69Wt98841eeukltWvXTqdPnzbVuXXrlubOnauVK1dq9+7dSklJUUREhOl6TEyMli1bpvfff1979+7Vr7/+qk8//dQsjgkTJmj58uVavHixjh8/rpEjR6pPnz768ssvzepFRkYqOjpaycnJqlevXp731aNHD1PSe/DgQaWmpsrT01Nbt25Vnz59NGzYMJ04cUJLlixRXFycZsyYYdZ+2rRp6tu3r5KSklS7dm316tVL//jHPzRu3DgdPnxYkjR06FBT/Rs3bqhDhw7asWOHjh49qrZt2+r5559XSkpKrvEZjUZ17NhRly5d0ubNm5WYmKiGDRuqdevW+vXXX3Ntk5GRofT0dLMDAAAAwP0xGIuYKQ8aNEienp6aPHmy3nnnHY0aNUrBwcE6fPiwunbtqvfff99SseIxc/36dbm6uurDDz/Uiy++KOmP2ddKlSpp8ODBev3111WzZk39+OOPqlSpkqldaGioGjdurJkzZyouLk79+/fXmTNnVKNGDUl/vOIwdepUXbp0SZJUqVIlDR8+XGPHjpUkZWZmqlq1amrUqJHWr1+vmzdvqly5ctq1a5eaNm1qGmfQoEG6deuWPvzwQ8XHx6tly5Zav369OnXqVKj7S0pKUoMGDXT+/Hl5eXlJkpo3b6727dtr3LhxpnoffPCBIiMjdfHiRUl/zHRPmDBB06ZNkyTt379fTZs21fvvv68BAwZIklavXq3+/fvrt99+y3P8OnXq6NVXXzUl515eXhoxYoRGjBihXbt2qUuXLrp8+bJsbGxMbby9vRUZGZnr++dRUVGaMmVKjvJnV7yrkk/Y0vlNL/Yu7hAAAADwmEtPT5eLi4vS0tLk7OycZ70ifzLs3XffVXZ2tiTplVdeUdmyZbV37149//zzeuWVV+49Yjxxzp07pzt37qhx48amMhcXF9WqVUuSdOTIERmNRvn4+Ji1y8jIkKurq+nc3t7elHBLkru7uy5fvizpjyQ+NTXVLJkuUaKEAgMDTSsvTpw4od9//11t2rQxG+f27dtq0KCBWVlgYOD93LISExN16NAhs5ntrKws/f7777p165bpve8/z6JXqFBBkkzL1e+W/f7770pPT5ezs7Nu3rypKVOmaNOmTbp48aIyMzP122+/5TnTnZiYqBs3bpg9R0n67bffzJat/9m4ceM0atQo03l6ero8PT2L+AQAAAAA/FmRk24rKytZWf3/q9K7d++u7t27P9Cg8GS4m/QaDIZcy7Ozs2Vtba3ExERZW1ub1XF0dDT9XLJkSbNrBoOhSK8y3P0l0WeffSYPDw+za3+eBZYkBweHQveb11hTpkxR165dc1yztbU1/fzne7r7fHIruxv7mDFjtHXrVs2dO1fe3t6ys7PTiy++qNu3b+cZh7u7u9n78XeVLl061zY2NjY5ngcAAACA+1PkpFuS9uzZoyVLlujs2bNau3atPDw8tHLlSlWrVk3PPPPMg44Rj6kaNWqoZMmSOnjwoGnGND09XadPn1ZISIgaNGigrKwsXb58Wc2aNbunMVxcXOTu7q79+/erefPmkv5YXn73HWZJ8vPzk42NjVJSUhQSEvJgbi4PDRs21MmTJ+Xt7f1A+92zZ4/Cw8PVpUsXSX+8431347a84rh06ZJKlChhWvoOAAAA4OErctK9bt06vfzyy+rdu7eOHj2qjIwMSX+8vztz5kxt3rz5gQeJx5OTk5P69eunMWPGqGzZsnJzc9PkyZNlZWUlg8EgHx8f9e7dW3379lVMTIwaNGign3/+Wbt27ZK/v786dOhQqHGGDx+uWbNmqWbNmvL19VVsbKyuXbtmFkdERIRGjhyp7OxsPfPMM0pPT9e+ffvk6Oiofv36PbB7njRpkp577jl5enrqpZdekpWVlb755hsdO3ZM06dPv+d+vb299cknn+j555+XwWDQxIkTTbPguQkNDVXTpk3VuXNnzZ49W7Vq1dLFixe1efNmde7c+b6X0QMAAAAonCLvXj59+nS98847Wrp0qdly2KefftpsV2pAkmJjY9W0aVM999xzCg0NVXBwsHx9fU1LrZcvX66+fftq9OjRqlWrll544QUdOHCgSO8Sjx49Wn379lV4eLiaNm0qJycn04zwXdOmTdOkSZMUHR0tX19ftW3bVhs3blS1atUe6P22bdtWmzZt0vbt2xUUFKQmTZooNjZWVatWva9+33rrLZUpU0ZPP/20nn/+ebVt29Y0k58bg8GgzZs3q3nz5howYIB8fHzUs2dPXbhwwfQOOQAAAADLK/Lu5fb29jpx4oS8vLzk5OSkr7/+WtWrV9e5c+fk5+en33//3VKx4glw8+ZNeXh4KCYmRgMHDizucJCPu7sxsns5AAAAkFNhdy8v8ky3u7u7zpw5k6N87969ql69elG7wxPu6NGj+uijj3T27FkdOXJEvXv/kewU9rNcAAAAAPA4K3LS/Y9//EPDhw/XgQMHZDAYdPHiRa1atUoRERF67bXXLBEjHnNz585V/fr1FRoaqps3b2rPnj0qV65ccYdVoDp16sjR0THXY9WqVcUdHgAAAIDHQKE2Uvvmm29Ut25dWVlZKTIyUmlpaWrZsqV+//13NW/eXDY2NoqIiNDQoUMtHS8eMw0aNFBiYmJxh3FPNm/erDt37uR6jfeiAQAAABRGoZLuBg0aKDU1VW5ubqpevboOHTqkf/3rX0pOTlZ2drb8/PzMvqsMPAnud/MzAAAAAChU0l26dGmdP39ebm5uunDhgrKzs+Xg4MBnhwAAAAAAyEehku5u3bopJCRE7u7uMhgMCgwMlLW1da51z50790ADBFC8/tu5R767MQIAAADIW6GS7nfffVddu3bVmTNnNGzYMA0ePFhOTk6Wjg0AAAAAgMdaoZJuSWrXrp0kKTExUcOHDyfpBgAAAACgAIVOuu9avny5JeIAAAAAAOCJU+TvdAMAAAAAgMIh6QYAAAAAwEKKvLwcwN9L9/UbVNLevrjDKJKNL3Yt7hAAAAAAScx0AwAAAABgMSTdAAAAAABYCEk3AAAAAAAWQtINAAAAAICFkHQDAAAAAGAhJN0AAAAAAFgISTfwCPPy8tK8efNM5waDQevXry9U26ioKAUEBFgkLgAAAACFw3e6gcdIamqqypQpU9xhAAAAACgkkm7gHt25c0clS5Z8qGNWrFjxoY4HAAAA4P6wvBx/K2vXrpW/v7/s7Ozk6uqq0NBQ3bx5U5K0fPly+fr6ytbWVrVr19aiRYtM7S5cuCCDwaA1a9aoRYsWsrW11QcffKC4uDiVLl1a69evl4+Pj2xtbdWmTRv98MMPhY5pw4YNCgwMlK2trcqVK6euXbvmWfevy8t//PFH9ezZU2XLlpWDg4MCAwN14MCBXNueP39e3t7eevXVV5WdnV3o+AAAAADcO5Ju/G2kpqYqLCxMAwYMUHJysuLj49W1a1cZjUYtXbpU48eP14wZM5ScnKyZM2dq4sSJWrFihVkfY8eO1bBhw5ScnKy2bdtKkm7duqUZM2ZoxYoVSkhIUHp6unr27FmomD777DN17dpVHTt21NGjR7Vz504FBgYWqu2NGzcUEhKiixcvasOGDfr6668VGRmZa0L97bffKjg4WC+99JIWL14sK6ucf/UzMjKUnp5udgAAAAC4Pywvx99GamqqMjMz1bVrV1WtWlWS5O/vL0maNm2aYmJiTLPM1apV04kTJ7RkyRL169fP1MeIESNyzETfuXNHCxcu1FNPPSVJWrFihXx9fXXw4EE1btw435hmzJihnj17asqUKaay+vXrF+p+PvzwQ125ckWHDh1S2bJlJUne3t456n311Vd67rnnNG7cOEVEROTZX3R0tFkcAAAAAO4fM93426hfv75at24tf39/vfTSS1q6dKmuXr2qK1eu6IcfftDAgQPl6OhoOqZPn66zZ8+a9ZHbLHSJEiXMymvXrq3SpUsrOTm5wJiSkpLUunXre7qfpKQkNWjQwJRw5yYlJUWhoaGaMGFCvgm3JI0bN05paWmmoyhL5AEAAADkjplu/G1YW1tr+/bt2rdvn7Zt26a3335b48eP18aNGyVJS5cuNc1W/7nNnzk4OOTat8FgKFTZX9nZ2RU2/HtqW758eVWqVEmrV6/WwIED5ezsnGddGxsb2djY3HM8AAAAAHJipht/KwaDQcHBwZoyZYqOHj2qUqVKKSEhQR4eHjp37py8vb3NjmrVqhXYZ2Zmpg4fPmw6P3nypK5du6batWsX2LZevXrauXPnPd1LvXr1lJSUpF9//TXPOnZ2dtq0aZNsbW3Vtm1bXb9+/Z7GAgAAAHBvSLrxt3HgwAHNnDlThw8fVkpKij755BNduXJFvr6+ioqKUnR0tObPn69Tp07p2LFjWr58uWJjYwvst2TJknr99dd14MABHTlyRP3791eTJk0KfJ9bkiZPnqyPPvpIkydPVnJyso4dO6Y5c+YU6n7CwsJUsWJFde7cWQkJCTp37pzWrVunr776yqyeg4ODPvvsM5UoUULt27fXjRs3CtU/AAAAgPtH0o2/DWdnZ+3evVsdOnSQj4+PJkyYoJiYGLVv316DBg3Se++9p7i4OPn7+yskJERxcXGFmum2t7fX2LFj1atXLzVt2lR2dnZavXp1oWJq0aKF/vvf/2rDhg0KCAhQq1at8vzk11+VKlVK27Ztk5ubmzp06CB/f3/NmjUrx5J4SXJ0dNSWLVtkNBrVoUMH02fSAAAAAFiWwWg0Gos7COBxFRcXpxEjRujatWvFHcoDl56eLhcXF7VdsVIl7e2LO5wi2fhi3t86BwAAAB6Eu/9eTktLy3fvJGa6AQAAAACwEJJuwILq1Klj9hmyPx+rVq0q7vAAAAAAWBifDAPuQ3h4uMLDw/O8vnnzZt25cyfXaxUqVLBQVAAAAAAeFSTdgAVVrVq1uEMAAAAAUIxYXg4AAAAAgIUw0w0gX2s6v5DvbowAAAAA8sZMNwAAAAAAFkLSDQAAAACAhZB0AwAAAABgISTdAAAAAABYCEk3AAAAAAAWwu7lAPLVc/12lbR3KO4wcvV/L7Yr7hAAAACAfDHTDQAAAACAhZB0AwAAAABgISTdAAAAAABYCEk3AAAAAAAWQtINAAAAAICFkHQDAAAAAGAhJN0AAAAAAFgISTcea3FxcSpdurTF+jcYDFq/fr0k6cKFCzIYDEpKSipU2/DwcHXu3NlisQEAAAB49JUo7gCAx4Wnp6dSU1NVrly54g4FAAAAwGOCmW48su7cuVPcIZixtrZWxYoVVaIEv6sCAAAAUDgk3SiStWvXyt/fX3Z2dnJ1dVVoaKhu3rwpSVq+fLl8fX1la2ur2rVra9GiRWZtx44dKx8fH9nb26t69eqaOHGiWWIdFRWlgIAALVu2TNWrV5eNjY2MRqOuXbumIUOGqEKFCrK1tVXdunW1adMms763bt0qX19fOTo6ql27dkpNTS30PS1btkx16tSRjY2N3N3dNXTo0Fzr5ba8/Pjx4+rYsaOcnZ3l5OSkZs2a6ezZs7m2T0xMlJubm2bMmCFJ+vrrr9WyZUs5OTnJ2dlZjRo10uHDhwsV89KlS+Xp6Sl7e3t16dJFsbGxOZbZT58+XW5ubnJyctKgQYP0xhtvKCAgIM8+MzIylJ6ebnYAAAAAuD9M2aHQUlNTFRYWpjlz5qhLly66fv269uzZI6PRqKVLl2ry5MlauHChGjRooKNHj2rw4MFycHBQv379JElOTk6Ki4tTpUqVdOzYMQ0ePFhOTk6KjIw0jXHmzBmtWbNG69atk7W1tbKzs9W+fXtdv35dH3zwgWrUqKETJ07I2tra1ObWrVuaO3euVq5cKSsrK/Xp00cRERFatWpVgfe0ePFijRo1SrNmzVL79u2VlpamhISEQj2Pn376Sc2bN1eLFi20a9cuOTs7KyEhQZmZmTnqxsfHq3PnzoqOjtarr74qSerdu7caNGigxYsXy9raWklJSSpZsmSB4yYkJOiVV17R7Nmz9cILL2jHjh2aOHGiWZ1Vq1ZpxowZWrRokYKDg7V69WrFxMSoWrVqefYbHR2tKVOmFOreAQAAABSOwWg0Gos7CDwejhw5okaNGunChQuqWrWq2bUqVapo9uzZCgsLM5VNnz5dmzdv1r59+3Lt780339THH39smt2NiorSzJkz9dNPP6l8+fKSpG3btql9+/ZKTk6Wj49Pjj7i4uLUv39/nTlzRjVq1JAkLVq0SFOnTtWlS5cKvCcPDw/1799f06dPz/W6wWDQp59+qs6dO+vChQuqVq2ajh49qoCAAP3rX//S6tWrdfLkyVyT5fDwcF27dk39+/fXyy+/rCVLlpg9H2dnZ7399tumX0oUVs+ePXXjxg2z2f4+ffpo06ZNunbtmiSpSZMmCgwM1MKFC011nnnmGd24cSPPjeAyMjKUkZFhOk9PT5enp6far1irkvYORYrxYfm/F9sVdwgAAAD4m0pPT5eLi4vS0tLk7OycZz2Wl6PQ6tevr9atW8vf318vvfSSli5dqqtXr+rKlSv64YcfNHDgQDk6OpqO6dOnmy21Xrt2rZ555hlVrFhRjo6OmjhxolJSUszGqFq1qinhlqSkpCRVrlw514T7Lnt7e1PCLUnu7u66fPlygfdz+fJlXbx4Ua1bty7KYzCLrVmzZvnOTh84cEDdunXTihUrzBJuSRo1apQGDRqk0NBQzZo1K89l6X918uRJNW7c2Kzsr+eFqfNXNjY2cnZ2NjsAAAAA3B+SbhSatbW1tm/fri1btsjPz09vv/22atWqpXPnzkn64z3jpKQk0/Htt99q//79kqT9+/erZ8+eat++vTZt2qSjR49q/Pjxun37ttkYDg7mM6p2dnYFxvXXpNdgMKgwCzgK0/f9tq9Ro4Zq166tZcuW5bjXqKgo0zvhu3btkp+fnz799NMC+zQajTIYDDnK/qowdQAAAABYFkk3isRgMCg4OFhTpkzR0aNHVapUKSUkJMjDw0Pnzp2Tt7e32XH3HeKEhARVrVpV48ePV2BgoGrWrKnvv/++wPHq1aunH3/8UadOnXrg9+Lk5CQvLy/t3LnzntrXq1dPe/bsyXeX9XLlymnXrl06e/asevTokaOuj4+PRo4cqW3btqlr165avnx5gePWrl1bBw8eNCv76wZstWrVKrAOAAAAAMsj6UahHThwQDNnztThw4eVkpKiTz75RFeuXJGvr6+ioqIUHR2t+fPn69SpUzp27JiWL1+u2NhYSZK3t7dSUlK0evVqnT17VgsWLCjUrG5ISIiaN2+ubt26afv27Tp//ry2bNmizz///IHcU1RUlGJiYrRgwQKdPn1aR44c0dtvv12otkOHDlV6erp69uypw4cP6/Tp01q5cqVOnjxpVs/NzU27du3Sd999p7CwMGVmZuq3337T0KFDFR8fr++//14JCQk6dOiQfH19Cxz39ddf1+bNmxUbG6vTp09ryZIl2rJli9nM9uuvv673339fK1as0OnTpzV9+nR98803OWa/AQAAAFgWSTcKzdnZWbt371aHDh3k4+OjCRMmKCYmRu3bt9egQYP03nvvKS4uTv7+/goJCVFcXJxpprtTp04aOXKkhg4dqoCAAO3bty/Hjtt5WbdunYKCghQWFiY/Pz9FRkYqKyvrgdxTv379NG/ePC1atEh16tTRc889p9OnTxeqraurq3bt2qUbN24oJCREjRo10tKlS3N9x7tixYratWuXjh07pt69e8vKykq//PKL+vbtKx8fH3Xv3l3t27cv1O7hwcHBeueddxQbG6v69evr888/18iRI2Vra2uq07t3b40bN04RERFq2LChzp8/r/DwcLM6AAAAACyP3cuBJ8DgwYP13Xffac+ePXnWadOmjSpWrKiVK1cWqs+7uzGyezkAAACQU2F3L+c73cBjaO7cuWrTpo0cHBy0ZcsWrVixQosWLTJdv3Xrlt555x21bdtW1tbW+uijj7Rjxw5t3769GKMGAAAA/n5YXo4n2p8/YfbXI79Z4eLUvn37PGOeOXOmJOngwYNq06aN/P399c4772jBggUaNGiQqQ+DwaDNmzerWbNmatSokTZu3Kh169YpNDS0uG4LAAAA+FtiphtPtKSkpDyveXh4PLxAiuC9997Tb7/9luu1smXLSpLWrFmTbx92dnbasWPHA48NAAAAQNGQdOOJ5u3tXdwhFNmj+ssAAAAAAEVH0g0gX6s7t8l3YwgAAAAAeeOdbgAAAAAALISkGwAAAAAACyHpBgAAAADAQki6AQAAAACwEJJuAAAAAAAshN3LAeSr1/99pZL2DsUdRg6fdnumuEMAAAAACsRMNwAAAAAAFkLSDQAAAACAhZB0AwAAAABgISTdAAAAAABYCEk3AAAAAAAWQtINAAAAAICFkHQDAAAAAGAhJN342zIYDFq/fn1xhwEAAADgCUbSjcdafHy8DAaDrl27VtyhPLL45QIAAABQfEi6AQAAAACwEJJuWMx//vMfubq6KiMjw6y8W7du6tu3ryRp8eLFqlGjhkqVKqVatWpp5cqVpnoXLlyQwWBQUlKSqezatWsyGAyKj4/XhQsX1LJlS0lSmTJlZDAYFB4eLkny8vLSvHnzzMYNCAhQVFSUWVlqaqrat28vOzs7VatWTf/973/Nrv/000/q0aOHypQpI1dXV3Xq1EkXLlwo9DNYtmyZ6tSpIxsbG7m7u2vo0KGmaykpKerUqZMcHR3l7Oys7t2763//+5/penh4uDp37mzW34gRI9SiRQvTeYsWLTRs2DBFRkaqbNmyqlixotk9enl5SZK6dOkig8FgOs9NRkaG0tPTzQ4AAAAA94ekGxbz0ksvKSsrSxs2bDCV/fzzz9q0aZP69++vTz/9VMOHD9fo0aP17bff6h//+If69++vL774olD9e3p6at26dZKkkydPKjU1VfPnzy9SjBMnTlS3bt309ddfq0+fPgoLC1NycrIk6datW2rZsqUcHR21e/du7d27V46OjmrXrp1u375dYN+LFy/WP//5Tw0ZMkTHjh3Thg0b5O3tLUkyGo3q3Lmzfv31V3355Zfavn27zp49qx49ehQpfklasWKFHBwcdODAAc2ZM0dTp07V9u3bJUmHDh2SJC1fvlypqamm89xER0fLxcXFdHh6ehY5FgAAAADmShR3AHhy2dnZqVevXlq+fLleeuklSdKqVatUuXJltWjRQs8884zCw8P12muvSZJGjRql/fv3a+7cuaYZ7PxYW1urbNmykiQ3NzeVLl26yDG+9NJLGjRokCRp2rRp2r59u95++20tWrRIq1evlpWVld577z0ZDAZJfySvpUuXVnx8vJ599tl8+54+fbpGjx6t4cOHm8qCgoIkSTt27NA333yj8+fPm5LblStXqk6dOjp06JCpXmHUq1dPkydPliTVrFlTCxcu1M6dO9WmTRuVL19eklS6dGlVrFgx337GjRunUaNGmc7T09NJvAEAAID7xEw3LGrw4MHatm2bfvrpJ0l/JK3h4eEyGAxKTk5WcHCwWf3g4GDTTPPD0LRp0xznd8dPTEzUmTNn5OTkJEdHRzk6Oqps2bL6/fffdfbs2Xz7vXz5si5evKjWrVvnej05OVmenp5mSa2fn59Kly5d5PuvV6+e2bm7u7suX75cpD4kycbGRs7OzmYHAAAAgPvDTDcsqkGDBqpfv77+85//qG3btjp27Jg2btxoun53Bvkuo9FoKrOysjKV3XXnzp1CjWtlZWXWriht746fnZ2tRo0aadWqVTnq3J1BzoudnV2+1/98n3mVF/YeSpYsmSP+7OzsfMcHAAAA8HAw0w2LGzRokJYvX65ly5YpNDTUNLvr6+urvXv3mtXdt2+ffH19Jf3/iW1qaqrp+p83VZOkUqVKSZKysrLMysuXL2/WLj09XefPn88R2/79+3Oc165dW5LUsGFDnT59Wm5ubvL29jY7XFxc8r1nJycneXl5aefOnble9/PzU0pKin744QdT2YkTJ5SWlmZ2/3++Bynn/RdGyZIlczwfAAAAAA8HSTcsrnfv3vrpp5+0dOlSDRgwwFQ+ZswYxcXF6Z133tHp06cVGxurTz75RBEREZL+mC1u0qSJZs2apRMnTmj37t2aMGGCWd9Vq1aVwWDQpk2bdOXKFd24cUOS1KpVK61cuVJ79uzRt99+q379+sna2jpHbP/973+1bNkynTp1SpMnT9bBgwdNO4z37t1b5cqVU6dOnbRnzx6dP39eX375pYYPH64ff/yxwPuOiopSTEyMFixYoNOnT+vIkSN6++23JUmhoaGqV6+eevfurSNHjujgwYPq27evQkJCFBgYaLqHw4cP6z//+Y9Onz6tyZMn69tvvy3y87+b/F+6dElXr14tcnsAAAAA946kGxbn7Oysbt26ydHR0ewTWJ07d9b8+fP15ptvqk6dOlqyZImWL19u9kmsZcuW6c6dOwoMDNTw4cM1ffp0s749PDw0ZcoUvfHGG6pQoYIpYR43bpyaN2+u5557Th06dFDnzp1Vo0aNHLFNmTJFq1evVr169bRixQqtWrVKfn5+kiR7e3vt3r1bVapUUdeuXeXr66sBAwbot99+K9T7zv369dO8efO0aNEi1alTR88995xOnz4t6Y8l4OvXr1eZMmXUvHlzhYaGqnr16vr4449N7du2bauJEycqMjJSQUFBun79uulTa0URExOj7du3y9PTUw0aNChyewAAAAD3zmD860ujgAW0adNGvr6+WrBgQXGHgkJKT0+Xi4uLOv7nc5W0dyjucHL4tNszxR0CAAAA/sbu/ns5LS0t30k5NlKDRf3666/atm2bdu3apYULFxZ3OAAAAADwUJF0w6IaNmyoq1evavbs2apVq1Zxh/NAOTo65nlty5Ytatas2UOMBgAAAMCjiKQbFnXhwoXiDsFi8ttJ3MPD4+EFAgAAAOCRRdIN3CNvb+/iDgEAAADAI46kG0C+PuzUtFC7tQMAAADIiU+GAQAAAABgISTdAAAAAABYCEk3AAAAAAAWQtINAAAAAICFkHQDAAAAAGAh7F4OIF99/+9blbR3LNYY/tutXrGODwAAANwrZroBAAAAALAQkm4AAAAAACyEpBsAAAAAAAsh6QYAAAAAwEJIugEAAAAAsBCSbgAAAAAALISkGwAAAAAACyHpxkPRokULjRgxorjDeCTExcWpdOnSxR0GAAAAgIeApBsPVHx8vAwGg65du1bcoQAAAABAsSPpxmPrzp07xR1CDo9iTAAAAACKD0k3iiwjI0PDhg2Tm5ubbG1t9cwzz+jQoUO6cOGCWrZsKUkqU6aMDAaDwsPDTe2ys7MVGRmpsmXLqmLFioqKijLrNy0tTUOGDJGbm5ucnZ3VqlUrff3116brUVFRCggI0LJly1S9enXZ2NjIaDTmG+vatWvl7+8vOzs7ubq6KjQ0VDdv3jRdX758uXx9fWVra6vatWtr0aJFZu3Hjh0rHx8f2dvbq3r16po4caJZYp1XTNeuXdOQIUNUoUIF2draqm7dutq0aZNZ31u3bpWvr68cHR3Vrl07paamFur5Z2ZmatiwYSpdurRcXV01duxY9evXT507dzbVuX79unr37i0HBwe5u7vrrbfeKnCJf0ZGhtLT080OAAAAAPeHpBtFFhkZqXXr1mnFihU6cuSIvL291bZtWzk5OWndunWSpJMnTyo1NVXz5883tVuxYoUcHBx04MABzZkzR1OnTtX27dslSUajUR07dtSlS5e0efNmJSYmqmHDhmrdurV+/fVXUx9nzpzRmjVrtG7dOiUlJeUbZ2pqqsLCwjRgwAAlJycrPj5eXbt2NSXqS5cu1fjx4zVjxgwlJydr5syZmjhxolasWGHqw8nJSXFxcTpx4oTmz5+vpUuX6q233jIb568xZWdnq3379tq3b58++OADnThxQrNmzZK1tbWpza1btzR37lytXLlSu3fvVkpKiiIiIgr1/GfPnq1Vq1Zp+fLlSkhIUHp6utavX29WZ9SoUUpISNCGDRu0fft27dmzR0eOHMm33+joaLm4uJgOT0/PQsUDAAAAIG8GY0FThcCf3Lx5U2XKlFFcXJx69eol6Y8l1V5eXhoxYoSCgoLUsmVLXb161WyzsBYtWigrK0t79uwxlTVu3FitWrXSrFmztGvXLnXp0kWXL1+WjY2NqY63t7ciIyM1ZMgQRUVFaebMmfrpp59Uvnz5AmM9cuSIGjVqpAsXLqhq1ao5rlepUkWzZ89WWFiYqWz69OnavHmz9u3bl2ufb775pj7++GMdPnxYknKNadu2bWrfvr2Sk5Pl4+OTo4+4uDj1799fZ86cUY0aNSRJixYt0tSpU3Xp0qUC76tixYqKiIgwJelZWVmqXr26GjRooPXr1+v69etydXXVhx9+qBdffFHSH6sIKlWqpMGDB2vevHm59puRkaGMjAzTeXp6ujw9PdXpPwkqae9YYFyW9N9u9Yp1fAAAAOCv0tPT5eLiorS0NDk7O+dZr8RDjAlPgLNnz+rOnTsKDg42lZUsWVKNGzdWcnKygoKC8mxbr5554uTu7q7Lly9LkhITE3Xjxg25urqa1fntt9909uxZ03nVqlULlXBLUv369dW6dWv5+/urbdu2evbZZ/Xiiy+qTJkyunLlin744QcNHDhQgwcPNrXJzMyUi4uL6Xzt2rWaN2+ezpw5oxs3bigzMzPHX6i/xpSUlKTKlSvnmnDfZW9vb0q4//os8pOWlqb//e9/aty4sanM2tpajRo1UnZ2tiTp3LlzunPnjlkdFxcX1apVK9++bWxszH7hAQAAAOD+kXSjSO4ujDAYDDnK/1r2VyVLljQ7NxgMpkQxOztb7u7uio+Pz9HuzzPmDg4OhY7V2tpa27dv1759+7Rt2za9/fbbGj9+vA4cOCB7e3tJfywxf+qpp3K0k6T9+/erZ8+emjJlitq2bSsXFxetXr1aMTExZvX/GpOdnV2BseX2LIqy6CS35//Xn/OrAwAAAODh4J1uFIm3t7dKlSqlvXv3msru3Lmjw4cPy9fXV6VKlZL0x5LnomjYsKEuXbqkEiVKyNvb2+woV67cPcdrMBgUHBysKVOm6OjRoypVqpQ+/fRTVahQQR4eHjp37lyO8apVqyZJSkhIUNWqVTV+/HgFBgaqZs2a+v777wscs169evrxxx916tSpe447Ly4uLqpQoYIOHjxoKsvKytLRo0dN5zVq1FDJkiXN6qSnp+v06dMPPB4AAAAA+WOmG0Xi4OCgV199VWPGjFHZsmVVpUoVzZkzR7du3dLAgQN169YtGQwGbdq0SR06dJCdnZ0cHQt+Hzg0NFRNmzZV586dNXv2bNWqVUsXL17U5s2b1blzZwUGBhY51gMHDmjnzp169tln5ebmpgMHDujKlSvy9fWV9Mf72MOGDZOzs7Pat2+vjIwMHT58WFevXtWoUaPk7e2tlJQUrV69WkFBQfrss8/06aefFjhuSEiImjdvrm7duik2Nlbe3t767rvvZDAY1K5duyLfx1+9/vrrio6Olre3t2rXrq23335bV69eNc1sOzk5qV+/fqY/Izc3N02ePFlWVlYFrkYAAAAA8GAx040imzVrlrp166aXX35ZDRs21JkzZ7R161aVKVNGHh4emjJlit544w1VqFBBQ4cOLVSfBoNBmzdvVvPmzTVgwAD5+PioZ8+eunDhgipUqHBPcTo7O2v37t3q0KGDfHx8NGHCBMXExKh9+/aSpEGDBum9995TXFyc/P39FRISori4ONNMd6dOnTRy5EgNHTpUAQEB2rdvnyZOnFiosdetW6egoCCFhYXJz89PkZGRRZ79z8vYsWMVFhamvn37qmnTpnJ0dFTbtm1la2trqhMbG6umTZvqueeeU2hoqIKDg02fRgMAAADw8LB7OfCYy87Olq+vr7p3765p06blWufmzZvy8PBQTEyMBg4cWKh+7+7GyO7lAAAAQE7sXg48ob7//ntt27ZNISEhysjI0MKFC3X+/HnTJ9wk6ejRo/ruu+/UuHFjpaWlaerUqZL+mL0HAAAA8PCQdOOxlZKSIj8/vzyvnzhxQlWqVHmIET0Y+b0Dv2XLFnl5eSkuLk4REREyGo2qW7euduzYYXpX/a65c+fq5MmTKlWqlBo1aqQ9e/bc16Z0AAAAAIqOpBuPrUqVKikpKSnf64+j/O7Jw8NDdnZ2SkhIyLePBg0aKDEx8QFHBgAAAKCoSLrx2Lr7ebEnzZN4TwAAAMDfFbuXAwAAAABgIcx0A8jXfzrVzXc3RgAAAAB5Y6YbAAAAAAALIekGAAAAAMBCSLoBAAAAALAQkm4AAAAAACyEpBsAAAAAAAth93IA+Yrc+KNK2Ts90D4XdPF8oP0BAAAAjypmugEAAAAAsBCSbgAAAAAALISkGwAAAAAACyHpBgAAAADAQki6AQAAAACwEJJuAAAAAAAshKQbf2tRUVEKCAgoUhuDwaD169dbJB4AAAAATxaSbvytRUREaOfOncUdhkXdyy8WAAAAADwYJYo7AKA4OTo6ytHRsbjDAAAAAPCEYqYbj4W1a9fK399fdnZ2cnV1VWhoqG7evKns7GxNnTpVlStXlo2NjQICAvT555+btf3xxx/Vs2dPlS1bVg4ODgoMDNSBAwck5ZwFPnTokNq0aaNy5crJxcVFISEhOnLkyD3Hnd/YkrR48WLVqFFDpUqVUq1atbRy5UrTtQsXLshgMCgpKclUdu3aNRkMBsXHx0uS4uPjZTAYtHPnTgUGBsre3l5PP/20Tp48KUmKi4vTlClT9PXXX8tgMMhgMCguLu6e7wcAAABA0TDTjUdeamqqwsLCNGfOHHXp0kXXr1/Xnj17ZDQaNX/+fMXExGjJkiVq0KCBli1bphdeeEHHjx9XzZo1dePGDYWEhMjDw0MbNmxQxYoVdeTIEWVnZ+c61vXr19WvXz8tWLBAkhQTE6MOHTro9OnTcnJyKlLcBY396aefavjw4Zo3b55CQ0O1adMm9e/fX5UrV1bLli2LNNb48eMVExOj8uXL65VXXtGAAQOUkJCgHj166Ntvv9Xnn3+uHTt2SJJcXFxy7SMjI0MZGRmm8/T09CLFAAAAACAnkm488lJTU5WZmamuXbuqatWqkiR/f39J0ty5czV27Fj17NlTkjR79mx98cUXmjdvnv7973/rww8/1JUrV3To0CGVLVtWkuTt7Z3nWK1atTI7X7JkicqUKaMvv/xSzz33XJHiLmjsuXPnKjw8XK+99pokadSoUdq/f7/mzp1b5KR7xowZCgkJkSS98cYb6tixo37//XfZ2dnJ0dFRJUqUUMWKFfPtIzo6WlOmTCnSuAAAAADyx/JyPPLq16+v1q1by9/fXy+99JKWLl2qq1evKj09XRcvXlRwcLBZ/eDgYCUnJ0uSkpKS1KBBA1PSW5DLly/rlVdekY+Pj1xcXOTi4qIbN24oJSWlyHEXNHZycnK+sRdFvXr1TD+7u7tL+uNeimLcuHFKS0szHT/88EOR4wAAAABgjqQbjzxra2tt375dW7ZskZ+fn95++23VqlVL58+fl/THJ7z+zGg0msrs7OyKNFZ4eLgSExM1b9487du3T0lJSXJ1ddXt27eLHHdhxs4vdisrK1PZXXfu3Mm1n5IlS+boM68l9HmxsbGRs7Oz2QEAAADg/pB047FgMBgUHBysKVOm6OjRoypVqpR27typSpUqae/evWZ19+3bJ19fX0l/zAAnJSXp119/LdQ4e/bs0bBhw9ShQwfVqVNHNjY2+vnnn+8p5oLG9vX1zTf28uXLS/pjef1df95UrbBKlSqlrKysIrcDAAAAcP94pxuPvAMHDmjnzp169tln5ebmpgMHDujKlSvy9fXVmDFjNHnyZNWoUUMBAQFavny5kpKStGrVKklSWFiYZs6cqc6dOys6Olru7u46evSoKlWqpKZNm+YYy9vbWytXrlRgYKDS09M1ZsyYIs+W31XQ2GPGjFH37t3VsGFDtW7dWhs3btQnn3xi2vDMzs5OTZo00axZs+Tl5aWff/5ZEyZMKHIcXl5eOn/+vJKSklS5cmU5OTnJxsbmnu4JAAAAQNEw041HnrOzs3bv3q0OHTrIx8dHEyZMUExMjNq3b69hw4Zp9OjRGj16tPz9/fX5559rw4YNqlmzpqQ/Znm3bdsmNzc3dejQQf7+/po1a5asra1zHWvZsmW6evWqGjRooJdfflnDhg2Tm5vbPcVd0NidO3fW/Pnz9eabb6pOnTpasmSJli9frhYtWpjFc+fOHQUGBmr48OGaPn16kePo1q2b2rVrp5YtW6p8+fL66KOP7ul+AAAAABSdwfjnF0YB4P9JT0+Xi4uL/vHBcZWyL9rn0gqyoIvnA+0PAAAAeNju/ns5LS0t3/2QmOkGAAAAAMBCSLqBezRz5kw5OjrmerRv3764wwMAAADwCGAjNeAevfLKK+revXuu1+518zUAAAAATxaSbuAelS1bVmXLli3uMAAAAAA8wlheDgAAAACAhTDTDSBfc56vnO9ujAAAAADyxkw3AAAAAAAWQtINAAAAAICFkHQDAAAAAGAhJN0AAAAAAFgISTcAAAAAABbC7uUA8vXuxsuys//tgfX3zy4VHlhfAAAAwKOOmW4AAAAAACyEpBsAAAAAAAsh6QYAAAAAwEJIugEAAAAAsBCSbgAAAAAALISkGwAAAAAACyHpBgAAAADAQki68cRo0aKFRowYUdxhPBLi4uJUunTp4g4DAAAA+Nsj6cZjJz4+XgaDQdeuXSvuUAAAAAAgXyTdQD7u3LlT3CHk8CjGBAAAACB3JN14JGVkZGjYsGFyc3OTra2tnnnmGR06dEgXLlxQy5YtJUllypSRwWBQeHi4qV12drYiIyNVtmxZVaxYUVFRUWb9pqWlaciQIXJzc5Ozs7NatWqlr7/+2nQ9KipKAQEBWrZsmapXry4bGxsZjcZ8Y127dq38/f1lZ2cnV1dXhYaG6ubNm6bry5cvl6+vr2xtbVW7dm0tWrTIrP3YsWPl4+Mje3t7Va9eXRMnTjRLrPOK6dq1axoyZIgqVKggW1tb1a1bV5s2bTLre+vWrfL19ZWjo6PatWun1NTUfJ95enq62QEAAADg/pQo7gCA3ERGRmrdunVasWKFqlatqjlz5qht27Y6ffq01q1bp27duunkyZNydnaWnZ2dqd2KFSs0atQoHThwQF999ZXCw8MVHBysNm3ayGg0qmPHjipbtqw2b94sFxcXLVmyRK1bt9apU6dUtmxZSdKZM2e0Zs0arVu3TtbW1vnGmZqaqrCwMM2ZM0ddunTR9evXtWfPHlOivnTpUk2ePFkLFy5UgwYNdPToUQ0ePFgODg7q16+fJMnJyUlxcXGqVKmSjh07psGDB8vJyUmRkZGmcf4aU3Z2ttq3b6/r16/rgw8+UI0aNXTixAmzeG/duqW5c+dq5cqVsrKyUp8+fRQREaFVq1blei/R0dGaMmXKvf2BAQAAAMiVwVjQNB7wkN28eVNlypRRXFycevXqJemPJdVeXl4aMWKEgoKC1LJlS129etVss7AWLVooKytLe/bsMZU1btxYrVq10qxZs7Rr1y516dJFly9flo2NjamOt7e3IiMjNWTIEEVFRWnmzJn66aefVL58+QJjPXLkiBo1aqQLFy6oatWqOa5XqVJFs2fPVlhYmKls+vTp2rx5s/bt25drn2+++aY+/vhjHT58WJJyjWnbtm1q3769kpOT5ePjk6OPuLg49e/fX2fOnFGNGjUkSYsWLdLUqVN16dKlXMfNyMhQRkaG6Tw9PV2enp5684PTsrN3KvBZFNY/u1R4YH0BAAAAxSU9PV0uLi5KS0uTs7NznvWY6cYj5+zZs7pz546Cg4NNZSVLllTjxo2VnJysoKCgPNvWq1fP7Nzd3V2XL1+WJCUmJurGjRtydXU1q/Pbb7/p7NmzpvOqVasWKuGWpPr166t169by9/dX27Zt9eyzz+rFF19UmTJldOXKFf3www8aOHCgBg8ebGqTmZkpFxcX0/natWs1b948nTlzRjdu3FBmZmaOv7R/jSkpKUmVK1fONeG+y97e3pRw//VZ5MbGxsbslxEAAAAA7h9JNx45dxdfGAyGHOV/LfurkiVLmp0bDAZlZ2dL+uN9b3d3d8XHx+do9+cZcwcHh0LHam1tre3bt2vfvn3atm2b3n77bY0fP14HDhyQvb29pD+WmD/11FM52knS/v371bNnT02ZMkVt27aVi4uLVq9erZiYGLP6f43pz0vq85Lbs2BhCwAAAPBwsZEaHjne3t4qVaqU9u7dayq7c+eODh8+LF9fX5UqVUqSlJWVVaR+GzZsqEuXLqlEiRLy9vY2O8qVK3fP8RoMBgUHB2vKlCk6evSoSpUqpU8//VQVKlSQh4eHzp07l2O8atWqSZISEhJUtWpVjR8/XoGBgapZs6a+//77AsesV6+efvzxR506deqe4wYAAABgecx045Hj4OCgV199VWPGjFHZsmVVpUoVzZkzR7du3dLAgQN169YtGQwGbdq0SR06dJCdnZ0cHR0L7Dc0NFRNmzZV586dNXv2bNWqVUsXL17U5s2b1blzZwUGBhY51gMHDmjnzp169tln5ebmpgMHDujKlSvy9fWV9Mf72MOGDZOzs7Pat2+vjIwMHT58WFevXtWoUaPk7e2tlJQUrV69WkFBQfrss8/06aefFjhuSEiImjdvrm7duik2Nlbe3t767rvvZDAY1K5duyLfBwAAAADLYKYbj6RZs2apW7duevnll9WwYUOdOXNGW7duVZkyZeTh4aEpU6bojTfeUIUKFTR06NBC9WkwGLR582Y1b95cAwYMkI+Pj3r27KkLFy6oQoV729zL2dlZu3fvVocOHeTj46MJEyYoJiZG7du3lyQNGjRI7733nuLi4uTv76+QkBDFxcWZZro7deqkkSNHaujQoQoICNC+ffs0ceLEQo29bt06BQUFKSwsTH5+foqMjCzy7D8AAAAAy2L3cgC5ursbI7uXAwAAADkVdvdyZroBAAAAALAQkm4gHykpKXJ0dMzzSElJKe4QAQAAADzC2EgNyEelSpWUlJSU73UAAAAAyAtJN5CPu58XAwAAAIB7QdINIF9DnnfLd2MIAAAAAHnjnW4AAAAAACyEpBsAAAAAAAsh6QYAAAAAwEJIugEAAAAAsBCSbgAAAAAALITdywHka8P6X2Rvf/uB9df1xXIPrC8AAADgUcdMNwAAAAAAFkLSDQAAAACAhZB0AwAAAABgISTdAAAAAABYCEk3AAAAAAAWQtINAAAAAICFkHQDAAAAAGAhJN3A/xMeHq7OnTsXdxj3JC4uTqVLly7uMAAAAAD8BUk3AAAAAAAWQtINPCBGo1GZmZnFHQYAAACARwhJNx45169fV+/eveXg4CB3d3e99dZbatGihUaMGCFJun37tiIjI+Xh4SEHBwc99dRTio+PN7W/u9R669at8vX1laOjo9q1a6fU1FRTnaysLI0aNUqlS5eWq6urIiMjZTQazeIwGo2aM2eOqlevLjs7O9WvX19r1641XY+Pj5fBYNDWrVsVGBgoGxsb7dmzJ997i4qKUkBAgJYtW6YqVarI0dFRr776qrKysjRnzhxVrFhRbm5umjFjhlm72NhY+fv7y8HBQZ6ennrttdd048aNfMfauHGjGjVqJFtbW1WvXl1TpkzJ95cCGRkZSk9PNzsAAAAA3B+SbjxyRo0apYSEBG3YsEHbt2/Xnj17dOTIEdP1/v37KyEhQatXr9Y333yjl156Se3atdPp06dNdW7duqW5c+dq5cqV2r17t1JSUhQREWG6HhMTo2XLlun999/X3r179euvv+rTTz81i2PChAlavny5Fi9erOPHj2vkyJHq06ePvvzyS7N6kZGRio6OVnJysurVq1fg/Z09e1ZbtmzR559/ro8++kjLli1Tx44d9eOPP+rLL7/U7NmzNWHCBO3fv9/UxsrKSgsWLNC3336rFStWaNeuXYqMjMxzjK1bt6pPnz4aNmyYTpw4oSVLliguLi5HMv9n0dHRcnFxMR2enp4F3gsAAACA/BmMf53eA4rR9evX5erqqg8//FAvvviiJCktLU2VKlXS4MGD9frrr6tmzZr68ccfValSJVO70NBQNW7cWDNnzlRcXJz69++vM2fOqEaNGpKkRYsWaerUqbp06ZIkqVKlSho+fLjGjh0rScrMzFS1atXUqFEjrV+/Xjdv3lS5cuW0a9cuNW3a1DTOoEGDdOvWLX344YeKj49Xy5YttX79enXq1KlQ9xcVFaU333xTly5dkpOTkySpXbt2OnnypM6ePSsrqz9+D1a7dm2Fh4frjTfeyLWf//73v3r11Vf1888/S/pjdn/EiBG6du2aJKl58+Zq3769xo0bZ2rzwQcfKDIyUhcvXsy1z4yMDGVkZJjO09PT5enpqZUrzsne3qlQ91cYXV8s98D6AgAAAIpLenq6XFxclJaWJmdn5zzrlXiIMQEFOnfunO7cuaPGjRubylxcXFSrVi1J0pEjR2Q0GuXj42PWLiMjQ66urqZze3t7U8ItSe7u7rp8+bKkP5L41NRUs2S6RIkSCgwMNC0xP3HihH7//Xe1adPGbJzbt2+rQYMGZmWBgYFFukcvLy9Twi1JFSpUkLW1tSnhvlt2N15J+uKLLzRz5kydOHFC6enpyszM1O+//66bN2/KwcEhxxiJiYk6dOiQ2cx2VlaWfv/9d926dUv29vY52tjY2MjGxqZI9wIAAAAgfyTdeKTcTXoNBkOu5dnZ2bK2tlZiYqKsra3N6jg6Opp+LlmypNk1g8GQ453t/GRnZ0uSPvvsM3l4eJhd+2timlvSm5/cYsut7G4M33//vTp06KBXXnlF06ZNU9myZbV3714NHDhQd+7cyTP+KVOmqGvXrjmu2draFileAAAAAPeOpBuPlBo1aqhkyZI6ePCg6Z3i9PR0nT59WiEhIWrQoIGysrJ0+fJlNWvW7J7GcHFxkbu7u/bv36/mzZtL+mN5eWJioho2bChJ8vPzk42NjVJSUhQSEvJgbu4eHT58WJmZmYqJiTHNhq9ZsybfNg0bNtTJkyfl7e39MEIEAAAAkAeSbjxSnJyc1K9fP40ZM0Zly5aVm5ubJk+eLCsrKxkMBvn4+Kh3797q27evYmJi1KBBA/3888/atWuX/P391aFDh0KNM3z4cM2aNUs1a9aUr6+vYmNjTe9D340jIiJCI0eOVHZ2tp555hmlp6dr3759cnR0VL9+/Sz0BHKqUaOGMjMz9fbbb+v5559XQkKC3nnnnXzbTJo0Sc8995w8PT310ksvycrKSt98842OHTum6dOnP6TIAQAAALB7OR45sbGxatq0qZ577jmFhoYqODhYvr6+pmXRy5cvV9++fTV69GjVqlVLL7zwgg4cOFCk3bZHjx6tvn37Kjw8XE2bNpWTk5O6dOliVmfatGmaNGmSoqOj5evrq7Zt22rjxo2qVq3aA73fggQEBCg2NlazZ89W3bp1tWrVKkVHR+fbpm3bttq0aZO2b9+uoKAgNWnSRLGxsapatepDihoAAACAxO7leAzcvHlTHh4eiomJ0cCBA4s7nL+Nu7sxsns5AAAAkBO7l+OxdfToUX333Xdq3Lix0tLSNHXqVEkq9Ge5AAAAAOBRwfJyPJLmzp2r+vXrKzQ0VDdv3tSePXtUrtyjP0Nap04dOTo65nqsWrWquMMDAAAA8JAx041HToMGDZSYmFjcYdyTzZs35/kZrwoVKjzkaAAAAAAUN5Ju4AFiozIAAAAAf0bSDSBfL3R2zXdjCAAAAAB5451uAAAAAAAshKQbAAAAAAALIekGAAAAAMBCSLoBAAAAALAQkm4AAAAAACyE3csB5Gv3xz/LwT7jvvpo2bv8A4oGAAAAeLww0w0AAAAAgIWQdAMAAAAAYCEk3QAAAAAAWAhJNwAAAAAAFkLSDQAAAACAhZB0AwAAAABgISTdAAAAAABYCEk3AAAAAAAWQtINWMDXX3+tsLAweXp6ys7OTr6+vpo/f75ZnQsXLshgMOQ4Pv/883z7/uSTTxQYGKjSpUvLwcFBAQEBWrlyZZ71o6OjZTAYNGLEiAdxawAAAACKoERxBwA8SLdv31apUqWKOwwlJiaqfPny+uCDD+Tp6al9+/ZpyJAhsra21tChQ83q7tixQ3Xq1DGdly1bNt++y5Ytq/Hjx6t27doqVaqUNm3apP79+8vNzU1t27Y1q3vo0CG9++67qlev3oO7OQAAAACFxkw38vT555/rmWeeUenSpeXq6qrnnntOZ8+eNV3ft2+fAgICZGtrq8DAQK1fv14Gg0FJSUmmOidOnFCHDh3k6OioChUq6OWXX9bPP/9cqPGvX7+u3r17y8HBQe7u7nrrrbfUokULsxlbLy8vTZ8+XeHh4XJxcdHgwYMlSevWrVOdOnVkY2MjLy8vxcTEmPVtMBi0fv16s7LSpUsrLi5O0v8/C7169Wo9/fTTsrW1VZ06dRQfH1+o2AcMGKAFCxYoJCRE1atXV58+fdS/f3998sknOeq6urqqYsWKpqOgXxq0aNFCXbp0ka+vr2rUqKHhw4erXr162rt3r1m9GzduqHfv3lq6dKnKlClTYMwZGRlKT083OwAAAADcH5Ju5OnmzZsaNWqUDh06pJ07d8rKykpdunRRdna2rl+/rueff17+/v46cuSIpk2bprFjx5q1T01NVUhIiAICAnT48GF9/vnn+t///qfu3bsXavxRo0YpISFBGzZs0Pbt27Vnzx4dOXIkR70333xTdevWVWJioiZOnKjExER1795dPXv21LFjxxQVFaWJEyeaEuqiGDNmjEaPHq2jR4/q6aef1gsvvKBffvmlyP1IUlpaWq6z2C+88ILc3NwUHBystWvXFqlPo9GonTt36uTJk2revLnZtX/+85/q2LGjQkNDC9VXdHS0XFxcTIenp2eRYgEAAACQE8vLkadu3bqZnb///vtyc3PTiRMntHfvXhkMBi1dulS2trby8/PTTz/9ZJpplqTFixerYcOGmjlzpqls2bJl8vT01KlTp+Tj45Pn2NevX9eKFSv04YcfqnXr1pKk5cuXq1KlSjnqtmrVShEREabz3r17q3Xr1po4caIkycfHRydOnNCbb76p8PDwIj2DoUOHmp7D4sWL9fnnn+v9999XZGRkkfr56quvtGbNGn322WemMkdHR8XGxio4OFhWVlbasGGDevTooRUrVqhPnz759peWliYPDw9lZGTI2tpaixYtUps2bUzXV69erSNHjujQoUOFjnHcuHEaNWqU6Tw9PZ3EGwAAALhPJN3I09mzZzVx4kTt379fP//8s7KzsyVJKSkpOnnypOrVqydbW1tT/caNG5u1T0xM1BdffCFHR8dc+84v6T537pzu3Llj1qeLi4tq1aqVo25gYKDZeXJysjp16mRWFhwcrHnz5ikrK0vW1tb53LW5pk2bmn4uUaKEAgMDlZycXOj2knT8+HF16tRJkyZNMkuMy5Urp5EjR5rdx9WrVzVnzhz16dNHKSkp8vPzM13/17/+pX/961+SJCcnJyUlJenGjRvauXOnRo0aperVq6tFixb64YcfNHz4cG3bts3sz6cgNjY2srGxKdK9AQAAAMgfSTfy9Pzzz8vT01NLly5VpUqVlJ2drbp16+r27dsyGo0yGAxm9Y1Go9l5dna2nn/+ec2ePTtH3+7u7vmOfbevgsaQJAcHhxx1CmpnMBhylN25cyffmP7ctrBOnDihVq1aafDgwZowYUKB9Zs0aaL33ntPklSpUiWz9+P/vDTdyspK3t7ekqSAgAAlJycrOjpaLVq0UGJioi5fvqxGjRqZ6mdlZWn37t1auHChaXYcAAAAgOWRdCNXv/zyi5KTk7VkyRI1a9ZMksw26qpdu7ZWrVqljIwM0+zo4cOHzfpo2LCh1q1bJy8vL5UoUbT/1WrUqKGSJUvq4MGDpiXO6enpOn36tEJCQvJt6+fnl2NTsX379snHx8eUbJYvX16pqamm66dPn9atW7dy9LV//37Tu9KZmZlKTEzMsft4Xo4fP65WrVqpX79+mjFjRqHaHD161PQLiRIlSpgS64IYjUZlZGRIklq3bq1jx46ZXe/fv79q166tsWPHknADAAAADxFJN3JVpkwZubq66t1335W7u7tSUlL0xhtvmK736tVL48eP15AhQ/TGG28oJSVFc+fOlfT/zwT/85//1NKlSxUWFqYxY8aoXLlyOnPmjFavXq2lS5fmm/w5OTmpX79+GjNmjMqWLSs3NzdNnjxZVlZWBc40jx49WkFBQZo2bZp69Oihr776SgsXLtSiRYtMdVq1aqWFCxeqSZMmys7O1tixY1WyZMkcff373/9WzZo15evrq7feektXr17VgAEDCnx+x48fV8uWLfXss89q1KhRunTpkiTJ2tpa5cuXlyStWLFCJUuWVIMGDWRlZaWNGzdqwYIFua4M+LPo6GgFBgaqRo0aun37tjZv3qz//Oc/Wrx4senZ1a1b16yNg4ODXF1dc5QDAAAAsCx2L0eurKystHr1aiUmJqpu3boaOXKk3nzzTdN1Z2dnbdy4UUlJSQoICND48eM1adIkSTK9R1ypUiUlJCQoKytLbdu2Vd26dTV8+HC5uLjIyqrg//ViY2PVtGlTPffccwoNDVVwcLB8fX0LfE+5YcOGWrNmjVavXq26detq0qRJmjp1qtkmajExMfL09FTz5s3Vq1cvRUREyN7ePkdfs2bN0uzZs1W/fn3t2bNH//d//6dy5coVGPt///tfXblyRatWrZK7u7vpCAoKMqs3ffp0BQYGKigoSKtXr9ayZcvM3vPOzc2bN/Xaa6+pTp06evrpp7V27Vp98MEHGjRoUIFxAQAAAHi4DMbcXpIF7sGqVavUv39/paWlyc7O7oH3f/PmTXl4eCgmJkYDBw584P3/2YULF1StWjUdPXpUAQEBFh3rUZWeni4XFxdtfPesHOyd7quvlr3LP6CoAAAAgEfD3X8vp6WlydnZOc96LC/HPfvPf/6j6tWry8PDQ19//bXGjh2r7t27P7CE++jRo/ruu+/UuHFjpaWlaerUqZKUY2dyAAAAAHhUsbwc9+zSpUvq06ePfH19NXLkSL300kt69913C9U2JSVFjo6OeR4pKSmSpLlz56p+/foKDQ3VzZs3tWfPnkIt77a0V155Jc/YX3nlleIODwAAAMAjguXlKBaZmZm6cOFCntfvZcfzh+ny5ctKT0/P9Zqzs7Pc3NweckQPHsvLAQAAgLyxvByPtKJ8DutR5Obm9kQk1gAAAAAsi6QbQL6a9yiX72/uAAAAAOSNd7oBAAAAALAQkm4AAAAAACyEpBsAAAAAAAsh6QYAAAAAwEJIugEAAAAAsBB2LweQr69XXJGj3e/31UeDQXxeDQAAAH9PzHQDAAAAAGAhJN0AAAAAAFgISTcAAAAAABZC0g0AAAAAgIWQdAMAAAAAYCEk3QAAAAAAWAhJNwAAAAAAFkLSDQAAAACAhZB0A0+4uLg4lS5durjDAAAAAP6WSLrxt3X79u3iDgEAAADAE46k+2/OaDRqzpw5ql69uuzs7FS/fn2tXbvWdP348ePq2LGjnJ2d5eTkpGbNmuns2bOSpOzsbE2dOlWVK1eWjY2NAgIC9Pnnn5vaXrhwQQaDQWvWrFGzZs1kZ2enoKAgnTp1SocOHVJgYKAcHR3Vrl07XblyxdQuPDxcnTt31syZM1WhQgWVLl1aU6ZMUWZmpsaMGaOyZcuqcuXKWrZsmdm9/PTTT+rRo4fKlCkjV1dXderUSRcuXMjRb3R0tCpVqiQfHx9J0o8//qiePXuqbNmycnBwUGBgoA4cOGBqt3HjRjVq1Ei2traqXr26KZbCuHbtmoYMGaIKFSrI1tZWdevW1aZNm0zX161bpzp16sjGxkZeXl6KiYkxa28wGLR+/XqzstKlSysuLs7sGX/yySdq2bKl7O3tVb9+fX311VeSpPj4ePXv319paWkyGAwyGAyKiooqVOwAAAAA7l+J4g4AxWvChAn65JNPtHjxYtWsWVO7d+9Wnz59VL58eXl7e6t58+Zq0aKFdu3aJWdnZyUkJJgSzvnz5ysmJkZLlixRgwYNtGzZMr3wwgs6fvy4atasaRpj8uTJmjdvnqpUqaIBAwYoLCxMzs7Omj9/vuzt7dW9e3dNmjRJixcvNrXZtWuXKleurN27dyshIUEDBw7UV199pebNm+vAgQP6+OOP9corr6hNmzby9PTUrVu31LJlSzVr1ky7d+9WiRIlNH36dLVr107ffPONSpUqJUnauXOnnJ2dtX37dhmNRt24cUMhISHy8PDQhg0bVLFiRR05ckTZ2dmSpK1bt6pPnz5asGCB6RcOQ4YMMd1XfrKzs9W+fXtdv35dH3zwgWrUqKETJ07I2tpakpSYmKju3bsrKipKPXr00L59+/Taa6/J1dVV4eHhRfpzHD9+vObOnauaNWtq/PjxCgsL05kzZ/T0009r3rx5mjRpkk6ePClJcnR0zLWPjIwMZWRkmM7T09OLFAMAAACAXBjxt3Xjxg2jra2tcd++fWblAwcONIaFhRnHjRtnrFatmvH27du5tq9UqZJxxowZZmVBQUHG1157zWg0Go3nz583SjK+9957pusfffSRUZJx586dprLo6GhjrVq1TOf9+vUzVq1a1ZiVlWUqq1WrlrFZs2am88zMTKODg4Pxo48+MhqNRuP7779vrFWrljE7O9tUJyMjw2hnZ2fcunWrqd8KFSoYMzIyTHWWLFlidHJyMv7yyy+53mOzZs2MM2fONCtbuXKl0d3dPdf6f7Z161ajlZWV8eTJk7le79Wrl7FNmzZmZWPGjDH6+fmZziUZP/30U7M6Li4uxuXLlxuNxtyf8fHjx42SjMnJyUaj0Whcvny50cXFpcB4J0+ebJSU49i94IzxyNL/3dcBAAAAPGnS0tKMkoxpaWn51mOm+2/sxIkT+v3339WmTRuz8tu3b6tBgwa6du2amjVrppIlS+Zom56erosXLyo4ONisPDg4WF9//bVZWb169Uw/V6hQQZLk7+9vVnb58mWzNnXq1JGVlZVZnbp165rOra2t5erqamqXmJioM2fOyMnJyayf33//3bQc/u64d2e9JSkpKUkNGjRQ2bJlc9zj3X4PHTqkGTNmmMqysrL0+++/69atW7K3t8+13d2+K1eubFrG/lfJycnq1KmTWVlwcLDmzZunrKws04x4Yfz5Gbu7u0uSLl++rNq1axe6j3HjxmnUqFGm8/T0dHl6eha6PQAAAICcSLr/xu4uof7ss8/k4eFhds3GxkYjRowosA+DwWB2bjQac5T9OWm/e+2vZXdjya3N3Tq5ld1tl52drUaNGmnVqlU5YixfvrzpZwcHB7NrdnZ2ud/Y/5Odna0pU6aoa9euOa7Z2trm27agvnN7Vkaj0ezcYDDkKLtz506OvnJ7xn99pgWxsbGRjY1NkdoAAAAAyB9J99+Yn5+fbGxslJKSopCQkBzX69WrpxUrVujOnTs5El5nZ2dVqlRJe/fuVfPmzU3l+/btU+PGjS0e+181bNhQH3/8sdzc3OTs7FzodvXq1dN7772nX3/9NdfZ7oYNG+rkyZPy9vYuckz16tXTjz/+qFOnTuU62+3n56e9e/eale3bt08+Pj6mWe7y5csrNTXVdP306dO6detWkeIoVaqUsrKyihw/AAAAgPvH7uV/Y05OToqIiNDIkSO1YsUKnT17VkePHtW///1vrVixQkOHDlV6erp69uypw4cP6/Tp01q5cqVpQ64xY8Zo9uzZ+vjjj3Xy5Em98cYbSkpK0vDhwx/6vfTu3VvlypVTp06dtGfPHp0/f15ffvmlhg8frh9//DHPdmFhYapYsaI6d+6shIQEnTt3TuvWrTPt/j1p0iT95z//UVRUlI4fP67k5GR9/PHHmjBhQoExhYSEqHnz5urWrZu2b9+u8+fPa8uWLaYd3kePHq2dO3dq2rRpOnXqlFasWKGFCxcqIiLC1EerVq20cOFCHTlyRIcPH9Yrr7yS63L//Hh5eenGjRvauXOnfv755yIn7QAAAADuHUn339y0adM0adIkRUdHy9fXV23bttXGjRtVrVo1ubq6ateuXaYdvhs1aqSlS5eakr5hw4Zp9OjRGj16tPz9/fX5559rw4YNZjuXPyz29vbavXu3qlSpoq5du8rX11cDBgzQb7/9lu/Md6lSpbRt2za5ubmpQ4cO8vf316xZs0wzzW3bttWmTZu0fft2BQUFqUmTJoqNjVXVqlULFde6desUFBSksLAw+fn5KTIy0jTr3LBhQ61Zs0arV69W3bp1NWnSJE2dOtVs5/KYmBh5enqqefPm6tWrlyIiIvJ9jzw3Tz/9tF555RX16NFD5cuX15w5c4rUHgAAAMC9Mxj/+sIoAOiPjdRcXFy0e8EZOdo5FdwgHw0GuT2gqAAAAIBHw91/L6elpeU70cdMNwAAAAAAFkLSDdyjVatWydHRMdejTp06xR0eAAAAgEcAu5cD9+iFF17QU089leu1om52BgAAAODJRNIN3CMnJyc5Od3fu84AAAAAnmwsLwcAAAAAwEKY6QaQr/r9yue7GyMAAACAvDHTDQAAAACAhZB0AwAAAABgISTdAAAAAABYCEk3AAAAAAAWQtINAAAAAICFsHs5gHx9v+h/crK9Vai6XiMqWjgaAAAA4PHCTDcAAAAAABZC0g0AAAAAgIWQdAMAAAAAYCEk3QAAAAAAWAhJNwAAAAAAFkLSDQAAAACAhZB0I08XLlyQwWBQUlLSffUTHh6uzp07P5CYJCkqKkoBAQEPrL+HLT4+XgaDQdeuXSvuUAAAAABYGN/pfoK0aNFCAQEBmjdvXnGHYmb+/PkyGo3FHQYAAAAAPHQk3bA4FxeX4g7hocnKypLBYJCVFYtIAAAAALC8/IkRHh6uL7/8UvPnz5fBYJDBYNCFCxd04sQJdejQQY6OjqpQoYJefvll/fzzz6Z22dnZmj17try9vWVjY6MqVapoxowZZn2fO3dOLVu2lL29verXr6+vvvrKdC0uLk6lS5fW1q1b5evrK0dHR7Vr106pqalmsf15eXlBY44dO1Y+Pj6yt7dX9erVNXHiRN25c+eenkt8fLwaN24sBwcHlS5dWsHBwfr+++9N1zdu3KhGjRrJ1tZW1atX15QpU5SZmWm6HhsbK39/fzk4OMjT01Ovvfaabty4keP+N23aJD8/P9nY2Oj7779XRkaGIiMj5enpKRsbG9WsWVPvv/++WWyJiYkKDAyUvb29nn76aZ08ebLQ9zV9+nS5ubnJyclJgwYN0htvvGG25D4zM1PDhg1T6dKl5erqqrFjx6pfv34PdJk/AAAAgIKRdD8h5s+fr6ZNm2rw4MFKTU1VamqqSpYsqZCQEAUEBOjw4cP6/PPP9b///U/du3c3tRs3bpxmz56tiRMn6sSJE/rwww9VoUIFs77Hjx+viIgIJSUlycfHR2FhYWaJ6a1btzR37lytXLlSu3fvVkpKiiIiIvKMtaAxnZycFBcXpxMnTmj+/PlaunSp3nrrrSI/k8zMTHXu3FkhISH65ptv9NVXX2nIkCEyGAySpK1bt6pPnz4aNmyYTpw4oSVLliguLs7sFwBWVlZasGCBvv32W61YsUK7du1SZGSk2Ti3bt1SdHS03nvvPR0/flxubm7q27evVq9erQULFig5OVnvvPOOHB0dczzXmJgYHT58WCVKlNCAAQMKdV+rVq3SjBkzNHv2bCUmJqpKlSpavHixWZ3Zs2dr1apVWr58uRISEpSenq7169fn229GRobS09PNDgAAAAD3yYgnRkhIiHH48OGm84kTJxqfffZZszo//PCDUZLx5MmTxvT0dKONjY1x6dKlufZ3/vx5oyTje++9Zyo7fvy4UZIxOTnZaDQajcuXLzdKMp45c8ZU59///rexQoUKpvN+/foZO3XqZDQajQWOmZs5c+YYGzVqZDqfPHmysX79+gW2++WXX4ySjPHx8bleb9asmXHmzJlmZStXrjS6u7vn2eeaNWuMrq6upvO795+UlGQqO3nypFGScfv27bn28cUXXxglGXfs2GEq++yzz4ySjL/99luB9/XUU08Z//nPf5qVBQcHmz2TChUqGN98803TeWZmprFKlSqmP4fcTJ482Sgpx/FN9Cnj+bdSC3UAAAAAfxdpaWlGSca0tLR86zHT/QRLTEzUF198IUdHR9NRu3ZtSdLZs2eVnJysjIwMtW7dOt9+6tWrZ/rZ3d1dknT58mVTmb29vWrUqGFW58/X/6wwY65du1bPPPOMKlasKEdHR02cOFEpKSkF3/BflC1bVuHh4Wrbtq2ef/55zZ8/32zZe2JioqZOnWr2fO6uFLh165Yk6YsvvlCbNm3k4eEhJycn9e3bV7/88otu3rxp6qdUqVJmzygpKUnW1tYKCQnJN76CnmteTp48qcaNG5uV/fk8LS1N//vf/8zKrK2t1ahRo3z7HTdunNLS0kzHDz/8UGAsAAAAAPJH0v0Ey87O1vPPP6+kpCSz4/Tp02revLns7OwK1U/JkiVNP99dmp2dnZ3r9bt1jHnsVl7QmPv371fPnj3Vvn17bdq0SUePHtX48eN1+/btQsX6V8uXL9dXX32lp59+Wh9//LF8fHy0f/9+0z1MmTLF7NkcO3ZMp0+flq2trb7//nt16NBBdevW1bp165SYmKh///vfkmT2jrmdnZ3puRTmHu8q6Lnm58/jScr1eRemzp/Z2NjI2dnZ7AAAAABwf0i6nyClSpVSVlaW6bxhw4Y6fvy4vLy85O3tbXY4ODioZs2asrOz086dOx9ajAWNmZCQoKpVq2r8+PEKDAxUzZo1zTY+uxcNGjTQuHHjtG/fPtWtW1cffvihpD+ez8mTJ3M8G29vb1lZWenw4cPKzMxUTEyMmjRpIh8fH128eLHA8fz9/ZWdna0vv/zyvuLOS61atXTw4EGzssOHD5t+dnFxUYUKFczqZGVl6ejRoxaJBwAAAEDe+GTYE8TLy0sHDhzQhQsX5OjoqH/+859aunSpwsLCNGbMGJUrV05nzpzR6tWrtXTpUtna2mrs2LGKjIxUqVKlFBwcrCtXruj48eMaOHCgRWIsaExvb2+lpKRo9erVCgoK0meffaZPP/30nsY6f/683n33Xb3wwguqVKmSTp48qVOnTqlv376SpEmTJum5556Tp6enXnrpJVlZWembb77RsWPHNH36dNWoUUOZmZl6++239fzzzyshIUHvvPNOgeN6eXmpX79+GjBggBYsWKD69evr+++/1+XLl802sbtXr7/+ugYPHqzAwEDTDP4333yj6tWrm9WJjo6Wt7e3ateurbfffltXr17NMfsNAAAAwLKY6X6CREREyNraWn5+fipfvrxu376thIQEZWVlqW3btqpbt66GDx8uFxcX03ekJ06cqNGjR2vSpEny9fVVjx49CvVe8f3Ib8xOnTpp5MiRGjp0qAICArRv3z5NnDjxnsaxt7fXd999p27dusnHx0dDhgzR0KFD9Y9//EOS1LZtW23atEnbt29XUFCQmjRpotjYWFWtWlWSFBAQoNjYWM2ePVt169bVqlWrFB0dXaixFy9erBdffFGvvfaaateurcGDB5u9B34/evfurXHjxikiIkINGzbU+fPnFR4eLltbW1OdsWPHKiwsTH379lXTpk3l6Oiotm3bmtUBAAAAYHkGY0EvegJ45LVp00YVK1bUypUrc72enZ0tX19fde/eXdOmTStUn+np6XJxcdE30afkZOtUqDZeIyoWOmYAAADgcXb338tpaWn57ofE8nLgMXPr1i298847atu2raytrfXRRx9px44d2r59u6nO999/r23btikkJEQZGRlauHChzp8/r169ehVj5AAAAMDfD8vL8Vj78+e+/nrs2bOnuMO7J3Xq1MnznlatWiWDwaDNmzerWbNmatSokTZu3Kh169YpNDTU1IeVlZXi4uIUFBSk4OBgHTt2TDt27JCvr28x3hkAAADw98NMNx5rSUlJeV7z8PB4eIE8QJs3bzb7JNmfVahQQXZ2dtqxY0e+fXh6eiohIcES4QEAAAAoApJuPNa8vb2LO4QH7u5GbgAAAAAefywvBwAAAADAQpjpBpCvqq9VyHc3RgAAAAB5Y6YbAAAAAAALIekGAAAAAMBCSLoBAAAAALAQkm4AAAAAACyEpBsAAAAAAAth93IA+frfgrO6ZeuU67WKEU/ed9IBAACAB4mZbgAAAAAALISkGwAAAAAACyHpBgAAAADAQki6AQAAAACwEJJuAAAAAAAshKQbAAAAAAALIekGAAAAAMBCnviku0WLFhoxYkRxh5GnCxcuyGAwKCkpqVjjCA8PV+fOnR/qmN99952aNGkiW1tbBQQEWHQsg8Gg9evXS3p0nrklFcefJwAAAICcShR3AHg0zJ8/X0aj8aGOOXnyZDk4OOjkyZNydHS06FipqakqU6aMRccAAAAAgL8i6YYkycXF5aGPefbsWXXs2FFVq1a1+FgVK1a0+BgPy+3bt1WqVKniDgMAAABAITzxy8slKTs7W5GRkSpbtqwqVqyoqKgo07WUlBR16tRJjo6OcnZ2Vvfu3fW///3PdD23ZbojRoxQixYtTOdr166Vv7+/7Ozs5OrqqtDQUN28edN0ffny5fL19ZWtra1q166tRYsW5Rvr4MGD5ePjo++//16StHHjRjVq1Ei2traqXr26pkyZoszMTFObtLQ0DRkyRG5ubnJ2dlarVq309ddfm65HRUUpICBAS5Yskaenp+zt7fXSSy/p2rVred5nixYtNGzYsDyfm/TH8vBnnnlGtra28vPz044dO8yWcefHYDAoMTFRU6dOlcFgMPU9duxY+fj4yN7eXtWrV9fEiRN1586dHPeybNkyValSRY6Ojnr11VeVlZWlOXPmqGLFinJzc9OMGTNyjJdbXEajUd7e3po7d65Z+bfffisrKyudPXu2wHuJiopSlSpVZGNjo0qVKmnYsGGma7dv31ZkZKQ8PDzk4OCgp556SvHx8abrv/zyi8LCwlS5cmXZ29vL399fH330kVn/LVq00NChQzVq1CiVK1dObdq0kSQdP35cHTt2lLOzs5ycnNSsWbMc8c6dO1fu7u5ydXXVP//5T7Nn+VcZGRlKT083OwAAAADcn7/FTPeKFSs0atQoHThwQF999ZXCw8MVHBys0NBQde7cWQ4ODvryyy+VmZmp1157TT169DBLjPKTmpqqsLAwzZkzR126dNH169e1Z88e01LtpUuXavLkyVq4cKEaNGigo0ePavDgwXJwcFC/fv3M+rp9+7Z69eqls2fPau/evXJzc9PWrVvVp08fLViwwJRUDRkyRNIfy7ONRqP+v/buPCyKK10D+Ns0yL4IEUXSgkgAFxBZVIKIEQTFuI47rriMEVc0LlEEo3FHvTGJMUTFRCPJ1aszRlwQlxCIqCiGKCGiMqCCS0wAF0Doc//wocaWVaQF9f09Tz+TOnVO1Tlf9Vh8XaeqevfuDVNTU8TExMDY2BibN2+Gj48P/vjjD5iamgIAMjIy8MMPP2D//v3Iz8/H+PHjERwcjJ07dz533Hr06AGlUon+/fujRYsWSEpKQkFBAWbPnl3jY5KTkwNfX1/07NkTc+bMkaaXGxoaIioqCs2bN0dqaiomTpwIQ0NDzJ07V2p75coVHDx4EIcOHcKVK1cwaNAgXLt2DXZ2djh58iQSExMRFBQEHx8fdO7cucp+yGQyBAUFYdu2bZgzZ45UvnXrVnh5eaFVq1ZVtt+9ezfWr1+P6OhotG3bFrm5uSo/eIwbNw6ZmZmIjo5G8+bNsXfvXvTs2ROpqal45513UFhYCFdXV8ybNw9GRkY4cOAARo0aBRsbG3Tq1EnlWHzwwQdISEiAEAI3btxA165d0a1bNxw7dgxGRkZISEhQ+THm+PHjsLCwwPHjx5GRkYGhQ4fC2dkZEydOrHAsK1aswJIlS6ocLxERERERPSfxmvP29hZdunRRKXN3dxfz5s0TR44cEXK5XGRlZUnrLl68KACI06dPCyGEGDNmjOjXr59K+xkzZghvb28hhBDJyckCgMjMzKxw/wqFQnz33XcqZUuXLhUeHh5CCCGuXbsmAIj4+Hjh6+srPD09xd9//y3V9fLyEsuXL1dp/+233woLCwshhBBxcXHCyMhIFBYWqtRp1aqV2Lx5sxBCiLCwMCGXy0V2dra0/uDBg0JDQ0Pk5ORUOM6q4lbWXlNTU2ovhBCxsbECgNi7d2+FsXhW+/btRVhYWJV1Vq9eLVxdXaXlsLAwoaenJ/Lz86Uyf39/YW1tLUpLS6Uye3t7sWLFCmn56X6Vxfz8+fNCCCFu3rwp5HK5SEpKEkIIUVxcLJo0aSKioqKqHUNERISws7MTxcXF5dZlZGQImUwmbty4oVLu4+MjFixYUOk2AwICxOzZs6Vlb29v4ezsrFJnwYIFomXLlhXuV4gnx9PKykqUlJRIZYMHDxZDhw6tdL+FhYUiLy9P+mRnZwsA4o+l50TOmssVfoiIiIiI3lR5eXkCgMjLy6uy3htxpdvJyUll2cLCArdv30ZaWhoUCgUUCoW0rk2bNjAxMUFaWhrc3d2r3Xb79u3h4+MDR0dH+Pv7w8/PD4MGDULjxo1x584dZGdnY/z48SpXF0tKSsrdQ102xTguLg56enpSeXJyMs6cOaMyXbq0tBSFhYV4+PAhkpOTcf/+fZiZmals79GjRypTjVu0aIG3335bWvbw8IBSqUR6enql9ztXFjcASE9Ph0KhUGnbsWPHauNVnd27d2PDhg3IyMjA/fv3UVJSAiMjI5U61tbWMDQ0lJabNm0KuVwODQ0NlbKyvlbHwsICvXv3xtatW9GxY0f8+OOPKCwsxODBg6ttO3jwYGzYsAE2Njbo2bMnAgIC0KdPH2hqauLcuXMQQsDOzk6lTVFRkXS8SktLsXLlSnz//fe4ceMGioqKUFRUBH19fZU2bm5uKsspKSnw8vKClpZWpX1r27Yt5HK5yjhTU1Mrra+trQ1tbe1qx0xERERERDX3RiTdzyYmMpkMSqUSQgjIZLJy9Z8u19DQKPdU76fvi5XL5YiNjUViYiKOHDmCjRs3YuHChUhKSpKS58jISJWpwmXtnhYQEIAdO3bg1KlT6N69u1SuVCqxZMkSDBw4sFw/dXR0oFQqYWFhUeF0eBMTkwqi8d8YPP2/FaksbgAqjd2LOHXqFIYNG4YlS5bA398fxsbGiI6ORkRERLX9qqqvNTFhwgSMGjUK69evx7Zt2zB06FCVHz8qo1AokJ6ejtjYWBw9ehRTpkzBmjVrcPLkSSiVSsjlciQnJ5c73mXT6SMiIrB+/Xps2LABjo6O0NfXx8yZM1FcXKxS/9kkXFdXt9q+vWhMiIiIiIjoxb0RSXdl2rRpg6ysLGRnZ0tXuy9duoS8vDy0bt0aANCkSRP89ttvKu1SUlJUEhqZTAZPT094enpi8eLFsLKywt69exESEgJLS0tcvXoVgYGBVfblgw8+QLt27dC3b18cOHAA3t7eAAAXFxekp6fD1ta2wnYuLi7Izc2FpqYmrK2tK91+VlYWbt68iebNmwMAfvnlF2hoaJS7CltTDg4OyMrKwq1bt9C0aVMAwJkzZ2q1rTIJCQmwsrLCwoULpbKyh8mpW0BAAPT19bFp0yYcPHgQP/30U43b6urqom/fvujbty+Cg4Ph4OCA1NRUdOjQAaWlpbh9+za8vLwqbBsfH49+/fph5MiRAJ78yHL58mXp+1cZJycnbN++HY8fP67yajcREREREdWvNzrp9vX1hZOTEwIDA7FhwwbpQWre3t7SdN7u3btjzZo1+Oabb+Dh4YEdO3bgt99+Q4cOHQAASUlJiIuLg5+fH8zNzZGUlIQ7d+5ISVN4eDimT58OIyMj9OrVC0VFRTh79iz++usvhISEqPRn2rRpKC0txfvvv4+DBw+iS5cuWLx4Md5//30oFAoMHjwYGhoa+PXXX5Gamoply5bB19cXHh4e6N+/P1atWgV7e3vcvHkTMTEx6N+/vzQOHR0djBkzBmvXrkV+fj6mT5+OIUOG1PpVWj169ECrVq0wZswYrF69GgUFBVKyXNsr4La2tsjKykJ0dDTc3d1x4MAB7N27t1bbel5yuRxjx47FggULYGtrCw8Pjxq1i4qKQmlpKTp16gQ9PT18++230NXVhZWVFczMzBAYGIjRo0cjIiICHTp0wN27d3Hs2DE4OjoiICAAtra22LNnDxITE9G4cWOsW7cOubm51SbdU6dOxcaNGzFs2DAsWLAAxsbGOHXqFDp27Ah7e/u6CAkREREREdWBN+KVYZUpe41U48aN0bVrV/j6+sLGxgbff/+9VMff3x+hoaGYO3cu3N3dUVBQgNGjR0vrjYyM8NNPPyEgIAB2dnZYtGgRIiIi0KtXLwBPpi1//fXXiIqKgqOjI7y9vREVFYWWLVtW2KeZM2diyZIlCAgIQGJiIvz9/fHjjz8iNjYW7u7u6Ny5M9atWye921omkyEmJgZdu3ZFUFAQ7OzsMGzYMGRmZkpXoIEnCe3AgQMREBAAPz8/tGvXrspXl1VHLpdj3759uH//Ptzd3TFhwgQsWrQIwJMEvzb69euHWbNmYerUqXB2dkZiYiJCQ0Nr3cfnNX78eBQXFyMoKKjGbUxMTBAZGQlPT084OTkhLi4O+/fvl+7Z3rZtG0aPHo3Zs2fD3t4effv2RVJSkjSzIjQ0FC4uLvD390e3bt3QrFmzcq+oq4iZmRmOHTuG+/fvw9vbG66uroiMjORVbyIiIiKiBkYmnr1hmV474eHh2LdvH1JSUtS6n4SEBHTp0gUZGRnVvmqrIUpISEC3bt1w/fp1lR8s3lT5+fkwNjbGH0vPwVDHsMI6zeZUfNsDEREREdHrruzv5by8vHIPf37aGz29nF7M3r17YWBggHfeeQcZGRmYMWMGfWHvJQAAMyBJREFUPD09X7mEu6ioCNnZ2QgNDcWQIUOYcBMRERERUZ15o6eX04spKCjAlClT4ODggLFjx8Ld3R3/+te/AADLly+HgYFBhZ+yqfcNxa5du2Bvb4+8vDysXr1aZd3OnTsrHUfbtm3rqcdERERERPSq4PRyUot79+7h3r17Fa7T1dWFpaXlS+5R7RQUFODWrVsVrtPS0pLurX8dcXo5EREREVHlOL2c6pWpqSlMTU3ruxsvzNDQEIaGFSecRERERERE1WHSTURVajq9VZW/3BERERERUeV4TzcRERERERGRmjDpJiIiIiIiIlITJt1EREREREREasKkm4iIiIiIiEhNmHQTERERERERqQmfXk5EVbr9xXk80jGocF3Tma4vuTdERERERK8WXukmIiIiIiIiUhMm3URERERERERqwqSbiIiIiIiISE2YdBMRERERERGpCZNuIiIiIiIiIjVh0k1ERERERESkJky6iYiIiIiIiNSESTcRERERERGRmjDpJlKTGTNmwNXVFdra2nB2dq6wzuHDh9G5c2cYGhqiSZMm+Mc//oFr165Vud3IyEh4eXmhcePGaNy4MXx9fXH69OlK669YsQIymQwzZ858gdEQEREREVFtMOmm10pxcXF9d0EihEBQUBCGDh1a4fqrV6+iX79+6N69O1JSUnD48GHcvXsXAwcOrHK7J06cwPDhw3H8+HH88ssvaNGiBfz8/HDjxo1ydc+cOYOvvvoKTk5OdTImIiIiIiJ6Pky6qVKHDh1Cly5dYGJiAjMzM7z//vu4cuWKtD4xMRHOzs7Q0dGBm5sb9u3bB5lMhpSUFKnOpUuXEBAQAAMDAzRt2hSjRo3C3bt3a7T/goICBAYGQl9fHxYWFli/fj26deumcsXW2toay5Ytw9ixY2FsbIyJEycCAPbs2YO2bdtCW1sb1tbWiIiIUNm2TCbDvn37VMpMTEwQFRUFAMjMzIRMJkN0dDTeffdd6OjooG3btjhx4kSN4/fpp58iODgYNjY2Fa4/d+4cSktLsWzZMrRq1QouLi6YM2cOLly4gMePH1e63Z07d2LKlClwdnaGg4MDIiMjoVQqERcXp1Lv/v37CAwMRGRkJBo3blxtf4uKipCfn6/yISIiIiKiF8Okmyr14MEDhISE4MyZM4iLi4OGhgYGDBgApVKJgoIC9OnTB46Ojjh37hyWLl2KefPmqbTPycmBt7c3nJ2dcfbsWRw6dAi3bt3CkCFDarT/kJAQJCQk4N///jdiY2MRHx+Pc+fOlau3Zs0atGvXDsnJyQgNDUVycjKGDBmCYcOGITU1FeHh4QgNDZUS6ufx4YcfYvbs2Th//jzeffdd9O3bF3/++edzb6cibm5ukMvl2LZtG0pLS5GXl4dvv/0Wfn5+0NLSqvF2Hj58iMePH8PU1FSlPDg4GL1794avr2+NtrNixQoYGxtLH4VC8VzjISIiIiKi8jTruwPUcP3jH/9QWd6yZQvMzc1x6dIl/Pzzz5DJZIiMjISOjg7atGmDGzduSFeaAWDTpk1wcXHB8uXLpbKtW7dCoVDgjz/+gJ2dXaX7LigowPbt2/Hdd9/Bx8cHALBt2zY0b968XN3u3btjzpw50nJgYCB8fHwQGhoKALCzs8OlS5ewZs0ajB079rliMHXqVCkOmzZtwqFDh7BlyxbMnTv3ubZTEWtraxw5cgSDBw/GP//5T5SWlsLDwwMxMTHPtZ358+fD0tJSJbmOjo7GuXPncObMmRpvZ8GCBQgJCZGW8/PzmXgTEREREb0gXummSl25cgUjRoyAjY0NjIyM0LJlSwBAVlYW0tPT4eTkBB0dHal+x44dVdonJyfj+PHjMDAwkD4ODg7Stqty9epVPH78WGWbxsbGsLe3L1fXzc1NZTktLQ2enp4qZZ6enrh8+TJKS0trMPL/8vDwkP5bU1MTbm5uSEtLe65tVCY3NxcTJkzAmDFjcObMGZw8eRKNGjXCoEGDIIRAVlaWSuye/vGizOrVq7Fr1y783//9n3QssrOzMWPGDOzYsUPl+FRHW1sbRkZGKh8iIiIiInoxvNJNlerTpw8UCgUiIyPRvHlzKJVKtGvXDsXFxRBCQCaTqdQXQqgsK5VK9OnTB6tWrSq3bQsLiyr3Xbat6vYBAPr6+uXqVNdOJpOVK6vqPupn29aFzz//HEZGRli9erVUtmPHDigUCiQlJcHNzU3l/vhnp4+vXbsWy5cvx9GjR1UelJacnIzbt2/D1dVVKistLcVPP/2Ezz77DEVFRZDL5XUyBiIiIiIiqhqTbqrQn3/+ibS0NGzevBleXl4AgJ9//lla7+DggJ07d6KoqAja2toAgLNnz6psw8XFBXv27IG1tTU0NZ/vq9aqVStoaWnh9OnT0hTn/Px8XL58Gd7e3lW2bdOmjUpfgScPfbOzs5OSzSZNmiAnJ0daf/nyZTx8+LDctk6dOoWuXbsCAEpKSpCcnIypU6c+11gq8/Dhw3LJb9myUqmEpqYmbG1tK2y7Zs0aLFu2DIcPHy53pd/HxwepqakqZePGjYODgwPmzZvHhJuIiIiI6CXi9HKqUOPGjWFmZoavvvoKGRkZOHbsmMr9viNGjIBSqcSkSZOQlpaGw4cPY+3atQD+eyU4ODgY9+7dw/Dhw3H69GlcvXoVR44cQVBQULXTvA0NDTFmzBh8+OGHOH78OC5evIigoCBoaGhUe6V59uzZiIuLw9KlS/HHH39g+/bt+Oyzz1Tu++7evTs+++wznDt3DmfPnsXkyZMrfHjZ559/jr179+L3339HcHAw/vrrLwQFBdUohhkZGUhJSUFubi4ePXqElJQUpKSkSK816927N86cOYOPP/4Yly9fxrlz5zBu3DhYWVmhQ4cOlW539erVWLRoEbZu3Qpra2vk5uYiNzcX9+/fl2LXrl07lY++vj7MzMzQrl27GvWdiIiIiIjqBpNuqpCGhgaio6ORnJyMdu3aYdasWVizZo203sjICPv370dKSgqcnZ2xcOFCLF68GACk+4ibN2+OhIQElJaWwt/fH+3atcOMGTNgbGwMDY3qv3rr1q2Dh4cH3n//ffj6+sLT0xOtW7eu9j5lFxcX/PDDD4iOjka7du2wePFifPzxxyoPUYuIiIBCoUDXrl0xYsQIzJkzB3p6euW2tXLlSqxatQrt27dHfHw8/vWvf+Gtt96qSQgxYcIEdOjQAZs3b8Yff/yBDh06oEOHDrh58yaAJ4n/d999h3379qFDhw7o2bMntLW1cejQIejq6la63S+++ALFxcUYNGgQLCwspE/Zjx5ERERERNRwyERFN8kS1cLOnTsxbtw45OXlVZk01taDBw9gaWmJiIgIjB8/vs63/7TMzEy0bNkS58+fh7Ozs1r31VDl5+fD2NgYl1ecgKGOQYV1ms50rbCciIiIiOh1V/b3cl5eXpUPIeY93VRr33zzDWxsbGBpaYkLFy5g3rx5GDJkSJ0l3OfPn8fvv/+Ojh07Ii8vDx9//DEAoF+/fnWyfSIiIiIiInXj9HKqtdzcXIwcORKtW7fGrFmzMHjwYHz11Vc1avvs67Ce/WRlZQF48oTu9u3bw9fXFw8ePEB8fHyNp3er0+TJkyvt++TJk+u7e0RERERE1EBwejnVi5KSEmRmZla6vjZPPH+Zbt++jfz8/ArXGRkZwdzc/CX3qO5xejkRERERUeU4vZwatKpeh/UqMDc3fy0SayIiIiIiUi8m3URUJfMpHar85Y6IiIiIiCrHe7qJiIiIiIiI1IRJNxEREREREZGaMOkmIiIiIiIiUhMm3URERERERERqwqSbiIiIiIiISE349HIiqtLtL+PxSEe/XHnT6d1efmeIiIiIiF4xvNJNREREREREpCZMuomIiIiIiIjUhEk3ERERERERkZow6SYiIiIiIiJSEybdRERERERERGrCpJuIiIiIiIhITZh0ExEREREREalJvSbd3bp1w8yZM+uzC1XKzMyETCZDSkpKvfZj7Nix6N+//0vd5++//47OnTtDR0cHzs7Oat2XTCbDvn37ADScmKtTfRxPIiIiIiKqH5r13QGq3v/8z/9ACPFS9xkWFgZ9fX2kp6fDwMBArfvKyclB48aN1boPIiIiIiKi+sCk+xVgbGz80vd55coV9O7dG1ZWVmrfV7NmzdS+j5eluLgYjRo1qu9uEBERERFRA1Hv93QrlUrMnTsXpqamaNasGcLDw6V1WVlZ6NevHwwMDGBkZIQhQ4bg1q1b0vqKpunOnDkT3bp1k5Z3794NR0dH6OrqwszMDL6+vnjw4IG0ftu2bWjdujV0dHTg4OCAL774osq+Tpw4EXZ2dvjPf/4DANi/fz9cXV2ho6MDGxsbLFmyBCUlJVKbvLw8TJo0Cebm5jAyMkL37t1x4cIFaX14eDicnZ2xefNmKBQK6OnpYfDgwfj7778rHWe3bt0wffr0SuMGPJke3qVLF+jo6KBNmzY4evSoyjTuqshkMiQnJ+Pjjz+GTCaTtj1v3jzY2dlBT08PNjY2CA0NxePHj8uNZevWrWjRogUMDAzwwQcfoLS0FKtXr0azZs1gbm6OTz75pNz+KuqXEAK2trZYu3atSvlvv/0GDQ0NXLlypdqxhIeHo0WLFtDW1kbz5s0xffp0aV1xcTHmzp0LS0tL6Ovro1OnTjhx4oS0/s8//8Tw4cPx9ttvQ09PD46Ojti1a5fK9rt164apU6ciJCQEb731Fnr06AEAuHjxInr37g0jIyMYGhrCy8urXH/Xrl0LCwsLmJmZITg4WCWWVcnJyUHv3r2hq6uLli1b4rvvvoO1tTU2bNgg1anN8S8qKkJ+fr7Kh4iIiIiIXky9X+nevn07QkJCkJSUhF9++QVjx46Fp6cnfH190b9/f+jr6+PkyZMoKSnBlClTMHToUJXEqCo5OTkYPnw4Vq9ejQEDBqCgoADx8fHSVO3IyEiEhYXhs88+Q4cOHXD+/HlMnDgR+vr6GDNmjMq2iouLMWLECFy5cgU///wzzM3NcfjwYYwcORKffvqplFRNmjQJwJPp2UII9O7dG6ampoiJiYGxsTE2b94MHx8f/PHHHzA1NQUAZGRk4IcffsD+/fuRn5+P8ePHIzg4GDt37nzuuPXo0QNKpRL9+/dHixYtkJSUhIKCAsyePbvGxyQnJwe+vr7o2bMn5syZI00vNzQ0RFRUFJo3b47U1FRMnDgRhoaGmDt3rtT2ypUrOHjwIA4dOoQrV65g0KBBuHbtGuzs7HDy5EkkJiYiKCgIPj4+6Ny5c5X9kMlkCAoKwrZt2zBnzhypfOvWrfDy8kKrVq2qbL97926sX78e0dHRaNu2LXJzc1V+8Bg3bhwyMzMRHR2N5s2bY+/evejZsydSU1PxzjvvoLCwEK6urpg3bx6MjIxw4MABjBo1CjY2NujUqZPKsfjggw+QkJAAIQRu3LiBrl27olu3bjh27BiMjIyQkJCg8mPM8ePHYWFhgePHjyMjIwNDhw6Fs7MzJk6cWO3xGT16NO7evYsTJ05AS0sLISEhuH37trS+tsd/xYoVWLJkSbX1iIiIiIjoOYh65O3tLbp06aJS5u7uLubNmyeOHDki5HK5yMrKktZdvHhRABCnT58WQggxZswY0a9fP5X2M2bMEN7e3kIIIZKTkwUAkZmZWeH+FQqF+O6771TKli5dKjw8PIQQQly7dk0AEPHx8cLX11d4enqKv//+W6rr5eUlli9frtL+22+/FRYWFkIIIeLi4oSRkZEoLCxUqdOqVSuxefNmIYQQYWFhQi6Xi+zsbGn9wYMHhYaGhsjJyalwnFXFray9pqam1F4IIWJjYwUAsXfv3gpj8az27duLsLCwKuusXr1auLq6SsthYWFCT09P5OfnS2X+/v7C2tpalJaWSmX29vZixYoV0vLT/SqL+fnz54UQQty8eVPI5XKRlJQkhBCiuLhYNGnSRERFRVU7hoiICGFnZyeKi4vLrcvIyBAymUzcuHFDpdzHx0csWLCg0m0GBASI2bNnS8ve3t7C2dlZpc6CBQtEy5YtK9yvEE+Op5WVlSgpKZHKBg8eLIYOHVrtmNLS0gQAcebMGans8uXLAoBYv369EKL2x7+wsFDk5eVJn+zsbAFAXF71o8j9n+PlPkREREREb7K8vDwBQOTl5VVZr96vdDs5OaksW1hY4Pbt20hLS4NCoYBCoZDWtWnTBiYmJkhLS4O7u3u1227fvj18fHzg6OgIf39/+Pn5YdCgQWjcuDHu3LmD7OxsjB8/XuXqYklJSbl7qMumGMfFxUFPT08qT05OxpkzZ1SmS5eWlqKwsBAPHz5EcnIy7t+/DzMzM5XtPXr0SGWqcYsWLfD2229Lyx4eHlAqlUhPT6/0fufK4gYA6enpUCgUKm07duxYbbyqs3v3bmzYsAEZGRm4f/8+SkpKYGRkpFLH2toahoaG0nLTpk0hl8uhoaGhUvb0ldmqWFhYoHfv3ti6dSs6duyIH3/8EYWFhRg8eHC1bQcPHowNGzbAxsYGPXv2REBAAPr06QNNTU2cO3cOQgjY2dmptCkqKpKOV2lpKVauXInvv/8eN27cQFFREYqKiqCvr6/Sxs3NTWU5JSUFXl5e0NLSqrRvbdu2hVwuVxlnampqtWNKT0+HpqYmXFxcpDJbW1uVB9HV9vhra2tDW1u72npERERERFRz9Z50P5uYyGQyKJVKCCEgk8nK1X+6XENDo9xTvZ++L1YulyM2NhaJiYk4cuQINm7ciIULFyIpKUlKniMjI1WmCpe1e1pAQAB27NiBU6dOoXv37lK5UqnEkiVLMHDgwHL91NHRgVKphIWFRYXT4U1MTCqIxn9j8PT/VqSyuAGoNHYv4tSpUxg2bBiWLFkCf39/GBsbIzo6GhEREdX2q6q+1sSECRMwatQorF+/Htu2bcPQoUNVfvyojEKhQHp6OmJjY3H06FFMmTIFa9aswcmTJ6FUKiGXy5GcnFzueJdNp4+IiMD69euxYcMGODo6Ql9fHzNnzkRxcbFK/WeTcF1d3Wr7VtuYPPt9r6hcHcefiIiIiIhqp96T7sq0adMGWVlZyM7Olq52X7p0CXl5eWjdujUAoEmTJvjtt99U2qWkpKgkNDKZDJ6envD09MTixYthZWWFvXv3IiQkBJaWlrh69SoCAwOr7MsHH3yAdu3aoW/fvjhw4AC8vb0BAC4uLkhPT4etrW2F7VxcXJCbmwtNTU1YW1tXuv2srCzcvHkTzZs3BwD88ssv0NDQKHcVtqYcHByQlZWFW7duoWnTpgCAM2fO1GpbZRISEmBlZYWFCxdKZWUPk1O3gIAA6OvrY9OmTTh48CB++umnGrfV1dVF37590bdvXwQHB8PBwQGpqano0KEDSktLcfv2bXh5eVXYNj4+Hv369cPIkSMBPPmR5fLly9L3rzJOTk7Yvn07Hj9+XOXV7tpwcHBASUkJzp8/D1dXVwBPngnw9IP31HH8iYiIiIiodhps0u3r6wsnJycEBgZiw4YN0oPUvL29pem83bt3x5o1a/DNN9/Aw8MDO3bswG+//YYOHToAAJKSkhAXFwc/Pz+Ym5sjKSkJd+7ckZKm8PBwTJ8+HUZGRujVqxeKiopw9uxZ/PXXXwgJCVHpz7Rp01BaWor3338fBw8eRJcuXbB48WK8//77UCgUGDx4MDQ0NPDrr78iNTUVy5Ytg6+vLzw8PNC/f3+sWrUK9vb2uHnzJmJiYtC/f39pHDo6OhgzZgzWrl2L/Px8TJ8+HUOGDKn1q7R69OiBVq1aYcyYMVi9ejUKCgqkZLm2V0BtbW2RlZWF6OhouLu748CBA9i7d2+ttvW85HI5xo4diwULFsDW1hYeHh41ahcVFYXS0lJ06tQJenp6+Pbbb6GrqwsrKyuYmZkhMDAQo0ePRkREBDp06IC7d+/i2LFjcHR0REBAAGxtbbFnzx4kJiaicePGWLduHXJzc6tNuqdOnYqNGzdi2LBhWLBgAYyNjXHq1Cl07NgR9vb2LxQLBwcH+Pr6YtKkSdi0aRO0tLQwe/Zs6OrqSsdWHcefiIiIiIhqp95fGVaZstcbNW7cGF27doWvry9sbGzw/fffS3X8/f0RGhqKuXPnwt3dHQUFBRg9erS03sjICD/99BMCAgJgZ2eHRYsWISIiAr169QLwZNry119/jaioKDg6OsLb2xtRUVFo2bJlhX2aOXMmlixZgoCAACQmJsLf3x8//vgjYmNj4e7ujs6dO2PdunXSu61lMhliYmLQtWtXBAUFwc7ODsOGDUNmZqZ0BRJ4ktAOHDgQAQEB8PPzQ7t27ap8dVl15HI59u3bh/v378Pd3R0TJkzAokWLADxJ8GujX79+mDVrFqZOnQpnZ2ckJiYiNDS01n18XuPHj0dxcTGCgoJq3MbExASRkZHw9PSEk5MT4uLisH//fume7W3btmH06NGYPXs27O3t0bdvXyQlJUkzK0JDQ+Hi4gJ/f39069YNzZo1K/eKuoqYmZnh2LFjuH//Pry9veHq6orIyMg6u+r9zTffoGnTpujatSsGDBggPUW+7Niq4/gTEREREVHtyERlN4nSSxEeHo59+/YhJSVFrftJSEhAly5dkJGRUe2rthqihIQEdOvWDdevX1f5wYKA69evQ6FQ4OjRo/Dx8amwTm2Of35+PoyNjXF51Y8w1NEvt77p9G4v0m0iIiIiolda2d/LeXl55R4w/bQGO72cXszevXthYGCAd955BxkZGZgxYwY8PT1fuYS7qKgI2dnZCA0NxZAhQ5hwA9JVdEdHR+Tk5GDu3LmwtrZG165dpTqvy/EnIiIiInrVNdjp5fRiCgoKMGXKFDg4OGDs2LFwd3fHv/71LwDA8uXLYWBgUOGnbOp9Q7Fr1y7Y29sjLy8Pq1evVlm3c+fOSsfRtm3beurxi4mPj690TGVPVX/8+DE++ugjtG3bFgMGDECTJk1w4sQJlenrVR1/IiIiIiJ6eTi9/A1079493Lt3r8J1urq6sLS0fMk9qp2CggLcunWrwnVaWlrSvfWvkkePHuHGjRuVrq/sSfnqwOnlRERERESV4/RyqpSpqSlMTU3ruxsvzNDQEIaGhvXdjTqlq6v7UhNrIiIiIiJSLybdRFQl88leVf5yR0REREREleM93URERERERERqwqSbiIiIiIiISE2YdBMRERERERGpCZNuIiIiIiIiIjVh0k1ERERERESkJky6iYiIiIiIiNSErwwjoird+eogCnX1ypWbB/eph94QEREREb1aeKWbiIiIiIiISE2YdBMRERERERGpCZNuIiIiIiIiIjVh0k1ERERERESkJky6iYiIiIiIiNSESTcRERERERGRmjDpfkOEh4fD2dm5yjpjx45F//79X0p/ACAzMxMymQwpKSkAgBMnTkAmk+Hvv/9+aX142Z4dMxERERERvd6YdL8h5syZg7i4uPruRpXeffdd5OTkwNjYuL67QkREREREVCc067sD9HIYGBjAwMCgvrtRpUaNGqFZs2b13Y1aE0KgtLQUmpr8vxURERERET3BK92vic2bN8PS0hJKpVKlvG/fvhgzZky56eWlpaUICQmBiYkJzMzMMHfuXAghVNoKIbB69WrY2NhAV1cX7du3x+7du1XqnDx5Eh07doS2tjYsLCwwf/58lJSUSOuVSiVWrVoFW1tbaGtro0WLFvjkk08qHMOz08ujoqJgYmKCffv2wc7ODjo6OujRoweys7NrFJMLFy7gvffeg6GhIYyMjODq6oqzZ89K6xMTE9G1a1fo6upCoVBg+vTpePDggbR+x44dcHNzg6GhIZo1a4YRI0bg9u3b5fp7+PBhuLm5QVtbG/Hx8TUa89WrV/Hee+9BT08P7du3xy+//FKjMQFAZGQkFAoF9PT0MGDAAKxbtw4mJiYqdZYtWwZzc3MYGhpiwoQJmD9/frW3FxARERERUd1j0v2aGDx4MO7evYvjx49LZX/99RcOHz6MwMDAcvUjIiKwdetWbNmyBT///DPu3buHvXv3qtRZtGgRtm3bhk2bNuHixYuYNWsWRo4ciZMnTwIAbty4gYCAALi7u+PChQvYtGkTtmzZgmXLlknbWLBgAVatWoXQ0FBcunQJ3333HZo2bVrjcT18+BCffPIJtm/fjoSEBOTn52PYsGE1ahsYGIi3334bZ86cQXJyMubPnw8tLS0AQGpqKvz9/TFw4ED8+uuv+P777/Hzzz9j6tSpUvvi4mIsXboUFy5cwL59+3Dt2jWMHTu23H7mzp2LFStWIC0tDU5OTjUa88KFCzFnzhykpKTAzs4Ow4cPV/mxojIJCQmYPHkyZsyYgZSUFPTo0aNcQr9z50588sknWLVqFZKTk9GiRQts2rSp2m0XFRUhPz9f5UNERERERC9I0Gujb9++IigoSFrevHmzaNasmSgpKRFhYWGiffv20joLCwuxcuVKafnx48fi7bffFv369RNCCHH//n2ho6MjEhMTVfYxfvx4MXz4cCGEEB999JGwt7cXSqVSWv/5558LAwMDUVpaKvLz84W2traIjIyssL/Xrl0TAMT58+eFEEIcP35cABB//fWXEEKIbdu2CQDi1KlTUpu0tDQBQCQlJVUbD0NDQxEVFVXhulGjRolJkyaplMXHxwsNDQ3x6NGjCtucPn1aABAFBQUq/d23b59Up6Zj/vrrr6WyixcvCgAiLS2t2jENHTpU9O7dW6UsMDBQGBsbS8udOnUSwcHBKnU8PT1Vjn9FwsLCBIByn4w10eLWZ/8u9yEiIiIiepPl5eUJACIvL6/KerzS/RoJDAzEnj17UFRUBODJFc9hw4ZBLper1MvLy0NOTg48PDykMk1NTbi5uUnLly5dQmFhIXr06CHdD25gYIBvvvkGV65cAQCkpaXBw8MDMplMaufp6Yn79+/j+vXrSEtLQ1FREXx8fGo9pmf75eDgABMTE6SlpVXbNiQkBBMmTICvry9Wrlwp9RsAkpOTERUVpTI2f39/KJVKXLt2DQBw/vx59OvXD1ZWVjA0NES3bt0AAFlZWSr7ebp/NR2zk5OT9N8WFhYAoDJ1vTLp6eno2LGjStmzyzWpU5EFCxYgLy9P+tR0Gj8REREREVWOT3x6jfTp0wdKpRIHDhyAu7s74uPjsW7dulptq+ze8AMHDsDS0lJlnba2NoAn93w/nXCXlQGATCaDrq5urfb9rGf3UVnZs8LDwzFixAgcOHAABw8eRFhYGKKjozFgwAAolUr885//xPTp08u1a9GiBR48eAA/Pz/4+flhx44daNKkCbKysuDv74/i4mKV+vr6+tJ/13TMZdPcnx7Ls/fjV6SqmD+tJnWepa2tLR1bIiIiIiKqG7zS/RrR1dXFwIEDsXPnTuzatQt2dnZwdXUtV8/Y2BgWFhY4deqUVFZSUoLk5GRpuU2bNtDW1kZWVhZsbW1VPgqFQqqTmJioktAlJibC0NAQlpaWeOedd6Crq/tCryorKSlRefhZeno6/v77bzg4ONSovZ2dHWbNmoUjR45g4MCB2LZtGwDAxcUFFy9eLDc2W1tbNGrUCL///jvu3r2LlStXwsvLCw4ODjW6El0XY66Kg4MDTp8+rVL2dHwAwN7evto6RERERET0cvBK92smMDAQffr0wcWLFzFy5MhK682YMQMrV67EO++8g9atW2PdunXSU8MBwNDQEHPmzMGsWbOgVCrRpUsX5OfnIzExEQYGBhgzZgymTJmCDRs2YNq0aZg6dSrS09MRFhaGkJAQaGhoQEdHB/PmzcPcuXPRqFEjeHp64s6dO7h48SLGjx9fo/FoaWlh2rRp+PTTT6GlpYWpU6eic+fO1U6XfvToET788EMMGjQILVu2xPXr13HmzBn84x//AADMmzcPnTt3RnBwMCZOnAh9fX2kpaUhNjYWGzduRIsWLdCoUSNs3LgRkydPxm+//YalS5dW29+6GHNVpk2bhq5du2LdunXo06cPjh07hoMHD6pc2Z42bRomTpwINzc3vPvuu/j+++/x66+/wsbG5oX3T0REREREz4dJ92ume/fuMDU1RXp6OkaMGFFpvdmzZyMnJwdjx46FhoYGgoKCMGDAAOTl5Ul1li5dCnNzc6xYsQJXr16FiYkJXFxc8NFHHwEALC0tERMTgw8//BDt27eHqakpxo8fj0WLFknbCA0NhaamJhYvXoybN2/CwsICkydPrvF49PT0MG/ePIwYMQLXr19Hly5dsHXr1mrbyeVy/Pnnnxg9ejRu3bqFt956CwMHDsSSJUsAPLmn+uTJk1i4cCG8vLwghECrVq0wdOhQAECTJk0QFRWFjz76CJ9++ilcXFywdu1a9O3bt9p9v+iYq+Lp6Ykvv/wSS5YswaJFi+Dv749Zs2bhs88+k+oEBgbi6tWrmDNnDgoLCzFkyBCMHTu23NVvIiIiIiJSP5moyc2eRPUgKioKM2fOVLkCT+VNnDgRv//+O+Lj4yut06NHDzRr1gzffvttjbebn58PY2NjZKyJhqGuXrn15sF9atVfIiIiIqLXQdnfy3l5eTAyMqq0Hq90E71i1q5dix49ekBfXx8HDx7E9u3b8cUXX0jrHz58iC+//BL+/v6Qy+XYtWsXjh49itjY2HrsNRERERHRm4kPUqNXVtu2bVVe+fX0Z+fOnfXdvVrp1atXpWNavnw5AOD06dPo0aMHHB0d8eWXX+LTTz/FhAkTpG3IZDLExMTAy8sLrq6u2L9/P/bs2QNfX9/6GhYRERER0RuL08vplfWf//wHjx8/rnBd06ZNYWho+JJ79OJu3LiBR48eVbjO1NQUpqamL60vnF5ORERERFQ5Ti+n156VlVV9d6HOPftOdCIiIiIierVxejkRERERERGRmvBKNxFVqcmkXlVOlyEiIiIiosrxSjcRERERERGRmvBKNxFVqOwZi/n5+fXcEyIiIiKihqfs7+Tqnk3OpJuIKvTnn38CABQKRT33hIiIiIio4SooKICxsXGl65l0E1GFyl5PlpWVVeU/IlQz+fn5UCgUyM7O5j3yL4ixrFuMZ91iPOsW41l3GMu6xXjWrVc1nkIIFBQUoHnz5lXWY9JNRBXS0HjyyAdjY+NX6h+/hs7IyIjxrCOMZd1iPOsW41m3GM+6w1jWLcazbr2K8azJxSk+SI2IiIiIiIhITZh0ExEREREREakJk24iqpC2tjbCwsKgra1d3115LTCedYexrFuMZ91iPOsW41l3GMu6xXjWrdc9njJR3fPNiYiIiIiIiKhWeKWbiIiIiIiISE2YdBMRERERERGpCZNuIiIiIiIiIjVh0k1ERERERESkJky6id4QX3zxBVq2bAkdHR24uroiPj6+yvonT56Eq6srdHR0YGNjgy+//LJcnT179qBNmzbQ1tZGmzZtsHfvXnV1v8Gp63hGRkbCy8sLjRs3RuPGjeHr64vTp0+rcwgNijq+n2Wio6Mhk8nQv3//Ou51w6WOeP79998IDg6GhYUFdHR00Lp1a8TExKhrCA2GOmK5YcMG2NvbQ1dXFwqFArNmzUJhYaG6htCgPE88c3JyMGLECNjb20NDQwMzZ86ssB7PRXUXT56L6v77WeZNOxepI5av9HlIENFrLzo6WmhpaYnIyEhx6dIlMWPGDKGvry/+85//VFj/6tWrQk9PT8yYMUNcunRJREZGCi0tLbF7926pTmJiopDL5WL58uUiLS1NLF++XGhqaopTp069rGHVG3XEc8SIEeLzzz8X58+fF2lpaWLcuHHC2NhYXL9+/WUNq96oI55lMjMzhaWlpfDy8hL9+vVT80gaBnXEs6ioSLi5uYmAgADx888/i8zMTBEfHy9SUlJe1rDqhTpiuWPHDqGtrS127twprl27Jg4fPiwsLCzEzJkzX9aw6s3zxvPatWti+vTpYvv27cLZ2VnMmDGjXB2ei+o2njwX1W08y7xp5yJ1xPJVPw8x6SZ6A3Ts2FFMnjxZpczBwUHMnz+/wvpz584VDg4OKmX//Oc/RefOnaXlIUOGiJ49e6rU8ff3F8OGDaujXjdc6ojns0pKSoShoaHYvn37i3e4gVNXPEtKSoSnp6f4+uuvxZgxY96IP3SEUE88N23aJGxsbERxcXHdd7gBU0csg4ODRffu3VXqhISEiC5dutRRrxuu543n07y9vSv8Q5znorqN57N4LnrxeL6J5yJ1xPJVPw9xejnRa664uBjJycnw8/NTKffz80NiYmKFbX755Zdy9f39/XH27Fk8fvy4yjqVbfN1oa54Puvhw4d4/PgxTE1N66bjDZQ64/nxxx+jSZMmGD9+fN13vIFSVzz//e9/w8PDA8HBwWjatCnatWuH5cuXo7S0VD0DaQDUFcsuXbogOTlZmrJ79epVxMTEoHfv3moYRcNRm3jWBM9FdRvPZ/Fc9OLxfNPOReqK5at+HtKs7w4QkXrdvXsXpaWlaNq0qUp506ZNkZubW2Gb3NzcCuuXlJTg7t27sLCwqLROZdt8Xagrns+aP38+LC0t4evrW3edb4DUFc+EhARs2bIFKSkp6up6g6SueF69ehXHjh1DYGAgYmJicPnyZQQHB6OkpASLFy9W23jqk7piOWzYMNy5cwddunSBEAIlJSX44IMPMH/+fLWNpSGoTTxrguci9Y6d56IXi+ebeC5SVyxf9fMQk26iN4RMJlNZFkKUK6uu/rPlz7vN14k64llm9erV2LVrF06cOAEdHZ066G3DV5fxLCgowMiRIxEZGYm33nqr7jv7Cqjr76dSqYS5uTm++uoryOVyuLq64ubNm1izZs0r8cfOi6jrWJ44cQKffPIJvvjiC3Tq1AkZGRmYMWMGLCwsEBoaWse9b3jUcd7guei/6nLsPBe9WDzf9HNRXX83X/XzEJNuotfcW2+9BblcXu7Xxdu3b5f7FbJMs2bNKqyvqakJMzOzKutUts3XhbriWWbt2rVYvnw5jh49Cicnp7rtfAOkjnhevHgRmZmZ6NOnj7ReqVQCADQ1NZGeno5WrVrV8UgaBnV9Py0sLKClpQW5XC7Vad26NXJzc1FcXIxGjRrV8Ujqn7piGRoailGjRmHChAkAAEdHRzx48ACTJk3CwoULoaHxet75V5t41gTPReoZO89FT7xIPK9cufJGnovU9d181c9Dr+e/7EQkadSoEVxdXREbG6tSHhsbi3fffbfCNh4eHuXqHzlyBG5ubtDS0qqyTmXbfF2oK54AsGbNGixduhSHDh2Cm5tb3Xe+AVJHPB0cHJCamoqUlBTp07dvX7z33ntISUmBQqFQ23jqm7q+n56ensjIyJD+YASAP/74AxYWFg3+D53aUlcsHz58WC6xlsvlEE8ebluHI2hYahPPmuC5qG7jCfBc9LQXieebei5S13fzlT8PveQHtxFRPSh7dcOWLVvEpUuXxMyZM4W+vr7IzMwUQggxf/58MWrUKKl+2WtvZs2aJS5duiS2bNlS7rU3CQkJQi6Xi5UrV4q0tDSxcuXKN+41LXUZz1WrVolGjRqJ3bt3i5ycHOlTUFDw0sf3sqkjns96U54YK4R64pmVlSUMDAzE1KlTRXp6uvjxxx+Fubm5WLZs2Usf38ukjliGhYUJQ0NDsWvXLnH16lVx5MgR0apVKzFkyJCXPr6X7XnjKYQQ58+fF+fPnxeurq5ixIgR4vz58+LixYvSep6L6jaePBfVbTyf9aaci9QRy1f9PMSkm+gN8fnnnwsrKyvRqFEj4eLiIk6ePCmtGzNmjPD29lapf+LECdGhQwfRqFEjYW1tLTZt2lRum//7v/8r7O3thZaWlnBwcBB79uxR9zAajLqOp5WVlQBQ7hMWFvYSRlP/1PH9fNqb8odOGXXEMzExUXTq1Eloa2sLGxsb8cknn4iSkhJ1D6Xe1XUsHz9+LMLDw0WrVq2Ejo6OUCgUYsqUKeKvv/56CaOpf88bz4r+XbSyslKpw3NR3cWT56K6/34+7U06F6kjlq/yeUgmxGs8l4mIiIiIiIioHvGebiIiIiIiIiI1YdJNREREREREpCZMuomIiIiIiIjUhEk3ERERERERkZow6SYiIiIiIiJSEybdRERERERERGrCpJuIiIiIiIhITZh0ExEREREREakJk24iIiIiIiIiNWHSTURERERERKQmTLqJiIiIXiOPHz+u7y4QEdFTmHQTERERvQS7d++Go6MjdHV1YWZmBl9fXzx48AAAsHXrVrRt2xba2tqwsLDA1KlTpXZZWVno168fDAwMYGRkhCFDhuDWrVvS+vDwcDg7O2Pr1q2wsbGBtrY2hBDIy8vDpEmTYG5uDiMjI3Tv3h0XLlx46eMmInrTMekmIiIiUrOcnBwMHz4cQUFBSEtLw4kTJzBw4EAIIbBp0yYEBwdj0qRJSE1Nxb///W/Y2toCAIQQ6N+/P+7du4eTJ08iNjYWV65cwdChQ1W2n5GRgR9++AF79uxBSkoKAKB3797Izc1FTEwMkpOT4eLiAh8fH9y7d+9lD5+I6I0mE0KI+u4EERER0evs3LlzcHV1RWZmJqysrFTWWVpaYty4cVi2bFm5drGxsejVqxeuXbsGhUIBALh06RLatm2L06dPw93dHeHh4Vi+fDlu3LiBJk2aAACOHTuGAQMG4Pbt29DW1pa2Z2tri7lz52LSpElqHC0RET1Ns747QERERPS6a9++PXx8fODo6Ah/f3/4+flh0KBBePz4MW7evAkfH58K26WlpUGhUEgJNwC0adMGJiYmSEtLg7u7OwDAyspKSrgBIDk5Gffv34eZmZnK9h49eoQrV66oYYRERFQZJt1EREREaiaXyxEbG4vExEQcOXIEGzduxMKFCxEXF1dlOyEEZDJZteX6+voq65VKJSwsLHDixIlybU1MTGo1BiIiqh0m3UREREQvgUwmg6enJzw9PbF48WJYWVkhNjYW1tbWiIuLw3vvvVeuTZs2bZCVlYXs7GyV6eV5eXlo3bp1pftycXFBbm4uNDU1YW1tra4hERFRDTDpJiIiIlKzpKQkxMXFwc/PD+bm5khKSsKdO3fQunVrhIeHY/LkyTA3N0evXr1QUFCAhIQETJs2Db6+vnByckJgYCA2bNiAkpISTJkyBd7e3nBzc6t0f76+vvDw8ED//v2xatUq2Nvb4+bNm4iJiUH//v2rbEtERHWLSTcRERGRmhkZGeGnn37Chg0bkJ+fDysrK0RERKBXr14AgMLCQqxfvx5z5szBW2+9hUGDBgF4cnV83759mDZtGrp27QoNDQ307NkTGzdurHJ/MpkMMTExWLhwIYKCgnDnzh00a9YMXbt2RdOmTdU+XiIi+i8+vZyIiIiIiIhITfiebiIiIiIiIiI1YdJNREREREREpCZMuomIiIiIiIjUhEk3ERERERERkZow6SYiIiIiIiJSEybdRERERERERGrCpJuIiIiIiIhITZh0ExEREREREakJk24iIiIiIiIiNWHSTURERERERKQmTLqJiIiIiIiI1OT/AW+Y1KArf5UNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the average feature importance across all folds\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(y='features', x='score', data=f.sort_values('score', ascending=False).head(30))\n",
    "plt.title('Average Feature Importances Across Folds')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>score_0</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>active_day</td>\n",
       "      <td>0.159296</td>\n",
       "      <td>0.155740</td>\n",
       "      <td>0.166424</td>\n",
       "      <td>0.169607</td>\n",
       "      <td>0.163285</td>\n",
       "      <td>0.162870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>not_active_day</td>\n",
       "      <td>0.146794</td>\n",
       "      <td>0.139832</td>\n",
       "      <td>0.138555</td>\n",
       "      <td>0.141981</td>\n",
       "      <td>0.142118</td>\n",
       "      <td>0.141856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>age_group_unknown</td>\n",
       "      <td>0.095493</td>\n",
       "      <td>0.099811</td>\n",
       "      <td>0.100184</td>\n",
       "      <td>0.098792</td>\n",
       "      <td>0.095811</td>\n",
       "      <td>0.098018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gender_unknown</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>0.087044</td>\n",
       "      <td>0.088489</td>\n",
       "      <td>0.086558</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.087166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>signin_count</td>\n",
       "      <td>0.061569</td>\n",
       "      <td>0.063233</td>\n",
       "      <td>0.061272</td>\n",
       "      <td>0.057957</td>\n",
       "      <td>0.062069</td>\n",
       "      <td>0.061220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>province_Kon Tum</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>province_Sơn La</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>province_Cao Bằng</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>province_Hà Giang</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>province_Lai Châu</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              features   score_0   score_1   score_2   score_3   score_4  \\\n",
       "104         active_day  0.159296  0.155740  0.166424  0.169607  0.163285   \n",
       "106     not_active_day  0.146794  0.139832  0.138555  0.141981  0.142118   \n",
       "9    age_group_unknown  0.095493  0.099811  0.100184  0.098792  0.095811   \n",
       "12      gender_unknown  0.087071  0.087044  0.088489  0.086558  0.086667   \n",
       "116       signin_count  0.061569  0.063233  0.061272  0.057957  0.062069   \n",
       "..                 ...       ...       ...       ...       ...       ...   \n",
       "50    province_Kon Tum  0.000006  0.000004  0.000005  0.000004  0.000005   \n",
       "68     province_Sơn La  0.000003  0.000005  0.000004  0.000004  0.000005   \n",
       "34   province_Cao Bằng  0.000004  0.000004  0.000005  0.000006  0.000003   \n",
       "39   province_Hà Giang  0.000005  0.000004  0.000005  0.000004  0.000003   \n",
       "51   province_Lai Châu  0.000004  0.000003  0.000003  0.000004  0.000003   \n",
       "\n",
       "        score  \n",
       "104  0.162870  \n",
       "106  0.141856  \n",
       "9    0.098018  \n",
       "12   0.087166  \n",
       "116  0.061220  \n",
       "..        ...  \n",
       "50   0.000005  \n",
       "68   0.000004  \n",
       "34   0.000004  \n",
       "39   0.000004  \n",
       "51   0.000003  \n",
       "\n",
       "[123 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv('/Users/natalie/Desktop/DS Thesis/user-churn-prediction/outputs/random_forest_top_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = pd.read_csv('/Users/natalie/Desktop/DS Thesis/user-churn-prediction/outputs/random_forest_top_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = f.features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESTIMATORS = 200\n",
    "SEED=42\n",
    "LGBM_Hyperparameters =  {\n",
    "    \"n_estimators\": N_ESTIMATORS,\n",
    "    'learning_rate':0.03,\n",
    "     'max_depth':8,\n",
    "     #'num_leaves': 2**8,\n",
    "     'colsample_bytree':0.8,\n",
    "     'subsample':0.8,\n",
    "     # 'reg_alpha':8,\n",
    "     # 'reg_lambda':32,\n",
    "\n",
    "    \"random_state\":SEED #,\n",
    "    #'device':'gpu',\n",
    "#     \"class_weight\": \"balanced\"\n",
    "}\n",
    "\n",
    "XGBoost_Hyperparameters = {\n",
    "    'objective' : 'binary:logistic',\n",
    "     'eval_metric':['logloss', 'auc'],\n",
    "     'n_estimators':N_ESTIMATORS,\n",
    "     'learning_rate':0.03,\n",
    "     'max_depth':8,\n",
    "     'colsample_bytree':0.5,\n",
    "     'subsample':0.8,\n",
    "     'reg_alpha':8,\n",
    "     'reg_lambda':32,\n",
    "     'seed':SEED,\n",
    "     # 'scale_pos_weight':3,\n",
    "     'enable_categorical':True,\n",
    "     'early_stopping_rounds': 50 #,\n",
    "     #'tree_method':'gpu_hist'\n",
    "     }\n",
    "RF_Hyperparameters = {\n",
    "    'n_estimators': N_ESTIMATORS,\n",
    "    'max_depth':8,\n",
    "    'random_state':SEED,\n",
    "    'max_features': 'sqrt', \n",
    "    'n_jobs': -1\n",
    "}\n",
    "Logreg_Hyperparameters = {'max_iter':N_ESTIMATORS,'random_state':SEED} \n",
    "MLP_Hyperparametesr = {'hidden_layer_sizes':(3,125), 'random_state':SEED, 'max_iter':min(N_ESTIMATORS,100)}\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "def cross_validate(train, FEATURES=None, USE_SMOTE=False, USE_CLASS_WEIGHT=False, USE_UNDER_SAMPLING=False):\n",
    "    oofs = np.zeros((train.shape[0], len(MODEL_NAMES)))\n",
    "    for i, (train_index, valid_index) in enumerate(kfold.split(train, train[TARGET])):\n",
    "        print(f\"===========fold {i}================\")\n",
    "        X_train, oh_encoder, robust_scaler = process_data(train.iloc[train_index])\n",
    "        X_valid, _, _  = process_data(train.iloc[valid_index], oh_encoder,robust_scaler)\n",
    "        if FEATURES is not None:\n",
    "            print(\"Number of features\", len(FEATURES))\n",
    "            X_train = X_train[FEATURES]\n",
    "            X_valid = X_valid[FEATURES]\n",
    "        print(X_train.isnull().sum())\n",
    "        y_train = train.iloc[train_index][TARGET].values\n",
    "        y_valid = train.iloc[valid_index][TARGET].values\n",
    "        logreg_hyperparameters = Logreg_Hyperparameters.copy()\n",
    "        lgb_hyperparameters = LGBM_Hyperparameters.copy()\n",
    "        xgboost_hyperparameters = XGBoost_Hyperparameters.copy()\n",
    "        rf_hyperparameters = RF_Hyperparameters.copy()\n",
    "        mlp_hyperparameters = MLP_Hyperparametesr.copy()\n",
    "        if USE_SMOTE:\n",
    "            print(\"SMOTEEEE\")\n",
    "            sm = SMOTE(random_state=42)\n",
    "            X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        elif USE_CLASS_WEIGHT:\n",
    "            print(\"CLASS_WEIGHTTTT\")\n",
    "           \n",
    "            class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train)\n",
    "            class_weights =  {0: class_weights[0], 1: class_weights[1]}\n",
    "            lgb_hyperparameters['class_weight'] = class_weights\n",
    "            logreg_hyperparameters['class_weight'] = class_weights\n",
    "            xgboost_hyperparameters['scale_pos_weight'] = class_weights[1] /  class_weights[0]\n",
    "            rf_hyperparameters['class_weight'] = class_weights\n",
    "        elif USE_UNDER_SAMPLING:\n",
    "            print(\"UNDER SAMPLING\")\n",
    "            rus = RandomUnderSampler(random_state=42)\n",
    "            X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "        print(\"LOGREG--------------\")\n",
    "        logreg_model = LogisticRegression(**logreg_hyperparameters)\n",
    "        logreg_model.fit(X_train, y_train)\n",
    "        logreg_y_pred_proba = logreg_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, logreg_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in logreg_y_pred_proba]\n",
    "\n",
    "        print(roc_auc_score(y_valid, logreg_y_pred_proba))\n",
    "\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index,0] = logreg_y_pred_proba\n",
    "\n",
    "        print(\"Random Forest--------------\")\n",
    "        rf_model = RandomForestClassifier(**rf_hyperparameters)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_y_pred_proba = rf_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, rf_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in rf_y_pred_proba]\n",
    "\n",
    "        print(roc_auc_score(y_valid, rf_y_pred_proba))\n",
    "\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index,1] = rf_y_pred_proba\n",
    "    #     models.append(model)\n",
    "        print(\"LGBModel--------------\")\n",
    "        lgb_model = LGBMClassifier(**lgb_hyperparameters)\n",
    "        callbacks = [lgb.early_stopping(200, verbose=50), lgb.log_evaluation(period=50)]\n",
    "        lgb_model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                  eval_metric=[\"logloss\", \"auc\"],\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "        lgb_y_pred_proba = lgb_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, lgb_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in lgb_y_pred_proba]\n",
    "        print(roc_auc_score(y_valid, lgb_y_pred_proba))\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index,2] = lgb_y_pred_proba\n",
    "    #     models.append(model)\n",
    "        # display(pd.DataFrame({'score': lgb_model.feature_importances_, 'feature': lgb_model.feature_name_}).sort_values('score',ascending=False))\n",
    "\n",
    "        print(\"XGBoost--------------\")\n",
    "        xgb_model = XGBClassifier(**xgboost_hyperparameters)\n",
    "        xgb_model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                  verbose=50)\n",
    "        xgb_y_pred_proba = xgb_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, xgb_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in xgb_y_pred_proba]\n",
    "        print(roc_auc_score(y_valid, xgb_y_pred_proba))\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index, 3] = xgb_y_pred_proba\n",
    "        \n",
    "        print(\"MLP------------------\")\n",
    "        mlp_model = MLPClassifier(**mlp_hyperparameters)\n",
    "        mlp_model.fit(X_train, y_train)\n",
    "        mlp_y_pred_proba = mlp_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, mlp_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in mlp_y_pred_proba]\n",
    "        print(roc_auc_score(y_valid, mlp_y_pred_proba))\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index, 4] = mlp_y_pred_proba\n",
    "    return oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "specificity_scores = []\n",
    "sensitivity_scores = []\n",
    "def scoring(y_test,y_pred_proba, best_threshold):\n",
    "    y_pred = [1 if y_hat >= best_threshold else 0 for y_hat in y_pred_proba]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    _f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    print(\"accuracy\", acc)\n",
    "    print(\"f1_score\", _f1_score)\n",
    "    print(\"auc\", auc_score)\n",
    "    print(\"sensitivity\", sensitivity, \"specificity\", specificity)\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    return acc, _f1_score, auc_score, specificity, sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(oofs,X_train, y_train, X_test, y_test, USE_SMOTE=False,USE_CLASS_WEIGHT=False, USE_UNDER_SAMPLING=False):\n",
    "    models = []\n",
    "    predictions = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "    specificity_scores = []\n",
    "    sensitivity_scores = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(MODEL_NAMES)):\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(train[TARGET].values, oofs[:,i])\n",
    "        best_thresholds.append(best_threshold)\n",
    "        print('\\n',best_threshold, best_score)\n",
    "    logreg_hyperparameters = Logreg_Hyperparameters.copy()\n",
    "    lgb_hyperparameters = LGBM_Hyperparameters.copy()\n",
    "    xgboost_hyperparameters = XGBoost_Hyperparameters.copy()\n",
    "    del xgboost_hyperparameters['early_stopping_rounds']\n",
    "    rf_hyperparameters = RF_Hyperparameters.copy()\n",
    "    mlp_hyperparameters = MLP_Hyperparametesr.copy()\n",
    "    if USE_SMOTE:\n",
    "        print(\"SMOTEEEE\")\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    elif USE_CLASS_WEIGHT:\n",
    "        print(\"CLASS_WEIGHTTTT\")\n",
    "        class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train)\n",
    "        class_weights =  {0: class_weights[0], 1: class_weights[1]}\n",
    "        lgb_hyperparameters['class_weight'] = class_weights\n",
    "        logreg_hyperparameters['class_weight'] = class_weights\n",
    "        xgboost_hyperparameters['scale_pos_weight'] = class_weights[1]/ class_weights[0]\n",
    "        rf_hyperparameters['class_weight'] = class_weights\n",
    "    elif USE_UNDER_SAMPLING:\n",
    "        print(\"UNDER SAMPLING\")\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "    print(\"LOGREG--------------\")\n",
    "    logreg_model = LogisticRegression(**logreg_hyperparameters)\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    logreg_y_pred_proba = logreg_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,logreg_y_pred_proba,best_thresholds[0])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(logreg_y_pred_proba)\n",
    "    models.append(logreg_model)\n",
    "\n",
    "    print(\"Random Forest--------------\")\n",
    "    rf_model = RandomForestClassifier(**rf_hyperparameters)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_y_pred_proba = rf_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,rf_y_pred_proba,best_thresholds[1])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(rf_y_pred_proba)\n",
    "    models.append(rf_model)\n",
    "\n",
    "    print(\"LGBModel--------------\")\n",
    "    lgb_model = LGBMClassifier(**lgb_hyperparameters)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    lgb_y_pred_proba = lgb_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,lgb_y_pred_proba,best_thresholds[2])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(lgb_y_pred_proba)\n",
    "    models.append(lgb_model)\n",
    "\n",
    "    print(\"XGBoost--------------\")\n",
    "    print(xgboost_hyperparameters)\n",
    "    xgb_model = XGBClassifier(**xgboost_hyperparameters)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_y_pred_proba = xgb_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,xgb_y_pred_proba,best_thresholds[3])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(xgb_y_pred_proba)\n",
    "    models.append(xgb_model)\n",
    "    \n",
    "    print(\"MLP--------------\")\n",
    "    mlp_model = MLPClassifier(**mlp_hyperparameters)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    mlp_y_pred_proba = mlp_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,mlp_y_pred_proba,best_thresholds[4])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(mlp_y_pred_proba)\n",
    "    models.append(mlp_model)\n",
    "\n",
    "    print(MODEL_NAMES)\n",
    "    print(accuracy_scores)\n",
    "    print(f1_scores)\n",
    "    print(auc_scores)\n",
    "    print(specificity_scores)\n",
    "    print(sensitivity_scores)\n",
    "    score_df = pd.DataFrame({'model_name': MODEL_NAMES,\n",
    "                         'accuracy_score':accuracy_scores, \n",
    "                         'f1_score': f1_scores, \n",
    "                         'auc_score': auc_scores, \n",
    "                         'specificity_score': specificity_scores, \n",
    "                         'sensitivity_score': sensitivity_scores})\n",
    "    return score_df,models, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n"
     ]
    }
   ],
   "source": [
    "X_train,oh_encoder,robust_scaler = process_data(train)\n",
    "X_test, _,_ = process_data(test,oh_encoder,robust_scaler)\n",
    "y_train = train[TARGET].values\n",
    "y_test = test[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========fold 0================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 10\n",
      "active_day           0\n",
      "not_active_day       0\n",
      "age_group_unknown    0\n",
      "gender_unknown       0\n",
      "signin_count         0\n",
      "newtab_count         0\n",
      "ads_impression       0\n",
      "clicks               0\n",
      "life_time            0\n",
      "ads_revenue          0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7626944581010868\n",
      "0.8785232474647239\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8900    0.8703    0.8801    251891\n",
      "           1     0.6247    0.6674    0.6453     81443\n",
      "\n",
      "    accuracy                         0.8208    333334\n",
      "   macro avg     0.7573    0.7689    0.7627    333334\n",
      "weighted avg     0.8252    0.8208    0.8227    333334\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7807241624024319\n",
      "0.8977639965284635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9048    0.8684    0.8862    251891\n",
      "           1     0.6379    0.7173    0.6753     81443\n",
      "\n",
      "    accuracy                         0.8314    333334\n",
      "   macro avg     0.7713    0.7928    0.7807    333334\n",
      "weighted avg     0.8396    0.8314    0.8346    333334\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1444\n",
      "[LightGBM] [Info] Number of data points in the train set: 666666, number of used features: 10\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129097\n",
      "[LightGBM] [Info] Start training from score -1.129097\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358965\ttraining's auc: 0.898196\tvalid_1's binary_logloss: 0.359561\tvalid_1's auc: 0.897526\n",
      "[100]\ttraining's binary_logloss: 0.334592\ttraining's auc: 0.899464\tvalid_1's binary_logloss: 0.335546\tvalid_1's auc: 0.898625\n",
      "[150]\ttraining's binary_logloss: 0.330182\ttraining's auc: 0.900134\tvalid_1's binary_logloss: 0.33145\tvalid_1's auc: 0.899121\n",
      "[200]\ttraining's binary_logloss: 0.328858\ttraining's auc: 0.900619\tvalid_1's binary_logloss: 0.330494\tvalid_1's auc: 0.899375\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.328858\ttraining's auc: 0.900619\tvalid_1's binary_logloss: 0.330494\tvalid_1's auc: 0.899375\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7813717269546931\n",
      "0.899375058396769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9077    0.8636    0.8851    251891\n",
      "           1     0.6333    0.7285    0.6776     81443\n",
      "\n",
      "    accuracy                         0.8306    333334\n",
      "   macro avg     0.7705    0.7961    0.7814    333334\n",
      "weighted avg     0.8407    0.8306    0.8344    333334\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54861\tvalidation_0-auc:0.83685\tvalidation_1-logloss:0.54865\tvalidation_1-auc:0.83593\n",
      "[50]\tvalidation_0-logloss:0.36404\tvalidation_0-auc:0.89739\tvalidation_1-logloss:0.36519\tvalidation_1-auc:0.89608\n",
      "[100]\tvalidation_0-logloss:0.33683\tvalidation_0-auc:0.89958\tvalidation_1-logloss:0.33879\tvalidation_1-auc:0.89785\n",
      "[150]\tvalidation_0-logloss:0.33045\tvalidation_0-auc:0.90078\tvalidation_1-logloss:0.33301\tvalidation_1-auc:0.89872\n",
      "[199]\tvalidation_0-logloss:0.32835\tvalidation_0-auc:0.90150\tvalidation_1-logloss:0.33139\tvalidation_1-auc:0.89913\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7814352478204216\n",
      "0.8991292093926174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9069    0.8654    0.8856    251891\n",
      "           1     0.6352    0.7252    0.6772     81443\n",
      "\n",
      "    accuracy                         0.8311    333334\n",
      "   macro avg     0.7711    0.7953    0.7814    333334\n",
      "weighted avg     0.8405    0.8311    0.8347    333334\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7784198607981363\n",
      "0.8963533753310687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9075    0.8596    0.8829    251891\n",
      "           1     0.6267    0.7289    0.6739     81443\n",
      "\n",
      "    accuracy                         0.8277    333334\n",
      "   macro avg     0.7671    0.7943    0.7784    333334\n",
      "weighted avg     0.8389    0.8277    0.8318    333334\n",
      "\n",
      "===========fold 1================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 10\n",
      "active_day           0\n",
      "not_active_day       0\n",
      "age_group_unknown    0\n",
      "gender_unknown       0\n",
      "signin_count         0\n",
      "newtab_count         0\n",
      "ads_impression       0\n",
      "clicks               0\n",
      "life_time            0\n",
      "ads_revenue          0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7632857611237953\n",
      "0.8786903695471153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8916    0.8679    0.8796    251891\n",
      "           1     0.6224    0.6736    0.6470     81442\n",
      "\n",
      "    accuracy                         0.8204    333333\n",
      "   macro avg     0.7570    0.7707    0.7633    333333\n",
      "weighted avg     0.8258    0.8204    0.8227    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7805713647088558\n",
      "0.8980532805567047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9091    0.8598    0.8838    251891\n",
      "           1     0.6287    0.7343    0.6774     81442\n",
      "\n",
      "    accuracy                         0.8291    333333\n",
      "   macro avg     0.7689    0.7970    0.7806    333333\n",
      "weighted avg     0.8406    0.8291    0.8333    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162886, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1445\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 10\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244329 -> initscore=-1.129091\n",
      "[LightGBM] [Info] Start training from score -1.129091\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.359163\ttraining's auc: 0.897943\tvalid_1's binary_logloss: 0.359371\tvalid_1's auc: 0.897888\n",
      "[100]\ttraining's binary_logloss: 0.334804\ttraining's auc: 0.899254\tvalid_1's binary_logloss: 0.335179\tvalid_1's auc: 0.899065\n",
      "[150]\ttraining's binary_logloss: 0.330425\ttraining's auc: 0.899916\tvalid_1's binary_logloss: 0.331084\tvalid_1's auc: 0.89955\n",
      "[200]\ttraining's binary_logloss: 0.329088\ttraining's auc: 0.900406\tvalid_1's binary_logloss: 0.330047\tvalid_1's auc: 0.899836\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.329088\ttraining's auc: 0.900406\tvalid_1's binary_logloss: 0.330047\tvalid_1's auc: 0.899836\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7814276579671169\n",
      "0.8998358706924219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9044    0.8701    0.8869    251891\n",
      "           1     0.6404    0.7156    0.6759     81442\n",
      "\n",
      "    accuracy                         0.8323    333333\n",
      "   macro avg     0.7724    0.7929    0.7814    333333\n",
      "weighted avg     0.8399    0.8323    0.8354    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54860\tvalidation_0-auc:0.83706\tvalidation_1-logloss:0.54864\tvalidation_1-auc:0.83551\n",
      "[50]\tvalidation_0-logloss:0.36419\tvalidation_0-auc:0.89719\tvalidation_1-logloss:0.36511\tvalidation_1-auc:0.89626\n",
      "[100]\tvalidation_0-logloss:0.33704\tvalidation_0-auc:0.89936\tvalidation_1-logloss:0.33850\tvalidation_1-auc:0.89821\n",
      "[150]\tvalidation_0-logloss:0.33073\tvalidation_0-auc:0.90053\tvalidation_1-logloss:0.33259\tvalidation_1-auc:0.89917\n",
      "[199]\tvalidation_0-logloss:0.32860\tvalidation_0-auc:0.90127\tvalidation_1-logloss:0.33093\tvalidation_1-auc:0.89961\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.7813099454078947\n",
      "0.8996107574328115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9122    0.8553    0.8828    251891\n",
      "           1     0.6248    0.7454    0.6798     81442\n",
      "\n",
      "    accuracy                         0.8284    333333\n",
      "   macro avg     0.7685    0.8003    0.7813    333333\n",
      "weighted avg     0.8420    0.8284    0.8332    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7783578524078927\n",
      "0.8967786163287566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9072    0.8601    0.8830    251891\n",
      "           1     0.6271    0.7278    0.6737     81442\n",
      "\n",
      "    accuracy                         0.8278    333333\n",
      "   macro avg     0.7671    0.7939    0.7784    333333\n",
      "weighted avg     0.8387    0.8278    0.8319    333333\n",
      "\n",
      "===========fold 2================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 10\n",
      "active_day           0\n",
      "not_active_day       0\n",
      "age_group_unknown    0\n",
      "gender_unknown       0\n",
      "signin_count         0\n",
      "newtab_count         0\n",
      "ads_impression       0\n",
      "clicks               0\n",
      "life_time            0\n",
      "ads_revenue          0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4199999999999998 best_score 0.7627629072385498\n",
      "0.8786985129842113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8876    0.8758    0.8817    251890\n",
      "           1     0.6311    0.6571    0.6438     81443\n",
      "\n",
      "    accuracy                         0.8224    333333\n",
      "   macro avg     0.7594    0.7664    0.7628    333333\n",
      "weighted avg     0.8250    0.8224    0.8236    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.780810002591383\n",
      "0.8979167804865984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9042    0.8696    0.8866    251890\n",
      "           1     0.6393    0.7150    0.6751     81443\n",
      "\n",
      "    accuracy                         0.8318    333333\n",
      "   macro avg     0.7718    0.7923    0.7808    333333\n",
      "weighted avg     0.8395    0.8318    0.8349    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1447\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 10\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244327 -> initscore=-1.129099\n",
      "[LightGBM] [Info] Start training from score -1.129099\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.359065\ttraining's auc: 0.898135\tvalid_1's binary_logloss: 0.35934\tvalid_1's auc: 0.897681\n",
      "[100]\ttraining's binary_logloss: 0.334677\ttraining's auc: 0.899379\tvalid_1's binary_logloss: 0.33521\tvalid_1's auc: 0.898869\n",
      "[150]\ttraining's binary_logloss: 0.330317\ttraining's auc: 0.900039\tvalid_1's binary_logloss: 0.331148\tvalid_1's auc: 0.899415\n",
      "[200]\ttraining's binary_logloss: 0.328978\ttraining's auc: 0.900519\tvalid_1's binary_logloss: 0.330169\tvalid_1's auc: 0.899699\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.328978\ttraining's auc: 0.900519\tvalid_1's binary_logloss: 0.330169\tvalid_1's auc: 0.899699\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7812953398042063\n",
      "0.8996986550936855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9074    0.8641    0.8852    251890\n",
      "           1     0.6338    0.7273    0.6774     81443\n",
      "\n",
      "    accuracy                         0.8307    333333\n",
      "   macro avg     0.7706    0.7957    0.7813    333333\n",
      "weighted avg     0.8406    0.8307    0.8344    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54863\tvalidation_0-auc:0.83683\tvalidation_1-logloss:0.54860\tvalidation_1-auc:0.83669\n",
      "[50]\tvalidation_0-logloss:0.36432\tvalidation_0-auc:0.89723\tvalidation_1-logloss:0.36477\tvalidation_1-auc:0.89653\n",
      "[100]\tvalidation_0-logloss:0.33705\tvalidation_0-auc:0.89944\tvalidation_1-logloss:0.33819\tvalidation_1-auc:0.89836\n",
      "[150]\tvalidation_0-logloss:0.33068\tvalidation_0-auc:0.90062\tvalidation_1-logloss:0.33243\tvalidation_1-auc:0.89920\n",
      "[199]\tvalidation_0-logloss:0.32854\tvalidation_0-auc:0.90136\tvalidation_1-logloss:0.33080\tvalidation_1-auc:0.89963\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7818241379638484\n",
      "0.8996270488977574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9070    0.8657    0.8859    251890\n",
      "           1     0.6360    0.7255    0.6778     81443\n",
      "\n",
      "    accuracy                         0.8315    333333\n",
      "   macro avg     0.7715    0.7956    0.7818    333333\n",
      "weighted avg     0.8408    0.8315    0.8350    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7788230115233553\n",
      "0.8969151142049625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9069    0.8614    0.8835    251890\n",
      "           1     0.6288    0.7264    0.6741     81443\n",
      "\n",
      "    accuracy                         0.8284    333333\n",
      "   macro avg     0.7679    0.7939    0.7788    333333\n",
      "weighted avg     0.8389    0.8284    0.8324    333333\n",
      "\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.4099999999999998 0.7628996331602209\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3999999999999998 0.7805839233885761\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7813547471528779\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7813824036556383\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7784948093503694\n",
      "LOGREG--------------\n",
      "accuracy 0.82143\n",
      "f1_score 0.7637634341338286\n",
      "auc 0.8788386843370741\n",
      "sensitivity 0.669092098270858 specificity 0.8707653203066047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8904    0.8708    0.8805    151074\n",
      "           1     0.6264    0.6691    0.6470     48926\n",
      "\n",
      "    accuracy                         0.8214    200000\n",
      "   macro avg     0.7584    0.7699    0.7638    200000\n",
      "weighted avg     0.8258    0.8214    0.8234    200000\n",
      "\n",
      "Random Forest--------------\n",
      "accuracy 0.83139\n",
      "f1_score 0.7801918264431436\n",
      "auc 0.897536500596889\n",
      "sensitivity 0.7128520622981646 specificity 0.8697790486781313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9034    0.8698    0.8863    151074\n",
      "           1     0.6394    0.7129    0.6741     48926\n",
      "\n",
      "    accuracy                         0.8314    200000\n",
      "   macro avg     0.7714    0.7913    0.7802    200000\n",
      "weighted avg     0.8388    0.8314    0.8344    200000\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 244328, number of negative: 755672\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1445\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000000, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129096\n",
      "[LightGBM] [Info] Start training from score -1.129096\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "accuracy 0.830575\n",
      "f1_score 0.7812415127963144\n",
      "auc 0.8995174436981423\n",
      "sensitivity 0.7269958713158647 specificity 0.8641195705415889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9072    0.8641    0.8851    151074\n",
      "           1     0.6341    0.7270    0.6774     48926\n",
      "\n",
      "    accuracy                         0.8306    200000\n",
      "   macro avg     0.7706    0.7956    0.7812    200000\n",
      "weighted avg     0.8404    0.8306    0.8343    200000\n",
      "\n",
      "XGBoost--------------\n",
      "{'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 8, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 8, 'reg_lambda': 32, 'seed': 42, 'enable_categorical': True}\n",
      "accuracy 0.830775\n",
      "f1_score 0.7811719361361384\n",
      "auc 0.8994342403633143\n",
      "sensitivity 0.72491109021788 specificity 0.8650595072613422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9066    0.8651    0.8854    151074\n",
      "           1     0.6350    0.7249    0.6770     48926\n",
      "\n",
      "    accuracy                         0.8308    200000\n",
      "   macro avg     0.7708    0.7950    0.7812    200000\n",
      "weighted avg     0.8402    0.8308    0.8344    200000\n",
      "\n",
      "MLP--------------\n",
      "accuracy 0.828255\n",
      "f1_score 0.7779242136422841\n",
      "auc 0.8965259707262141\n",
      "sensitivity 0.7198422106855251 specificity 0.8633649734567166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9049    0.8634    0.8836    151074\n",
      "           1     0.6305    0.7198    0.6722     48926\n",
      "\n",
      "    accuracy                         0.8283    200000\n",
      "   macro avg     0.7677    0.7916    0.7779    200000\n",
      "weighted avg     0.8378    0.8283    0.8319    200000\n",
      "\n",
      "['log_reg', 'randomforest', 'lightgbm', 'xgboost', 'mlp']\n",
      "[0.82143, 0.83139, 0.830575, 0.830775, 0.828255]\n",
      "[0.7637634341338286, 0.7801918264431436, 0.7812415127963144, 0.7811719361361384, 0.7779242136422841]\n",
      "[0.8788386843370741, 0.897536500596889, 0.8995174436981423, 0.8994342403633143, 0.8965259707262141]\n",
      "[0.8707653203066047, 0.8697790486781313, 0.8641195705415889, 0.8650595072613422, 0.8633649734567166]\n",
      "[0.669092098270858, 0.7128520622981646, 0.7269958713158647, 0.72491109021788, 0.7198422106855251]\n"
     ]
    }
   ],
   "source": [
    "nothing_oofs = cross_validate(train,FEATURES=top_features[:10])\n",
    "nothing_score_df, nothing_models, nothing_predictions = train_model(nothing_oofs,X_train[top_features[:10]], y_train, X_test[top_features[:10]], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "===========fold 0================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 20\n",
      "active_day           0\n",
      "not_active_day       0\n",
      "age_group_unknown    0\n",
      "gender_unknown       0\n",
      "signin_count         0\n",
      "newtab_count         0\n",
      "ads_impression       0\n",
      "clicks               0\n",
      "life_time            0\n",
      "ads_revenue          0\n",
      "total_active_time    0\n",
      "work_count           0\n",
      "search_volume_gg     0\n",
      "search_volume        0\n",
      "news_count           0\n",
      "gender_female        0\n",
      "serp_click           0\n",
      "search_clicks_gg     0\n",
      "youtube_count        0\n",
      "other_search_gg      0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4299999999999998 best_score 0.7634830302435618\n",
      "0.8790693753113508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8866    0.8794    0.8830    251891\n",
      "           1     0.6361    0.6520    0.6440     81443\n",
      "\n",
      "    accuracy                         0.8239    333334\n",
      "   macro avg     0.7614    0.7657    0.7635    333334\n",
      "weighted avg     0.8254    0.8239    0.8246    333334\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7796926428940752\n",
      "0.8964603337667343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9101    0.8566    0.8825    251891\n",
      "           1     0.6247    0.7384    0.6768     81443\n",
      "\n",
      "    accuracy                         0.8277    333334\n",
      "   macro avg     0.7674    0.7975    0.7797    333334\n",
      "weighted avg     0.8404    0.8277    0.8323    333334\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3741\n",
      "[LightGBM] [Info] Number of data points in the train set: 666666, number of used features: 20\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129097\n",
      "[LightGBM] [Info] Start training from score -1.129097\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358376\ttraining's auc: 0.898628\tvalid_1's binary_logloss: 0.359024\tvalid_1's auc: 0.897899\n",
      "[100]\ttraining's binary_logloss: 0.334059\ttraining's auc: 0.899938\tvalid_1's binary_logloss: 0.335116\tvalid_1's auc: 0.899016\n",
      "[150]\ttraining's binary_logloss: 0.328977\ttraining's auc: 0.900852\tvalid_1's binary_logloss: 0.330492\tvalid_1's auc: 0.89968\n",
      "[200]\ttraining's binary_logloss: 0.327364\ttraining's auc: 0.901481\tvalid_1's binary_logloss: 0.329376\tvalid_1's auc: 0.900023\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.327364\ttraining's auc: 0.901481\tvalid_1's binary_logloss: 0.329376\tvalid_1's auc: 0.900023\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7821732447120215\n",
      "0.9000225094677671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9055    0.8691    0.8869    251891\n",
      "           1     0.6399    0.7196    0.6774     81443\n",
      "\n",
      "    accuracy                         0.8325    333334\n",
      "   macro avg     0.7727    0.7943    0.7822    333334\n",
      "weighted avg     0.8406    0.8325    0.8357    333334\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54786\tvalidation_0-auc:0.85557\tvalidation_1-logloss:0.54790\tvalidation_1-auc:0.85443\n",
      "[50]\tvalidation_0-logloss:0.36642\tvalidation_0-auc:0.89588\tvalidation_1-logloss:0.36781\tvalidation_1-auc:0.89425\n",
      "[100]\tvalidation_0-logloss:0.33810\tvalidation_0-auc:0.89916\tvalidation_1-logloss:0.34054\tvalidation_1-auc:0.89698\n",
      "[150]\tvalidation_0-logloss:0.32914\tvalidation_0-auc:0.90174\tvalidation_1-logloss:0.33246\tvalidation_1-auc:0.89907\n",
      "[199]\tvalidation_0-logloss:0.32598\tvalidation_0-auc:0.90297\tvalidation_1-logloss:0.33007\tvalidation_1-auc:0.89985\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.781584251724765\n",
      "0.8998535439659792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9073    0.8647    0.8855    251891\n",
      "           1     0.6347    0.7269    0.6776     81443\n",
      "\n",
      "    accuracy                         0.8310    333334\n",
      "   macro avg     0.7710    0.7958    0.7816    333334\n",
      "weighted avg     0.8407    0.8310    0.8347    333334\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7780835052535319\n",
      "0.8962433286553274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9044    0.8650    0.8843    251891\n",
      "           1     0.6321    0.7171    0.6719     81443\n",
      "\n",
      "    accuracy                         0.8289    333334\n",
      "   macro avg     0.7682    0.7911    0.7781    333334\n",
      "weighted avg     0.8378    0.8289    0.8324    333334\n",
      "\n",
      "===========fold 1================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 20\n",
      "active_day           0\n",
      "not_active_day       0\n",
      "age_group_unknown    0\n",
      "gender_unknown       0\n",
      "signin_count         0\n",
      "newtab_count         0\n",
      "ads_impression       0\n",
      "clicks               0\n",
      "life_time            0\n",
      "ads_revenue          0\n",
      "total_active_time    0\n",
      "work_count           0\n",
      "search_volume_gg     0\n",
      "search_volume        0\n",
      "news_count           0\n",
      "gender_female        0\n",
      "serp_click           0\n",
      "search_clicks_gg     0\n",
      "youtube_count        0\n",
      "other_search_gg      0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4299999999999998 best_score 0.7641940258655853\n",
      "0.8791602432849361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8864    0.8811    0.8837    251891\n",
      "           1     0.6388    0.6506    0.6447     81442\n",
      "\n",
      "    accuracy                         0.8248    333333\n",
      "   macro avg     0.7626    0.7658    0.7642    333333\n",
      "weighted avg     0.8259    0.8248    0.8253    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.7792301410867275\n",
      "0.8964069813162189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9113    0.8537    0.8816    251891\n",
      "           1     0.6216    0.7430    0.6769     81442\n",
      "\n",
      "    accuracy                         0.8267    333333\n",
      "   macro avg     0.7664    0.7984    0.7792    333333\n",
      "weighted avg     0.8405    0.8267    0.8316    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162886, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3742\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 20\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244329 -> initscore=-1.129091\n",
      "[LightGBM] [Info] Start training from score -1.129091\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358594\ttraining's auc: 0.8984\tvalid_1's binary_logloss: 0.358784\tvalid_1's auc: 0.898354\n",
      "[100]\ttraining's binary_logloss: 0.334307\ttraining's auc: 0.899696\tvalid_1's binary_logloss: 0.33476\tvalid_1's auc: 0.899448\n",
      "[150]\ttraining's binary_logloss: 0.329279\ttraining's auc: 0.900582\tvalid_1's binary_logloss: 0.32998\tvalid_1's auc: 0.900193\n",
      "[200]\ttraining's binary_logloss: 0.3277\ttraining's auc: 0.901188\tvalid_1's binary_logloss: 0.328767\tvalid_1's auc: 0.900554\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.3277\ttraining's auc: 0.901188\tvalid_1's binary_logloss: 0.328767\tvalid_1's auc: 0.900554\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7819957209946051\n",
      "0.9005539178103865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9049    0.8701    0.8871    251891\n",
      "           1     0.6409    0.7171    0.6769     81442\n",
      "\n",
      "    accuracy                         0.8327    333333\n",
      "   macro avg     0.7729    0.7936    0.7820    333333\n",
      "weighted avg     0.8404    0.8327    0.8358    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54783\tvalidation_0-auc:0.85623\tvalidation_1-logloss:0.54789\tvalidation_1-auc:0.85436\n",
      "[50]\tvalidation_0-logloss:0.36649\tvalidation_0-auc:0.89572\tvalidation_1-logloss:0.36786\tvalidation_1-auc:0.89423\n",
      "[100]\tvalidation_0-logloss:0.33821\tvalidation_0-auc:0.89900\tvalidation_1-logloss:0.34044\tvalidation_1-auc:0.89713\n",
      "[150]\tvalidation_0-logloss:0.32934\tvalidation_0-auc:0.90154\tvalidation_1-logloss:0.33216\tvalidation_1-auc:0.89941\n",
      "[199]\tvalidation_0-logloss:0.32618\tvalidation_0-auc:0.90279\tvalidation_1-logloss:0.32963\tvalidation_1-auc:0.90030\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.782166294253287\n",
      "0.9003044737197047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9094    0.8617    0.8849    251891\n",
      "           1     0.6320    0.7346    0.6794     81442\n",
      "\n",
      "    accuracy                         0.8306    333333\n",
      "   macro avg     0.7707    0.7981    0.7822    333333\n",
      "weighted avg     0.8416    0.8306    0.8347    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7792593168992867\n",
      "0.8972744092127023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9110    0.8543    0.8818    251891\n",
      "           1     0.6222    0.7419    0.6768     81442\n",
      "\n",
      "    accuracy                         0.8269    333333\n",
      "   macro avg     0.7666    0.7981    0.7793    333333\n",
      "weighted avg     0.8404    0.8269    0.8317    333333\n",
      "\n",
      "===========fold 2================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 20\n",
      "active_day           0\n",
      "not_active_day       0\n",
      "age_group_unknown    0\n",
      "gender_unknown       0\n",
      "signin_count         0\n",
      "newtab_count         0\n",
      "ads_impression       0\n",
      "clicks               0\n",
      "life_time            0\n",
      "ads_revenue          0\n",
      "total_active_time    0\n",
      "work_count           0\n",
      "search_volume_gg     0\n",
      "search_volume        0\n",
      "news_count           0\n",
      "gender_female        0\n",
      "serp_click           0\n",
      "search_clicks_gg     0\n",
      "youtube_count        0\n",
      "other_search_gg      0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7637061905329103\n",
      "0.8792695709563069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8923    0.8670    0.8795    251890\n",
      "           1     0.6218    0.6764    0.6479     81443\n",
      "\n",
      "    accuracy                         0.8204    333333\n",
      "   macro avg     0.7571    0.7717    0.7637    333333\n",
      "weighted avg     0.8262    0.8204    0.8229    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7796313158170102\n",
      "0.8966696969881213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9021    0.8719    0.8867    251890\n",
      "           1     0.6410    0.7073    0.6725     81443\n",
      "\n",
      "    accuracy                         0.8317    333333\n",
      "   macro avg     0.7715    0.7896    0.7796    333333\n",
      "weighted avg     0.8383    0.8317    0.8344    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3744\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 20\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244327 -> initscore=-1.129099\n",
      "[LightGBM] [Info] Start training from score -1.129099\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358457\ttraining's auc: 0.898579\tvalid_1's binary_logloss: 0.358795\tvalid_1's auc: 0.89808\n",
      "[100]\ttraining's binary_logloss: 0.334184\ttraining's auc: 0.899813\tvalid_1's binary_logloss: 0.334804\tvalid_1's auc: 0.899235\n",
      "[150]\ttraining's binary_logloss: 0.32913\ttraining's auc: 0.900719\tvalid_1's binary_logloss: 0.33015\tvalid_1's auc: 0.899974\n",
      "[200]\ttraining's binary_logloss: 0.32755\ttraining's auc: 0.90133\tvalid_1's binary_logloss: 0.32899\tvalid_1's auc: 0.900343\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.32755\ttraining's auc: 0.90133\tvalid_1's binary_logloss: 0.32899\tvalid_1's auc: 0.900343\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7820398356308758\n",
      "0.9003429704210014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9084    0.8635    0.8854    251890\n",
      "           1     0.6337    0.7306    0.6787     81443\n",
      "\n",
      "    accuracy                         0.8310    333333\n",
      "   macro avg     0.7711    0.7970    0.7820    333333\n",
      "weighted avg     0.8413    0.8310    0.8349    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54786\tvalidation_0-auc:0.85534\tvalidation_1-logloss:0.54784\tvalidation_1-auc:0.85524\n",
      "[50]\tvalidation_0-logloss:0.36673\tvalidation_0-auc:0.89570\tvalidation_1-logloss:0.36742\tvalidation_1-auc:0.89473\n",
      "[100]\tvalidation_0-logloss:0.33835\tvalidation_0-auc:0.89901\tvalidation_1-logloss:0.33992\tvalidation_1-auc:0.89754\n",
      "[150]\tvalidation_0-logloss:0.32939\tvalidation_0-auc:0.90156\tvalidation_1-logloss:0.33183\tvalidation_1-auc:0.89961\n",
      "[199]\tvalidation_0-logloss:0.32620\tvalidation_0-auc:0.90282\tvalidation_1-logloss:0.32943\tvalidation_1-auc:0.90039\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.78221467952752\n",
      "0.9003910066385363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9070    0.8662    0.8862    251890\n",
      "           1     0.6368    0.7254    0.6783     81443\n",
      "\n",
      "    accuracy                         0.8318    333333\n",
      "   macro avg     0.7719    0.7958    0.7822    333333\n",
      "weighted avg     0.8410    0.8318    0.8354    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.7783505195467992\n",
      "0.8964778873413883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9082    0.8582    0.8825    251890\n",
      "           1     0.6252    0.7316    0.6742     81443\n",
      "\n",
      "    accuracy                         0.8273    333333\n",
      "   macro avg     0.7667    0.7949    0.7784    333333\n",
      "weighted avg     0.8390    0.8273    0.8316    333333\n",
      "\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.4299999999999998 0.7637919057467317\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3799999999999999 0.7794028508460559\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3999999999999998 0.7820455083216884\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7819214150294325\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3799999999999999 0.7783176123310267\n",
      "LOGREG--------------\n",
      "accuracy 0.82408\n",
      "f1_score 0.7638962547387922\n",
      "auc 0.8794354124586506\n",
      "sensitivity 0.6524138494869803 specificity 0.8796748613262375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8866    0.8797    0.8831    151074\n",
      "           1     0.6372    0.6524    0.6447     48926\n",
      "\n",
      "    accuracy                         0.8241    200000\n",
      "   macro avg     0.7619    0.7660    0.7639    200000\n",
      "weighted avg     0.8255    0.8241    0.8248    200000\n",
      "\n",
      "Random Forest--------------\n",
      "accuracy 0.82778\n",
      "f1_score 0.7795919566414669\n",
      "auc 0.8964017141281289\n",
      "sensitivity 0.7362138740138168 specificity 0.8574341051405272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9094    0.8574    0.8827    151074\n",
      "           1     0.6258    0.7362    0.6765     48926\n",
      "\n",
      "    accuracy                         0.8278    200000\n",
      "   macro avg     0.7676    0.7968    0.7796    200000\n",
      "weighted avg     0.8400    0.8278    0.8322    200000\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 244328, number of negative: 755672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3742\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000000, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129096\n",
      "[LightGBM] [Info] Start training from score -1.129096\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "accuracy 0.83279\n",
      "f1_score 0.7825657349104386\n",
      "auc 0.9001836118134108\n",
      "sensitivity 0.7198217716551527 specificity 0.8693752730449978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9055    0.8694    0.8871    151074\n",
      "           1     0.6409    0.7198    0.6781     48926\n",
      "\n",
      "    accuracy                         0.8328    200000\n",
      "   macro avg     0.7732    0.7946    0.7826    200000\n",
      "weighted avg     0.8408    0.8328    0.8359    200000\n",
      "\n",
      "XGBoost--------------\n",
      "{'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 8, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 8, 'reg_lambda': 32, 'seed': 42, 'enable_categorical': True}\n",
      "accuracy 0.83152\n",
      "f1_score 0.7821661517569302\n",
      "auc 0.9001180564449958\n",
      "sensitivity 0.7266688468299064 specificity 0.8654765214398242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9072    0.8655    0.8859    151074\n",
      "           1     0.6363    0.7267    0.6785     48926\n",
      "\n",
      "    accuracy                         0.8315    200000\n",
      "   macro avg     0.7717    0.7961    0.7822    200000\n",
      "weighted avg     0.8409    0.8315    0.8351    200000\n",
      "\n",
      "MLP--------------\n",
      "accuracy 0.826385\n",
      "f1_score 0.7781896364761914\n",
      "auc 0.8969552670743235\n",
      "sensitivity 0.7363160691656788 specificity 0.8555542317010207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9092    0.8556    0.8816    151074\n",
      "           1     0.6228    0.7363    0.6748     48926\n",
      "\n",
      "    accuracy                         0.8264    200000\n",
      "   macro avg     0.7660    0.7959    0.7782    200000\n",
      "weighted avg     0.8392    0.8264    0.8310    200000\n",
      "\n",
      "['log_reg', 'randomforest', 'lightgbm', 'xgboost', 'mlp']\n",
      "[0.82408, 0.82778, 0.83279, 0.83152, 0.826385]\n",
      "[0.7638962547387922, 0.7795919566414669, 0.7825657349104386, 0.7821661517569302, 0.7781896364761914]\n",
      "[0.8794354124586506, 0.8964017141281289, 0.9001836118134108, 0.9001180564449958, 0.8969552670743235]\n",
      "[0.8796748613262375, 0.8574341051405272, 0.8693752730449978, 0.8654765214398242, 0.8555542317010207]\n",
      "[0.6524138494869803, 0.7362138740138168, 0.7198217716551527, 0.7266688468299064, 0.7363160691656788]\n",
      "30\n",
      "===========fold 0================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 30\n",
      "active_day                       0\n",
      "not_active_day                   0\n",
      "age_group_unknown                0\n",
      "gender_unknown                   0\n",
      "signin_count                     0\n",
      "newtab_count                     0\n",
      "ads_impression                   0\n",
      "clicks                           0\n",
      "life_time                        0\n",
      "ads_revenue                      0\n",
      "total_active_time                0\n",
      "work_count                       0\n",
      "search_volume_gg                 0\n",
      "search_volume                    0\n",
      "news_count                       0\n",
      "gender_female                    0\n",
      "serp_click                       0\n",
      "search_clicks_gg                 0\n",
      "youtube_count                    0\n",
      "other_search_gg                  0\n",
      "social_count                     0\n",
      "other_search                     0\n",
      "gender_male                      0\n",
      "age_group_25-34                  0\n",
      "ecommerce_count                  0\n",
      "technical_search_gg              0\n",
      "housekeeping_family_search       0\n",
      "age_group_18-24                  0\n",
      "housekeeping_family_search_gg    0\n",
      "videoclip_search_gg              0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4199999999999998 best_score 0.7640267665607507\n",
      "0.879307563879316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8889    0.8749    0.8819    251891\n",
      "           1     0.6312    0.6619    0.6462     81443\n",
      "\n",
      "    accuracy                         0.8229    333334\n",
      "   macro avg     0.7600    0.7684    0.7640    333334\n",
      "weighted avg     0.8260    0.8229    0.8243    333334\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7780549386671475\n",
      "0.8951930443550619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9076    0.8588    0.8825    251891\n",
      "           1     0.6256    0.7295    0.6736     81443\n",
      "\n",
      "    accuracy                         0.8272    333334\n",
      "   macro avg     0.7666    0.7942    0.7781    333334\n",
      "weighted avg     0.8387    0.8272    0.8315    333334\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5248\n",
      "[LightGBM] [Info] Number of data points in the train set: 666666, number of used features: 30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129097\n",
      "[LightGBM] [Info] Start training from score -1.129097\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358971\ttraining's auc: 0.89839\tvalid_1's binary_logloss: 0.359612\tvalid_1's auc: 0.897662\n",
      "[100]\ttraining's binary_logloss: 0.333988\ttraining's auc: 0.899987\tvalid_1's binary_logloss: 0.335029\tvalid_1's auc: 0.89907\n",
      "[150]\ttraining's binary_logloss: 0.32885\ttraining's auc: 0.900936\tvalid_1's binary_logloss: 0.330371\tvalid_1's auc: 0.89974\n",
      "[200]\ttraining's binary_logloss: 0.327071\ttraining's auc: 0.901656\tvalid_1's binary_logloss: 0.329118\tvalid_1's auc: 0.900143\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.327071\ttraining's auc: 0.901656\tvalid_1's binary_logloss: 0.329118\tvalid_1's auc: 0.900143\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7820118518315711\n",
      "0.9001431896831494\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9121    0.8565    0.8834    251891\n",
      "           1     0.6266    0.7449    0.6806     81443\n",
      "\n",
      "    accuracy                         0.8292    333334\n",
      "   macro avg     0.7693    0.8007    0.7820    333334\n",
      "weighted avg     0.8424    0.8292    0.8339    333334\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54624\tvalidation_0-auc:0.88880\tvalidation_1-logloss:0.54626\tvalidation_1-auc:0.88776\n",
      "[50]\tvalidation_0-logloss:0.36278\tvalidation_0-auc:0.89875\tvalidation_1-logloss:0.36423\tvalidation_1-auc:0.89710\n",
      "[100]\tvalidation_0-logloss:0.33512\tvalidation_0-auc:0.90109\tvalidation_1-logloss:0.33771\tvalidation_1-auc:0.89884\n",
      "[150]\tvalidation_0-logloss:0.32819\tvalidation_0-auc:0.90245\tvalidation_1-logloss:0.33174\tvalidation_1-auc:0.89961\n",
      "[199]\tvalidation_0-logloss:0.32485\tvalidation_0-auc:0.90370\tvalidation_1-logloss:0.32928\tvalidation_1-auc:0.90036\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7825817257975765\n",
      "0.9003596587902017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9080    0.8650    0.8860    251891\n",
      "           1     0.6358    0.7290    0.6792     81443\n",
      "\n",
      "    accuracy                         0.8317    333334\n",
      "   macro avg     0.7719    0.7970    0.7826    333334\n",
      "weighted avg     0.8415    0.8317    0.8354    333334\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.7786119757994497\n",
      "0.8965463613201016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9073    0.8602    0.8831    251891\n",
      "           1     0.6274    0.7282    0.6741     81443\n",
      "\n",
      "    accuracy                         0.8280    333334\n",
      "   macro avg     0.7674    0.7942    0.7786    333334\n",
      "weighted avg     0.8389    0.8280    0.8321    333334\n",
      "\n",
      "===========fold 1================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 30\n",
      "active_day                       0\n",
      "not_active_day                   0\n",
      "age_group_unknown                0\n",
      "gender_unknown                   0\n",
      "signin_count                     0\n",
      "newtab_count                     0\n",
      "ads_impression                   0\n",
      "clicks                           0\n",
      "life_time                        0\n",
      "ads_revenue                      0\n",
      "total_active_time                0\n",
      "work_count                       0\n",
      "search_volume_gg                 0\n",
      "search_volume                    0\n",
      "news_count                       0\n",
      "gender_female                    0\n",
      "serp_click                       0\n",
      "search_clicks_gg                 0\n",
      "youtube_count                    0\n",
      "other_search_gg                  0\n",
      "social_count                     0\n",
      "other_search                     0\n",
      "gender_male                      0\n",
      "age_group_25-34                  0\n",
      "ecommerce_count                  0\n",
      "technical_search_gg              0\n",
      "housekeeping_family_search       0\n",
      "age_group_18-24                  0\n",
      "housekeeping_family_search_gg    0\n",
      "videoclip_search_gg              0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7626833265846273\n",
      "0.8787145154115175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8888    0.8730    0.8808    251891\n",
      "           1     0.6277    0.6623    0.6445     81442\n",
      "\n",
      "    accuracy                         0.8215    333333\n",
      "   macro avg     0.7583    0.7676    0.7627    333333\n",
      "weighted avg     0.8250    0.8215    0.8231    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.7780566379901643\n",
      "0.8954366312525923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9143    0.8465    0.8791    251891\n",
      "           1     0.6139    0.7546    0.6770     81442\n",
      "\n",
      "    accuracy                         0.8241    333333\n",
      "   macro avg     0.7641    0.8006    0.7781    333333\n",
      "weighted avg     0.8409    0.8241    0.8297    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162886, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5245\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244329 -> initscore=-1.129091\n",
      "[LightGBM] [Info] Start training from score -1.129091\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.35914\ttraining's auc: 0.898152\tvalid_1's binary_logloss: 0.359357\tvalid_1's auc: 0.898073\n",
      "[100]\ttraining's binary_logloss: 0.334232\ttraining's auc: 0.899748\tvalid_1's binary_logloss: 0.334678\tvalid_1's auc: 0.899495\n",
      "[150]\ttraining's binary_logloss: 0.329141\ttraining's auc: 0.900686\tvalid_1's binary_logloss: 0.32987\tvalid_1's auc: 0.900255\n",
      "[200]\ttraining's binary_logloss: 0.327387\ttraining's auc: 0.901392\tvalid_1's binary_logloss: 0.328503\tvalid_1's auc: 0.900696\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.327387\ttraining's auc: 0.901392\tvalid_1's binary_logloss: 0.328503\tvalid_1's auc: 0.900696\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7824306211812704\n",
      "0.9006957231447891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9024    0.8756    0.8888    251891\n",
      "           1     0.6477    0.7070    0.6760     81442\n",
      "\n",
      "    accuracy                         0.8344    333333\n",
      "   macro avg     0.7750    0.7913    0.7824    333333\n",
      "weighted avg     0.8401    0.8344    0.8368    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54623\tvalidation_0-auc:0.88853\tvalidation_1-logloss:0.54627\tvalidation_1-auc:0.88803\n",
      "[50]\tvalidation_0-logloss:0.36292\tvalidation_0-auc:0.89852\tvalidation_1-logloss:0.36426\tvalidation_1-auc:0.89709\n",
      "[100]\tvalidation_0-logloss:0.33534\tvalidation_0-auc:0.90084\tvalidation_1-logloss:0.33750\tvalidation_1-auc:0.89904\n",
      "[150]\tvalidation_0-logloss:0.32847\tvalidation_0-auc:0.90218\tvalidation_1-logloss:0.33145\tvalidation_1-auc:0.89992\n",
      "[199]\tvalidation_0-logloss:0.32515\tvalidation_0-auc:0.90344\tvalidation_1-logloss:0.32881\tvalidation_1-auc:0.90080\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7829860438701526\n",
      "0.9007986913281497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9106    0.8608    0.8850    251891\n",
      "           1     0.6317    0.7386    0.6810     81442\n",
      "\n",
      "    accuracy                         0.8309    333333\n",
      "   macro avg     0.7711    0.7997    0.7830    333333\n",
      "weighted avg     0.8425    0.8309    0.8351    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7787089337592938\n",
      "0.8971607834248524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9086    0.8579    0.8825    251891\n",
      "           1     0.6252    0.7331    0.6749     81442\n",
      "\n",
      "    accuracy                         0.8274    333333\n",
      "   macro avg     0.7669    0.7955    0.7787    333333\n",
      "weighted avg     0.8394    0.8274    0.8318    333333\n",
      "\n",
      "===========fold 2================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 30\n",
      "active_day                       0\n",
      "not_active_day                   0\n",
      "age_group_unknown                0\n",
      "gender_unknown                   0\n",
      "signin_count                     0\n",
      "newtab_count                     0\n",
      "ads_impression                   0\n",
      "clicks                           0\n",
      "life_time                        0\n",
      "ads_revenue                      0\n",
      "total_active_time                0\n",
      "work_count                       0\n",
      "search_volume_gg                 0\n",
      "search_volume                    0\n",
      "news_count                       0\n",
      "gender_female                    0\n",
      "serp_click                       0\n",
      "search_clicks_gg                 0\n",
      "youtube_count                    0\n",
      "other_search_gg                  0\n",
      "social_count                     0\n",
      "other_search                     0\n",
      "gender_male                      0\n",
      "age_group_25-34                  0\n",
      "ecommerce_count                  0\n",
      "technical_search_gg              0\n",
      "housekeeping_family_search       0\n",
      "age_group_18-24                  0\n",
      "housekeeping_family_search_gg    0\n",
      "videoclip_search_gg              0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7635613496343735\n",
      "0.8790324837023381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8902    0.8714    0.8807    251890\n",
      "           1     0.6267    0.6674    0.6464     81443\n",
      "\n",
      "    accuracy                         0.8216    333333\n",
      "   macro avg     0.7584    0.7694    0.7636    333333\n",
      "weighted avg     0.8258    0.8216    0.8235    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7783117863183031\n",
      "0.8956181273867049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9077    0.8590    0.8827    251890\n",
      "           1     0.6260    0.7299    0.6739     81443\n",
      "\n",
      "    accuracy                         0.8274    333333\n",
      "   macro avg     0.7668    0.7944    0.7783    333333\n",
      "weighted avg     0.8389    0.8274    0.8317    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5240\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244327 -> initscore=-1.129099\n",
      "[LightGBM] [Info] Start training from score -1.129099\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.359054\ttraining's auc: 0.898347\tvalid_1's binary_logloss: 0.359357\tvalid_1's auc: 0.897878\n",
      "[100]\ttraining's binary_logloss: 0.334053\ttraining's auc: 0.899907\tvalid_1's binary_logloss: 0.334677\tvalid_1's auc: 0.899332\n",
      "[150]\ttraining's binary_logloss: 0.328947\ttraining's auc: 0.900839\tvalid_1's binary_logloss: 0.329951\tvalid_1's auc: 0.900091\n",
      "[200]\ttraining's binary_logloss: 0.327164\ttraining's auc: 0.901562\tvalid_1's binary_logloss: 0.328695\tvalid_1's auc: 0.900508\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.327164\ttraining's auc: 0.901562\tvalid_1's binary_logloss: 0.328695\tvalid_1's auc: 0.900508\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7822168558936402\n",
      "0.9005079288288507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9086    0.8632    0.8854    251890\n",
      "           1     0.6336    0.7316    0.6791     81443\n",
      "\n",
      "    accuracy                         0.8311    333333\n",
      "   macro avg     0.7711    0.7974    0.7822    333333\n",
      "weighted avg     0.8414    0.8311    0.8350    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54623\tvalidation_0-auc:0.88854\tvalidation_1-logloss:0.54626\tvalidation_1-auc:0.88794\n",
      "[50]\tvalidation_0-logloss:0.36303\tvalidation_0-auc:0.89857\tvalidation_1-logloss:0.36397\tvalidation_1-auc:0.89732\n",
      "[100]\tvalidation_0-logloss:0.33535\tvalidation_0-auc:0.90092\tvalidation_1-logloss:0.33728\tvalidation_1-auc:0.89917\n",
      "[150]\tvalidation_0-logloss:0.32843\tvalidation_0-auc:0.90225\tvalidation_1-logloss:0.33125\tvalidation_1-auc:0.89999\n",
      "[199]\tvalidation_0-logloss:0.32510\tvalidation_0-auc:0.90351\tvalidation_1-logloss:0.32880\tvalidation_1-auc:0.90073\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7825133542570175\n",
      "0.900733049406631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9109    0.8596    0.8845    251890\n",
      "           1     0.6301    0.7398    0.6806     81443\n",
      "\n",
      "    accuracy                         0.8303    333333\n",
      "   macro avg     0.7705    0.7997    0.7825    333333\n",
      "weighted avg     0.8423    0.8303    0.8346    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7785169974310263\n",
      "0.8964769956870983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9064    0.8619    0.8836    251890\n",
      "           1     0.6291    0.7246    0.6735     81443\n",
      "\n",
      "    accuracy                         0.8283    333333\n",
      "   macro avg     0.7677    0.7932    0.7785    333333\n",
      "weighted avg     0.8386    0.8283    0.8322    333333\n",
      "\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.4099999999999998 0.7633841452055234\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3699999999999999 0.778035136561471\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3999999999999998 0.7821491805886371\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3799999999999999 0.7825597419784966\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7783767534353591\n",
      "LOGREG--------------\n",
      "accuracy 0.821125\n",
      "f1_score 0.7630731782931148\n",
      "auc 0.8790340236384291\n",
      "sensitivity 0.6665780975350529 specificity 0.8711757152124124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8897    0.8712    0.8804    151074\n",
      "           1     0.6263    0.6666    0.6458     48926\n",
      "\n",
      "    accuracy                         0.8211    200000\n",
      "   macro avg     0.7580    0.7689    0.7631    200000\n",
      "weighted avg     0.8253    0.8211    0.8230    200000\n",
      "\n",
      "Random Forest--------------\n",
      "accuracy 0.825135\n",
      "f1_score 0.7776500530247134\n",
      "auc 0.8949989429700973\n",
      "sensitivity 0.741957241548461 specificity 0.8520724942743292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9107    0.8521    0.8804    151074\n",
      "           1     0.6190    0.7420    0.6749     48926\n",
      "\n",
      "    accuracy                         0.8251    200000\n",
      "   macro avg     0.7648    0.7970    0.7777    200000\n",
      "weighted avg     0.8393    0.8251    0.8301    200000\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 244328, number of negative: 755672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5241\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000000, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129096\n",
      "[LightGBM] [Info] Start training from score -1.129096\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "accuracy 0.83285\n",
      "f1_score 0.7827062108218357\n",
      "auc 0.9002723627091751\n",
      "sensitivity 0.7204145035359523 specificity 0.8692627454095344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9057    0.8693    0.8871    151074\n",
      "           1     0.6409    0.7204    0.6783     48926\n",
      "\n",
      "    accuracy                         0.8328    200000\n",
      "   macro avg     0.7733    0.7948    0.7827    200000\n",
      "weighted avg     0.8409    0.8328    0.8360    200000\n",
      "\n",
      "XGBoost--------------\n",
      "{'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 8, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 8, 'reg_lambda': 32, 'seed': 42, 'enable_categorical': True}\n",
      "accuracy 0.83022\n",
      "f1_score 0.7826157763074926\n",
      "auc 0.9005196472554498\n",
      "sensitivity 0.740424314270531 specificity 0.859300740034685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9109    0.8593    0.8843    151074\n",
      "           1     0.6302    0.7404    0.6809     48926\n",
      "\n",
      "    accuracy                         0.8302    200000\n",
      "   macro avg     0.7706    0.7999    0.7826    200000\n",
      "weighted avg     0.8422    0.8302    0.8346    200000\n",
      "\n",
      "MLP--------------\n",
      "accuracy 0.82284\n",
      "f1_score 0.7768847948381081\n",
      "auc 0.896754135537327\n",
      "sensitivity 0.754200220741528 specificity 0.8450693037849001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9139    0.8451    0.8781    151074\n",
      "           1     0.6119    0.7542    0.6756     48926\n",
      "\n",
      "    accuracy                         0.8228    200000\n",
      "   macro avg     0.7629    0.7996    0.7769    200000\n",
      "weighted avg     0.8400    0.8228    0.8286    200000\n",
      "\n",
      "['log_reg', 'randomforest', 'lightgbm', 'xgboost', 'mlp']\n",
      "[0.821125, 0.825135, 0.83285, 0.83022, 0.82284]\n",
      "[0.7630731782931148, 0.7776500530247134, 0.7827062108218357, 0.7826157763074926, 0.7768847948381081]\n",
      "[0.8790340236384291, 0.8949989429700973, 0.9002723627091751, 0.9005196472554498, 0.896754135537327]\n",
      "[0.8711757152124124, 0.8520724942743292, 0.8692627454095344, 0.859300740034685, 0.8450693037849001]\n",
      "[0.6665780975350529, 0.741957241548461, 0.7204145035359523, 0.740424314270531, 0.754200220741528]\n",
      "40\n",
      "===========fold 0================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 40\n",
      "active_day                       0\n",
      "not_active_day                   0\n",
      "age_group_unknown                0\n",
      "gender_unknown                   0\n",
      "signin_count                     0\n",
      "newtab_count                     0\n",
      "ads_impression                   0\n",
      "clicks                           0\n",
      "life_time                        0\n",
      "ads_revenue                      0\n",
      "total_active_time                0\n",
      "work_count                       0\n",
      "search_volume_gg                 0\n",
      "search_volume                    0\n",
      "news_count                       0\n",
      "gender_female                    0\n",
      "serp_click                       0\n",
      "search_clicks_gg                 0\n",
      "youtube_count                    0\n",
      "other_search_gg                  0\n",
      "social_count                     0\n",
      "other_search                     0\n",
      "gender_male                      0\n",
      "age_group_25-34                  0\n",
      "ecommerce_count                  0\n",
      "technical_search_gg              0\n",
      "housekeeping_family_search       0\n",
      "age_group_18-24                  0\n",
      "housekeeping_family_search_gg    0\n",
      "videoclip_search_gg              0\n",
      "entertainment_count              0\n",
      "videoclip_search                 0\n",
      "ads_click                        0\n",
      "technical_search                 0\n",
      "sidebar_count                    0\n",
      "marketing_search_gg              0\n",
      "download_count                   0\n",
      "age_group_45-54                  0\n",
      "dating_search_gg                 0\n",
      "marketing_search                 0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.43999999999999984 best_score 0.762662571900803\n",
      "0.8783637412747765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8829    0.8867    0.8848    251891\n",
      "           1     0.6449    0.6362    0.6405     81443\n",
      "\n",
      "    accuracy                         0.8255    333334\n",
      "   macro avg     0.7639    0.7615    0.7627    333334\n",
      "weighted avg     0.8247    0.8255    0.8251    333334\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.7767136658185918\n",
      "0.8940391093109709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9132    0.8464    0.8786    251891\n",
      "           1     0.6127    0.7512    0.6749     81443\n",
      "\n",
      "    accuracy                         0.8232    333334\n",
      "   macro avg     0.7629    0.7988    0.7767    333334\n",
      "weighted avg     0.8398    0.8232    0.8288    333334\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6838\n",
      "[LightGBM] [Info] Number of data points in the train set: 666666, number of used features: 40\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129097\n",
      "[LightGBM] [Info] Start training from score -1.129097\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.357858\ttraining's auc: 0.898799\tvalid_1's binary_logloss: 0.358504\tvalid_1's auc: 0.8981\n",
      "[100]\ttraining's binary_logloss: 0.333201\ttraining's auc: 0.90026\tvalid_1's binary_logloss: 0.334313\tvalid_1's auc: 0.899305\n",
      "[150]\ttraining's binary_logloss: 0.328146\ttraining's auc: 0.901223\tvalid_1's binary_logloss: 0.329718\tvalid_1's auc: 0.899997\n",
      "[200]\ttraining's binary_logloss: 0.326279\ttraining's auc: 0.901961\tvalid_1's binary_logloss: 0.328412\tvalid_1's auc: 0.900401\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326279\ttraining's auc: 0.901961\tvalid_1's binary_logloss: 0.328412\tvalid_1's auc: 0.900401\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7823109440203844\n",
      "0.900400520445546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9055    0.8694    0.8871    251891\n",
      "           1     0.6404    0.7193    0.6775     81443\n",
      "\n",
      "    accuracy                         0.8327    333334\n",
      "   macro avg     0.7729    0.7943    0.7823    333334\n",
      "weighted avg     0.8407    0.8327    0.8359    333334\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54687\tvalidation_0-auc:0.87093\tvalidation_1-logloss:0.54690\tvalidation_1-auc:0.87014\n",
      "[50]\tvalidation_0-logloss:0.36411\tvalidation_0-auc:0.89795\tvalidation_1-logloss:0.36572\tvalidation_1-auc:0.89609\n",
      "[100]\tvalidation_0-logloss:0.33412\tvalidation_0-auc:0.90129\tvalidation_1-logloss:0.33697\tvalidation_1-auc:0.89881\n",
      "[150]\tvalidation_0-logloss:0.32652\tvalidation_0-auc:0.90309\tvalidation_1-logloss:0.33041\tvalidation_1-auc:0.90003\n",
      "[199]\tvalidation_0-logloss:0.32351\tvalidation_0-auc:0.90424\tvalidation_1-logloss:0.32830\tvalidation_1-auc:0.90066\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7824361094515273\n",
      "0.9006599412154637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9053    0.8699    0.8872    251891\n",
      "           1     0.6410    0.7187    0.6776     81443\n",
      "\n",
      "    accuracy                         0.8329    333334\n",
      "   macro avg     0.7732    0.7943    0.7824    333334\n",
      "weighted avg     0.8408    0.8329    0.8360    333334\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7778539644352795\n",
      "0.8958035934322033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9031    0.8671    0.8848    251891\n",
      "           1     0.6342    0.7123    0.6709     81443\n",
      "\n",
      "    accuracy                         0.8293    333334\n",
      "   macro avg     0.7686    0.7897    0.7779    333334\n",
      "weighted avg     0.8374    0.8293    0.8325    333334\n",
      "\n",
      "===========fold 1================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 40\n",
      "active_day                       0\n",
      "not_active_day                   0\n",
      "age_group_unknown                0\n",
      "gender_unknown                   0\n",
      "signin_count                     0\n",
      "newtab_count                     0\n",
      "ads_impression                   0\n",
      "clicks                           0\n",
      "life_time                        0\n",
      "ads_revenue                      0\n",
      "total_active_time                0\n",
      "work_count                       0\n",
      "search_volume_gg                 0\n",
      "search_volume                    0\n",
      "news_count                       0\n",
      "gender_female                    0\n",
      "serp_click                       0\n",
      "search_clicks_gg                 0\n",
      "youtube_count                    0\n",
      "other_search_gg                  0\n",
      "social_count                     0\n",
      "other_search                     0\n",
      "gender_male                      0\n",
      "age_group_25-34                  0\n",
      "ecommerce_count                  0\n",
      "technical_search_gg              0\n",
      "housekeeping_family_search       0\n",
      "age_group_18-24                  0\n",
      "housekeeping_family_search_gg    0\n",
      "videoclip_search_gg              0\n",
      "entertainment_count              0\n",
      "videoclip_search                 0\n",
      "ads_click                        0\n",
      "technical_search                 0\n",
      "sidebar_count                    0\n",
      "marketing_search_gg              0\n",
      "download_count                   0\n",
      "age_group_45-54                  0\n",
      "dating_search_gg                 0\n",
      "marketing_search                 0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.764616417528069\n",
      "0.8781611910689685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8910    0.8713    0.8811    251891\n",
      "           1     0.6275    0.6703    0.6482     81442\n",
      "\n",
      "    accuracy                         0.8222    333333\n",
      "   macro avg     0.7592    0.7708    0.7646    333333\n",
      "weighted avg     0.8266    0.8222    0.8242    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.776942825483103\n",
      "0.8943831278860466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9122    0.8486    0.8792    251891\n",
      "           1     0.6148    0.7474    0.6746     81442\n",
      "\n",
      "    accuracy                         0.8239    333333\n",
      "   macro avg     0.7635    0.7980    0.7769    333333\n",
      "weighted avg     0.8395    0.8239    0.8293    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162886, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6836\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 40\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244329 -> initscore=-1.129091\n",
      "[LightGBM] [Info] Start training from score -1.129091\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358092\ttraining's auc: 0.898545\tvalid_1's binary_logloss: 0.358272\tvalid_1's auc: 0.898509\n",
      "[100]\ttraining's binary_logloss: 0.333432\ttraining's auc: 0.900023\tvalid_1's binary_logloss: 0.333831\tvalid_1's auc: 0.899814\n",
      "[150]\ttraining's binary_logloss: 0.328452\ttraining's auc: 0.900949\tvalid_1's binary_logloss: 0.32916\tvalid_1's auc: 0.900537\n",
      "[200]\ttraining's binary_logloss: 0.326675\ttraining's auc: 0.901654\tvalid_1's binary_logloss: 0.327817\tvalid_1's auc: 0.900951\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326675\ttraining's auc: 0.901654\tvalid_1's binary_logloss: 0.327817\tvalid_1's auc: 0.900951\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7825323831710862\n",
      "0.9009509395653167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9052    0.8702    0.8874    251891\n",
      "           1     0.6415    0.7182    0.6777     81442\n",
      "\n",
      "    accuracy                         0.8331    333333\n",
      "   macro avg     0.7734    0.7942    0.7825    333333\n",
      "weighted avg     0.8408    0.8331    0.8361    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54683\tvalidation_0-auc:0.87105\tvalidation_1-logloss:0.54690\tvalidation_1-auc:0.86914\n",
      "[50]\tvalidation_0-logloss:0.36431\tvalidation_0-auc:0.89766\tvalidation_1-logloss:0.36573\tvalidation_1-auc:0.89611\n",
      "[100]\tvalidation_0-logloss:0.33438\tvalidation_0-auc:0.90105\tvalidation_1-logloss:0.33669\tvalidation_1-auc:0.89914\n",
      "[150]\tvalidation_0-logloss:0.32686\tvalidation_0-auc:0.90280\tvalidation_1-logloss:0.32996\tvalidation_1-auc:0.90049\n",
      "[199]\tvalidation_0-logloss:0.32389\tvalidation_0-auc:0.90393\tvalidation_1-logloss:0.32770\tvalidation_1-auc:0.90122\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7831858794263211\n",
      "0.9012176242118193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9081    0.8658    0.8864    251891\n",
      "           1     0.6371    0.7290    0.6800     81442\n",
      "\n",
      "    accuracy                         0.8323    333333\n",
      "   macro avg     0.7726    0.7974    0.7832    333333\n",
      "weighted avg     0.8419    0.8323    0.8360    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7780018040899153\n",
      "0.8959630763235709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9027    0.8683    0.8851    251891\n",
      "           1     0.6355    0.7104    0.6709     81442\n",
      "\n",
      "    accuracy                         0.8297    333333\n",
      "   macro avg     0.7691    0.7893    0.7780    333333\n",
      "weighted avg     0.8374    0.8297    0.8328    333333\n",
      "\n",
      "===========fold 2================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 40\n",
      "active_day                       0\n",
      "not_active_day                   0\n",
      "age_group_unknown                0\n",
      "gender_unknown                   0\n",
      "signin_count                     0\n",
      "newtab_count                     0\n",
      "ads_impression                   0\n",
      "clicks                           0\n",
      "life_time                        0\n",
      "ads_revenue                      0\n",
      "total_active_time                0\n",
      "work_count                       0\n",
      "search_volume_gg                 0\n",
      "search_volume                    0\n",
      "news_count                       0\n",
      "gender_female                    0\n",
      "serp_click                       0\n",
      "search_clicks_gg                 0\n",
      "youtube_count                    0\n",
      "other_search_gg                  0\n",
      "social_count                     0\n",
      "other_search                     0\n",
      "gender_male                      0\n",
      "age_group_25-34                  0\n",
      "ecommerce_count                  0\n",
      "technical_search_gg              0\n",
      "housekeeping_family_search       0\n",
      "age_group_18-24                  0\n",
      "housekeeping_family_search_gg    0\n",
      "videoclip_search_gg              0\n",
      "entertainment_count              0\n",
      "videoclip_search                 0\n",
      "ads_click                        0\n",
      "technical_search                 0\n",
      "sidebar_count                    0\n",
      "marketing_search_gg              0\n",
      "download_count                   0\n",
      "age_group_45-54                  0\n",
      "dating_search_gg                 0\n",
      "marketing_search                 0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4199999999999998 best_score 0.7639006450083454\n",
      "0.8782799347444962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8865    0.8803    0.8834    251890\n",
      "           1     0.6376    0.6514    0.6444     81443\n",
      "\n",
      "    accuracy                         0.8244    333333\n",
      "   macro avg     0.7620    0.7658    0.7639    333333\n",
      "weighted avg     0.8257    0.8244    0.8250    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.7765223201095803\n",
      "0.8943978365349152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9093    0.8532    0.8804    251890\n",
      "           1     0.6187    0.7369    0.6727     81443\n",
      "\n",
      "    accuracy                         0.8248    333333\n",
      "   macro avg     0.7640    0.7951    0.7765    333333\n",
      "weighted avg     0.8383    0.8248    0.8296    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6832\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 40\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244327 -> initscore=-1.129099\n",
      "[LightGBM] [Info] Start training from score -1.129099\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358009\ttraining's auc: 0.898756\tvalid_1's binary_logloss: 0.358359\tvalid_1's auc: 0.898223\n",
      "[100]\ttraining's binary_logloss: 0.333349\ttraining's auc: 0.900106\tvalid_1's binary_logloss: 0.334006\tvalid_1's auc: 0.899484\n",
      "[150]\ttraining's binary_logloss: 0.328317\ttraining's auc: 0.90108\tvalid_1's binary_logloss: 0.329383\tvalid_1's auc: 0.900253\n",
      "[200]\ttraining's binary_logloss: 0.326479\ttraining's auc: 0.901794\tvalid_1's binary_logloss: 0.32805\tvalid_1's auc: 0.900678\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326479\ttraining's auc: 0.901794\tvalid_1's binary_logloss: 0.32805\tvalid_1's auc: 0.900678\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7820946804947713\n",
      "0.9006775887242607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9085    0.8633    0.8853    251890\n",
      "           1     0.6336    0.7311    0.6789     81443\n",
      "\n",
      "    accuracy                         0.8310    333333\n",
      "   macro avg     0.7711    0.7972    0.7821    333333\n",
      "weighted avg     0.8413    0.8310    0.8349    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54686\tvalidation_0-auc:0.87028\tvalidation_1-logloss:0.54685\tvalidation_1-auc:0.87021\n",
      "[50]\tvalidation_0-logloss:0.36437\tvalidation_0-auc:0.89774\tvalidation_1-logloss:0.36534\tvalidation_1-auc:0.89643\n",
      "[100]\tvalidation_0-logloss:0.33441\tvalidation_0-auc:0.90107\tvalidation_1-logloss:0.33639\tvalidation_1-auc:0.89926\n",
      "[150]\tvalidation_0-logloss:0.32679\tvalidation_0-auc:0.90288\tvalidation_1-logloss:0.32976\tvalidation_1-auc:0.90053\n",
      "[199]\tvalidation_0-logloss:0.32385\tvalidation_0-auc:0.90399\tvalidation_1-logloss:0.32769\tvalidation_1-auc:0.90114\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7830807838338345\n",
      "0.901136940137689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9086    0.8646    0.8861    251890\n",
      "           1     0.6358    0.7311    0.6801     81443\n",
      "\n",
      "    accuracy                         0.8320    333333\n",
      "   macro avg     0.7722    0.7978    0.7831    333333\n",
      "weighted avg     0.8420    0.8320    0.8357    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7786538069171698\n",
      "0.8962746281360341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9031    0.8684    0.8854    251890\n",
      "           1     0.6362    0.7118    0.6719     81443\n",
      "\n",
      "    accuracy                         0.8301    333333\n",
      "   macro avg     0.7697    0.7901    0.7787    333333\n",
      "weighted avg     0.8379    0.8301    0.8332    333333\n",
      "\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.4099999999999998 0.7636373178001735\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3599999999999999 0.7767121741958718\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7822653888648534\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.782900677744078\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7779333868001664\n",
      "LOGREG--------------\n",
      "accuracy 0.82171\n",
      "f1_score 0.7630395977064199\n",
      "auc 0.8781794051981157\n",
      "sensitivity 0.6624698524302007 specificity 0.8732806439228458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8888    0.8733    0.8809    151074\n",
      "           1     0.6287    0.6625    0.6451     48926\n",
      "\n",
      "    accuracy                         0.8217    200000\n",
      "   macro avg     0.7587    0.7679    0.7630    200000\n",
      "weighted avg     0.8251    0.8217    0.8233    200000\n",
      "\n",
      "Random Forest--------------\n",
      "accuracy 0.82281\n",
      "f1_score 0.7766092800659706\n",
      "auc 0.8942376418524164\n",
      "sensitivity 0.7522380738257777 specificity 0.8456650383255888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9133    0.8457    0.8782    151074\n",
      "           1     0.6122    0.7522    0.6750     48926\n",
      "\n",
      "    accuracy                         0.8228    200000\n",
      "   macro avg     0.7628    0.7990    0.7766    200000\n",
      "weighted avg     0.8397    0.8228    0.8285    200000\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 244328, number of negative: 755672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6831\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000000, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129096\n",
      "[LightGBM] [Info] Start training from score -1.129096\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "accuracy 0.83099\n",
      "f1_score 0.7821361907408511\n",
      "auc 0.900495140618026\n",
      "sensitivity 0.730593140661407 specificity 0.8635039781828773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9082    0.8635    0.8853    151074\n",
      "           1     0.6342    0.7306    0.6790     48926\n",
      "\n",
      "    accuracy                         0.8310    200000\n",
      "   macro avg     0.7712    0.7970    0.7821    200000\n",
      "weighted avg     0.8412    0.8310    0.8348    200000\n",
      "\n",
      "XGBoost--------------\n",
      "{'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 8, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 8, 'reg_lambda': 32, 'seed': 42, 'enable_categorical': True}\n",
      "accuracy 0.83161\n",
      "f1_score 0.7826644767361639\n",
      "auc 0.9008996619779915\n",
      "sensitivity 0.7297755794465111 specificity 0.8645895389014655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9081    0.8646    0.8858    151074\n",
      "           1     0.6358    0.7298    0.6795     48926\n",
      "\n",
      "    accuracy                         0.8316    200000\n",
      "   macro avg     0.7719    0.7972    0.7827    200000\n",
      "weighted avg     0.8415    0.8316    0.8353    200000\n",
      "\n",
      "MLP--------------\n",
      "accuracy 0.825605\n",
      "f1_score 0.7777714168331542\n",
      "auc 0.8959118508127084\n",
      "sensitivity 0.7391979724481871 specificity 0.8535883077167481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9100    0.8536    0.8809    151074\n",
      "           1     0.6205    0.7392    0.6747     48926\n",
      "\n",
      "    accuracy                         0.8256    200000\n",
      "   macro avg     0.7652    0.7964    0.7778    200000\n",
      "weighted avg     0.8392    0.8256    0.8304    200000\n",
      "\n",
      "['log_reg', 'randomforest', 'lightgbm', 'xgboost', 'mlp']\n",
      "[0.82171, 0.82281, 0.83099, 0.83161, 0.825605]\n",
      "[0.7630395977064199, 0.7766092800659706, 0.7821361907408511, 0.7826644767361639, 0.7777714168331542]\n",
      "[0.8781794051981157, 0.8942376418524164, 0.900495140618026, 0.9008996619779915, 0.8959118508127084]\n",
      "[0.8732806439228458, 0.8456650383255888, 0.8635039781828773, 0.8645895389014655, 0.8535883077167481]\n",
      "[0.6624698524302007, 0.7522380738257777, 0.730593140661407, 0.7297755794465111, 0.7391979724481871]\n",
      "50\n",
      "===========fold 0================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 50\n",
      "active_day                       0\n",
      "not_active_day                   0\n",
      "age_group_unknown                0\n",
      "gender_unknown                   0\n",
      "signin_count                     0\n",
      "newtab_count                     0\n",
      "ads_impression                   0\n",
      "clicks                           0\n",
      "life_time                        0\n",
      "ads_revenue                      0\n",
      "total_active_time                0\n",
      "work_count                       0\n",
      "search_volume_gg                 0\n",
      "search_volume                    0\n",
      "news_count                       0\n",
      "gender_female                    0\n",
      "serp_click                       0\n",
      "search_clicks_gg                 0\n",
      "youtube_count                    0\n",
      "other_search_gg                  0\n",
      "social_count                     0\n",
      "other_search                     0\n",
      "gender_male                      0\n",
      "age_group_25-34                  0\n",
      "ecommerce_count                  0\n",
      "technical_search_gg              0\n",
      "housekeeping_family_search       0\n",
      "age_group_18-24                  0\n",
      "housekeeping_family_search_gg    0\n",
      "videoclip_search_gg              0\n",
      "entertainment_count              0\n",
      "videoclip_search                 0\n",
      "ads_click                        0\n",
      "technical_search                 0\n",
      "sidebar_count                    0\n",
      "marketing_search_gg              0\n",
      "download_count                   0\n",
      "age_group_45-54                  0\n",
      "dating_search_gg                 0\n",
      "marketing_search                 0\n",
      "age_group_35-44                  0\n",
      "incognito_count                  0\n",
      "age_group_under 14               0\n",
      "dating_search                    0\n",
      "province_Hồ Chí Minh             0\n",
      "age_group_15-17                  0\n",
      "region_Northern Vietnam          0\n",
      "age_group_55+                    0\n",
      "province_type_urban              0\n",
      "region_Southern Vietnam          0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4199999999999998 best_score 0.7635499990947248\n",
      "0.8784204173252369\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8863    0.8802    0.8832    251891\n",
      "           1     0.6372    0.6507    0.6439     81443\n",
      "\n",
      "    accuracy                         0.8241    333334\n",
      "   macro avg     0.7617    0.7654    0.7635    333334\n",
      "weighted avg     0.8254    0.8241    0.8248    333334\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.776269091394529\n",
      "0.8938017819522575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9132    0.8458    0.8782    251891\n",
      "           1     0.6117    0.7512    0.6743     81443\n",
      "\n",
      "    accuracy                         0.8227    333334\n",
      "   macro avg     0.7624    0.7985    0.7763    333334\n",
      "weighted avg     0.8395    0.8227    0.8284    333334\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7242\n",
      "[LightGBM] [Info] Number of data points in the train set: 666666, number of used features: 50\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129097\n",
      "[LightGBM] [Info] Start training from score -1.129097\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358557\ttraining's auc: 0.898599\tvalid_1's binary_logloss: 0.359204\tvalid_1's auc: 0.897869\n",
      "[100]\ttraining's binary_logloss: 0.333765\ttraining's auc: 0.900146\tvalid_1's binary_logloss: 0.334853\tvalid_1's auc: 0.8992\n",
      "[150]\ttraining's binary_logloss: 0.328278\ttraining's auc: 0.901274\tvalid_1's binary_logloss: 0.329864\tvalid_1's auc: 0.900041\n",
      "[200]\ttraining's binary_logloss: 0.326295\ttraining's auc: 0.902039\tvalid_1's binary_logloss: 0.328431\tvalid_1's auc: 0.900483\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326295\ttraining's auc: 0.902039\tvalid_1's binary_logloss: 0.328431\tvalid_1's auc: 0.900483\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7823926809796793\n",
      "0.9004830554645383\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9123    0.8568    0.8837    251891\n",
      "           1     0.6272    0.7452    0.6811     81443\n",
      "\n",
      "    accuracy                         0.8295    333334\n",
      "   macro avg     0.7697    0.8010    0.7824    333334\n",
      "weighted avg     0.8426    0.8295    0.8342    333334\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54738\tvalidation_0-auc:0.86577\tvalidation_1-logloss:0.54742\tvalidation_1-auc:0.86458\n",
      "[50]\tvalidation_0-logloss:0.36579\tvalidation_0-auc:0.89663\tvalidation_1-logloss:0.36744\tvalidation_1-auc:0.89473\n",
      "[100]\tvalidation_0-logloss:0.33526\tvalidation_0-auc:0.90093\tvalidation_1-logloss:0.33817\tvalidation_1-auc:0.89838\n",
      "[150]\tvalidation_0-logloss:0.32713\tvalidation_0-auc:0.90300\tvalidation_1-logloss:0.33106\tvalidation_1-auc:0.89989\n",
      "[199]\tvalidation_0-logloss:0.32353\tvalidation_0-auc:0.90437\tvalidation_1-logloss:0.32844\tvalidation_1-auc:0.90069\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7826933436238318\n",
      "0.9006921353304049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9081    0.8650    0.8860    251891\n",
      "           1     0.6359    0.7292    0.6794     81443\n",
      "\n",
      "    accuracy                         0.8318    333334\n",
      "   macro avg     0.7720    0.7971    0.7827    333334\n",
      "weighted avg     0.8416    0.8318    0.8355    333334\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.778514950614618\n",
      "0.8965819307854903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9050    0.8644    0.8843    251891\n",
      "           1     0.6318    0.7195    0.6728     81443\n",
      "\n",
      "    accuracy                         0.8290    333334\n",
      "   macro avg     0.7684    0.7919    0.7785    333334\n",
      "weighted avg     0.8383    0.8290    0.8326    333334\n",
      "\n",
      "===========fold 1================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 50\n",
      "active_day                       0\n",
      "not_active_day                   0\n",
      "age_group_unknown                0\n",
      "gender_unknown                   0\n",
      "signin_count                     0\n",
      "newtab_count                     0\n",
      "ads_impression                   0\n",
      "clicks                           0\n",
      "life_time                        0\n",
      "ads_revenue                      0\n",
      "total_active_time                0\n",
      "work_count                       0\n",
      "search_volume_gg                 0\n",
      "search_volume                    0\n",
      "news_count                       0\n",
      "gender_female                    0\n",
      "serp_click                       0\n",
      "search_clicks_gg                 0\n",
      "youtube_count                    0\n",
      "other_search_gg                  0\n",
      "social_count                     0\n",
      "other_search                     0\n",
      "gender_male                      0\n",
      "age_group_25-34                  0\n",
      "ecommerce_count                  0\n",
      "technical_search_gg              0\n",
      "housekeeping_family_search       0\n",
      "age_group_18-24                  0\n",
      "housekeeping_family_search_gg    0\n",
      "videoclip_search_gg              0\n",
      "entertainment_count              0\n",
      "videoclip_search                 0\n",
      "ads_click                        0\n",
      "technical_search                 0\n",
      "sidebar_count                    0\n",
      "marketing_search_gg              0\n",
      "download_count                   0\n",
      "age_group_45-54                  0\n",
      "dating_search_gg                 0\n",
      "marketing_search                 0\n",
      "age_group_35-44                  0\n",
      "incognito_count                  0\n",
      "age_group_under 14               0\n",
      "dating_search                    0\n",
      "province_Hồ Chí Minh             0\n",
      "age_group_15-17                  0\n",
      "region_Northern Vietnam          0\n",
      "age_group_55+                    0\n",
      "province_type_urban              0\n",
      "region_Southern Vietnam          0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4199999999999998 best_score 0.7650211341046698\n",
      "0.8784895927487386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8872    0.8805    0.8838    251891\n",
      "           1     0.6388    0.6538    0.6462     81442\n",
      "\n",
      "    accuracy                         0.8251    333333\n",
      "   macro avg     0.7630    0.7671    0.7650    333333\n",
      "weighted avg     0.8265    0.8251    0.8258    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.7759399808521299\n",
      "0.8939896085794385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9112    0.8489    0.8789    251891\n",
      "           1     0.6142    0.7441    0.6729     81442\n",
      "\n",
      "    accuracy                         0.8233    333333\n",
      "   macro avg     0.7627    0.7965    0.7759    333333\n",
      "weighted avg     0.8386    0.8233    0.8286    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162886, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7242\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 50\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244329 -> initscore=-1.129091\n",
      "[LightGBM] [Info] Start training from score -1.129091\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358772\ttraining's auc: 0.898375\tvalid_1's binary_logloss: 0.359038\tvalid_1's auc: 0.898264\n",
      "[100]\ttraining's binary_logloss: 0.333996\ttraining's auc: 0.899923\tvalid_1's binary_logloss: 0.334509\tvalid_1's auc: 0.899609\n",
      "[150]\ttraining's binary_logloss: 0.328583\ttraining's auc: 0.901008\tvalid_1's binary_logloss: 0.329412\tvalid_1's auc: 0.900491\n",
      "[200]\ttraining's binary_logloss: 0.326567\ttraining's auc: 0.901793\tvalid_1's binary_logloss: 0.327805\tvalid_1's auc: 0.901001\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326567\ttraining's auc: 0.901793\tvalid_1's binary_logloss: 0.327805\tvalid_1's auc: 0.901001\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7826601198523115\n",
      "0.9010006395902234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9082    0.8648    0.8859    251891\n",
      "           1     0.6356    0.7296    0.6794     81442\n",
      "\n",
      "    accuracy                         0.8317    333333\n",
      "   macro avg     0.7719    0.7972    0.7827    333333\n",
      "weighted avg     0.8416    0.8317    0.8355    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54736\tvalidation_0-auc:0.86598\tvalidation_1-logloss:0.54742\tvalidation_1-auc:0.86432\n",
      "[50]\tvalidation_0-logloss:0.36586\tvalidation_0-auc:0.89648\tvalidation_1-logloss:0.36740\tvalidation_1-auc:0.89477\n",
      "[100]\tvalidation_0-logloss:0.33550\tvalidation_0-auc:0.90069\tvalidation_1-logloss:0.33797\tvalidation_1-auc:0.89858\n",
      "[150]\tvalidation_0-logloss:0.32743\tvalidation_0-auc:0.90274\tvalidation_1-logloss:0.33074\tvalidation_1-auc:0.90020\n",
      "[199]\tvalidation_0-logloss:0.32386\tvalidation_0-auc:0.90413\tvalidation_1-logloss:0.32795\tvalidation_1-auc:0.90114\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.7830160261644784\n",
      "0.9011429528822432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9138    0.8549    0.8834    251891\n",
      "           1     0.6259    0.7507    0.6826     81442\n",
      "\n",
      "    accuracy                         0.8295    333333\n",
      "   macro avg     0.7699    0.8028    0.7830    333333\n",
      "weighted avg     0.8435    0.8295    0.8343    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7793870665219312\n",
      "0.8971627353362656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9067    0.8625    0.8841    251891\n",
      "           1     0.6305    0.7255    0.6747     81442\n",
      "\n",
      "    accuracy                         0.8291    333333\n",
      "   macro avg     0.7686    0.7940    0.7794    333333\n",
      "weighted avg     0.8392    0.8291    0.8329    333333\n",
      "\n",
      "===========fold 2================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 50\n",
      "active_day                       0\n",
      "not_active_day                   0\n",
      "age_group_unknown                0\n",
      "gender_unknown                   0\n",
      "signin_count                     0\n",
      "newtab_count                     0\n",
      "ads_impression                   0\n",
      "clicks                           0\n",
      "life_time                        0\n",
      "ads_revenue                      0\n",
      "total_active_time                0\n",
      "work_count                       0\n",
      "search_volume_gg                 0\n",
      "search_volume                    0\n",
      "news_count                       0\n",
      "gender_female                    0\n",
      "serp_click                       0\n",
      "search_clicks_gg                 0\n",
      "youtube_count                    0\n",
      "other_search_gg                  0\n",
      "social_count                     0\n",
      "other_search                     0\n",
      "gender_male                      0\n",
      "age_group_25-34                  0\n",
      "ecommerce_count                  0\n",
      "technical_search_gg              0\n",
      "housekeeping_family_search       0\n",
      "age_group_18-24                  0\n",
      "housekeeping_family_search_gg    0\n",
      "videoclip_search_gg              0\n",
      "entertainment_count              0\n",
      "videoclip_search                 0\n",
      "ads_click                        0\n",
      "technical_search                 0\n",
      "sidebar_count                    0\n",
      "marketing_search_gg              0\n",
      "download_count                   0\n",
      "age_group_45-54                  0\n",
      "dating_search_gg                 0\n",
      "marketing_search                 0\n",
      "age_group_35-44                  0\n",
      "incognito_count                  0\n",
      "age_group_under 14               0\n",
      "dating_search                    0\n",
      "province_Hồ Chí Minh             0\n",
      "age_group_15-17                  0\n",
      "region_Northern Vietnam          0\n",
      "age_group_55+                    0\n",
      "province_type_urban              0\n",
      "region_Southern Vietnam          0\n",
      "dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4199999999999998 best_score 0.7643567562098222\n",
      "0.8784135797179908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8874    0.8789    0.8831    251890\n",
      "           1     0.6363    0.6551    0.6456     81443\n",
      "\n",
      "    accuracy                         0.8242    333333\n",
      "   macro avg     0.7619    0.7670    0.7644    333333\n",
      "weighted avg     0.8261    0.8242    0.8251    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.7763127816282033\n",
      "0.8942154957673385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9083    0.8548    0.8807    251890\n",
      "           1     0.6201    0.7331    0.6719     81443\n",
      "\n",
      "    accuracy                         0.8251    333333\n",
      "   macro avg     0.7642    0.7940    0.7763    333333\n",
      "weighted avg     0.8379    0.8251    0.8297    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7236\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 50\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244327 -> initscore=-1.129099\n",
      "[LightGBM] [Info] Start training from score -1.129099\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358691\ttraining's auc: 0.898567\tvalid_1's binary_logloss: 0.358981\tvalid_1's auc: 0.898105\n",
      "[100]\ttraining's binary_logloss: 0.33389\ttraining's auc: 0.90004\tvalid_1's binary_logloss: 0.33446\tvalid_1's auc: 0.899496\n",
      "[150]\ttraining's binary_logloss: 0.328403\ttraining's auc: 0.901166\tvalid_1's binary_logloss: 0.329367\tvalid_1's auc: 0.900415\n",
      "[200]\ttraining's binary_logloss: 0.326397\ttraining's auc: 0.901954\tvalid_1's binary_logloss: 0.327867\tvalid_1's auc: 0.900897\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326397\ttraining's auc: 0.901954\tvalid_1's binary_logloss: 0.327867\tvalid_1's auc: 0.900897\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7823687627590921\n",
      "0.9008973128486364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9088    0.8631    0.8854    251890\n",
      "           1     0.6336    0.7322    0.6794     81443\n",
      "\n",
      "    accuracy                         0.8311    333333\n",
      "   macro avg     0.7712    0.7977    0.7824    333333\n",
      "weighted avg     0.8416    0.8311    0.8350    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54738\tvalidation_0-auc:0.86549\tvalidation_1-logloss:0.54738\tvalidation_1-auc:0.86541\n",
      "[50]\tvalidation_0-logloss:0.36605\tvalidation_0-auc:0.89651\tvalidation_1-logloss:0.36695\tvalidation_1-auc:0.89526\n",
      "[100]\tvalidation_0-logloss:0.33554\tvalidation_0-auc:0.90074\tvalidation_1-logloss:0.33752\tvalidation_1-auc:0.89890\n",
      "[150]\tvalidation_0-logloss:0.32744\tvalidation_0-auc:0.90278\tvalidation_1-logloss:0.33040\tvalidation_1-auc:0.90038\n",
      "[199]\tvalidation_0-logloss:0.32382\tvalidation_0-auc:0.90416\tvalidation_1-logloss:0.32775\tvalidation_1-auc:0.90119\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7831373930536244\n",
      "0.901191545578723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9019    0.8778    0.8896    251890\n",
      "           1     0.6508    0.7046    0.6766     81443\n",
      "\n",
      "    accuracy                         0.8354    333333\n",
      "   macro avg     0.7763    0.7912    0.7831    333333\n",
      "weighted avg     0.8405    0.8354    0.8376    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4199999999999998 best_score 0.7791547198710684\n",
      "0.8967671604272818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9061    0.8633    0.8842    251890\n",
      "           1     0.6311    0.7234    0.6741     81443\n",
      "\n",
      "    accuracy                         0.8291    333333\n",
      "   macro avg     0.7686    0.7933    0.7792    333333\n",
      "weighted avg     0.8389    0.8291    0.8329    333333\n",
      "\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.4199999999999998 0.7643097541794163\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3699999999999999 0.7761323573311238\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7824307191358058\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7828413636898839\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7786312497628838\n",
      "LOGREG--------------\n",
      "accuracy 0.825115\n",
      "f1_score 0.7649744916443333\n",
      "auc 0.8784114669460334\n",
      "sensitivity 0.6525364836692147 specificity 0.8810053351337755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8867    0.8810    0.8839    151074\n",
      "           1     0.6398    0.6525    0.6461     48926\n",
      "\n",
      "    accuracy                         0.8251    200000\n",
      "   macro avg     0.7633    0.7668    0.7650    200000\n",
      "weighted avg     0.8263    0.8251    0.8257    200000\n",
      "\n",
      "Random Forest--------------\n",
      "accuracy 0.824105\n",
      "f1_score 0.7756130030714761\n",
      "auc 0.8936491372903018\n",
      "sensitivity 0.7342312880676941 specificity 0.8532110091743119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9084    0.8532    0.8799    151074\n",
      "           1     0.6183    0.7342    0.6713     48926\n",
      "\n",
      "    accuracy                         0.8241    200000\n",
      "   macro avg     0.7633    0.7937    0.7756    200000\n",
      "weighted avg     0.8374    0.8241    0.8289    200000\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 244328, number of negative: 755672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7238\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000000, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129096\n",
      "[LightGBM] [Info] Start training from score -1.129096\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "accuracy 0.831355\n",
      "f1_score 0.7826504721807575\n",
      "auc 0.900551377850975\n",
      "sensitivity 0.7316764092711442 specificity 0.8636363636363636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9086    0.8636    0.8855    151074\n",
      "           1     0.6347    0.7317    0.6798     48926\n",
      "\n",
      "    accuracy                         0.8314    200000\n",
      "   macro avg     0.7717    0.7977    0.7827    200000\n",
      "weighted avg     0.8416    0.8314    0.8352    200000\n",
      "\n",
      "XGBoost--------------\n",
      "{'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 8, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 8, 'reg_lambda': 32, 'seed': 42, 'enable_categorical': True}\n",
      "accuracy 0.832345\n",
      "f1_score 0.7834073221283668\n",
      "auc 0.9009395816336423\n",
      "sensitivity 0.7296938233250214 specificity 0.8655890490752876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9082    0.8656    0.8864    151074\n",
      "           1     0.6374    0.7297    0.6805     48926\n",
      "\n",
      "    accuracy                         0.8323    200000\n",
      "   macro avg     0.7728    0.7976    0.7834    200000\n",
      "weighted avg     0.8419    0.8323    0.8360    200000\n",
      "\n",
      "MLP--------------\n",
      "accuracy 0.82454\n",
      "f1_score 0.7772737335712232\n",
      "auc 0.8964082010857013\n",
      "sensitivity 0.7437149981604873 specificity 0.8507155433760938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9111    0.8507    0.8799    151074\n",
      "           1     0.6174    0.7437    0.6747     48926\n",
      "\n",
      "    accuracy                         0.8245    200000\n",
      "   macro avg     0.7642    0.7972    0.7773    200000\n",
      "weighted avg     0.8392    0.8245    0.8297    200000\n",
      "\n",
      "['log_reg', 'randomforest', 'lightgbm', 'xgboost', 'mlp']\n",
      "[0.825115, 0.824105, 0.831355, 0.832345, 0.82454]\n",
      "[0.7649744916443333, 0.7756130030714761, 0.7826504721807575, 0.7834073221283668, 0.7772737335712232]\n",
      "[0.8784114669460334, 0.8936491372903018, 0.900551377850975, 0.9009395816336423, 0.8964082010857013]\n",
      "[0.8810053351337755, 0.8532110091743119, 0.8636363636363636, 0.8655890490752876, 0.8507155433760938]\n",
      "[0.6525364836692147, 0.7342312880676941, 0.7316764092711442, 0.7296938233250214, 0.7437149981604873]\n",
      "100\n",
      "===========fold 0================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 100\n",
      "active_day              0\n",
      "not_active_day          0\n",
      "age_group_unknown       0\n",
      "gender_unknown          0\n",
      "signin_count            0\n",
      "                       ..\n",
      "province_Đắk Lắk        0\n",
      "province_Hưng Yên       0\n",
      "province_Bình Phước     0\n",
      "province_Tuyên Quang    0\n",
      "province_Hà Tĩnh        0\n",
      "Length: 100, dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7630791075468005\n",
      "0.8784125660264597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8891    0.8730    0.8810    251891\n",
      "           1     0.6281    0.6632    0.6452     81443\n",
      "\n",
      "    accuracy                         0.8218    333334\n",
      "   macro avg     0.7586    0.7681    0.7631    333334\n",
      "weighted avg     0.8253    0.8218    0.8234    333334\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.768127754416051\n",
      "0.8892341455588243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9045    0.8491    0.8760    251891\n",
      "           1     0.6077    0.7228    0.6603     81443\n",
      "\n",
      "    accuracy                         0.8183    333334\n",
      "   macro avg     0.7561    0.7860    0.7681    333334\n",
      "weighted avg     0.8320    0.8183    0.8233    333334\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7455\n",
      "[LightGBM] [Info] Number of data points in the train set: 666666, number of used features: 100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129097\n",
      "[LightGBM] [Info] Start training from score -1.129097\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358397\ttraining's auc: 0.8987\tvalid_1's binary_logloss: 0.359041\tvalid_1's auc: 0.897968\n",
      "[100]\ttraining's binary_logloss: 0.333744\ttraining's auc: 0.900163\tvalid_1's binary_logloss: 0.334837\tvalid_1's auc: 0.899219\n",
      "[150]\ttraining's binary_logloss: 0.328247\ttraining's auc: 0.901265\tvalid_1's binary_logloss: 0.329815\tvalid_1's auc: 0.900047\n",
      "[200]\ttraining's binary_logloss: 0.326267\ttraining's auc: 0.902044\tvalid_1's binary_logloss: 0.328397\tvalid_1's auc: 0.900493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326267\ttraining's auc: 0.902044\tvalid_1's binary_logloss: 0.328397\tvalid_1's auc: 0.900493\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7824116684172594\n",
      "0.900493387538289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9059    0.8688    0.8869    251891\n",
      "           1     0.6398    0.7208    0.6779     81443\n",
      "\n",
      "    accuracy                         0.8326    333334\n",
      "   macro avg     0.7728    0.7948    0.7824    333334\n",
      "weighted avg     0.8409    0.8326    0.8359    333334\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54578\tvalidation_0-auc:0.89255\tvalidation_1-logloss:0.54582\tvalidation_1-auc:0.89141\n",
      "[50]\tvalidation_0-logloss:0.36249\tvalidation_0-auc:0.89849\tvalidation_1-logloss:0.36410\tvalidation_1-auc:0.89666\n",
      "[100]\tvalidation_0-logloss:0.33359\tvalidation_0-auc:0.90175\tvalidation_1-logloss:0.33653\tvalidation_1-auc:0.89925\n",
      "[150]\tvalidation_0-logloss:0.32622\tvalidation_0-auc:0.90341\tvalidation_1-logloss:0.33022\tvalidation_1-auc:0.90031\n",
      "[199]\tvalidation_0-logloss:0.32312\tvalidation_0-auc:0.90457\tvalidation_1-logloss:0.32807\tvalidation_1-auc:0.90090\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7829120166978498\n",
      "0.9009015844913779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9084    0.8647    0.8860    251891\n",
      "           1     0.6357    0.7304    0.6798     81443\n",
      "\n",
      "    accuracy                         0.8319    333334\n",
      "   macro avg     0.7721    0.7976    0.7829    333334\n",
      "weighted avg     0.8418    0.8319    0.8356    333334\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7782612944020226\n",
      "0.8966610861156951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9071    0.8601    0.8830    251891\n",
      "           1     0.6271    0.7275    0.6735     81443\n",
      "\n",
      "    accuracy                         0.8277    333334\n",
      "   macro avg     0.7671    0.7938    0.7783    333334\n",
      "weighted avg     0.8387    0.8277    0.8318    333334\n",
      "\n",
      "===========fold 1================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 100\n",
      "active_day              0\n",
      "not_active_day          0\n",
      "age_group_unknown       0\n",
      "gender_unknown          0\n",
      "signin_count            0\n",
      "                       ..\n",
      "province_Đắk Lắk        0\n",
      "province_Hưng Yên       0\n",
      "province_Bình Phước     0\n",
      "province_Tuyên Quang    0\n",
      "province_Hà Tĩnh        0\n",
      "Length: 100, dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7642279751846615\n",
      "0.878531370404299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8888    0.8755    0.8821    251891\n",
      "           1     0.6320    0.6613    0.6463     81442\n",
      "\n",
      "    accuracy                         0.8232    333333\n",
      "   macro avg     0.7604    0.7684    0.7642    333333\n",
      "weighted avg     0.8261    0.8232    0.8245    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3599999999999999 best_score 0.7678951803253451\n",
      "0.8895511189150243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9033    0.8512    0.8765    251891\n",
      "           1     0.6094    0.7182    0.6593     81442\n",
      "\n",
      "    accuracy                         0.8187    333333\n",
      "   macro avg     0.7563    0.7847    0.7679    333333\n",
      "weighted avg     0.8315    0.8187    0.8234    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162886, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7459\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244329 -> initscore=-1.129091\n",
      "[LightGBM] [Info] Start training from score -1.129091\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.35857\ttraining's auc: 0.898468\tvalid_1's binary_logloss: 0.358818\tvalid_1's auc: 0.898371\n",
      "[100]\ttraining's binary_logloss: 0.333965\ttraining's auc: 0.899951\tvalid_1's binary_logloss: 0.334493\tvalid_1's auc: 0.899629\n",
      "[150]\ttraining's binary_logloss: 0.328509\ttraining's auc: 0.901021\tvalid_1's binary_logloss: 0.329336\tvalid_1's auc: 0.900511\n",
      "[200]\ttraining's binary_logloss: 0.326533\ttraining's auc: 0.901816\tvalid_1's binary_logloss: 0.327831\tvalid_1's auc: 0.900985\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326533\ttraining's auc: 0.901816\tvalid_1's binary_logloss: 0.327831\tvalid_1's auc: 0.900985\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7826059172637501\n",
      "0.9009847464711332\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9114    0.8588    0.8843    251891\n",
      "           1     0.6294    0.7417    0.6809     81442\n",
      "\n",
      "    accuracy                         0.8302    333333\n",
      "   macro avg     0.7704    0.8002    0.7826    333333\n",
      "weighted avg     0.8425    0.8302    0.8346    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54575\tvalidation_0-auc:0.89240\tvalidation_1-logloss:0.54580\tvalidation_1-auc:0.89155\n",
      "[50]\tvalidation_0-logloss:0.36259\tvalidation_0-auc:0.89831\tvalidation_1-logloss:0.36407\tvalidation_1-auc:0.89675\n",
      "[100]\tvalidation_0-logloss:0.33378\tvalidation_0-auc:0.90160\tvalidation_1-logloss:0.33626\tvalidation_1-auc:0.89954\n",
      "[150]\tvalidation_0-logloss:0.32644\tvalidation_0-auc:0.90322\tvalidation_1-logloss:0.32979\tvalidation_1-auc:0.90071\n",
      "[199]\tvalidation_0-logloss:0.32341\tvalidation_0-auc:0.90434\tvalidation_1-logloss:0.32754\tvalidation_1-auc:0.90139\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7829882140116653\n",
      "0.9013867405123037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9108    0.8604    0.8849    251891\n",
      "           1     0.6313    0.7394    0.6811     81442\n",
      "\n",
      "    accuracy                         0.8308    333333\n",
      "   macro avg     0.7711    0.7999    0.7830    333333\n",
      "weighted avg     0.8425    0.8308    0.8351    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7799894270184654\n",
      "0.8973667389974948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9082    0.8606    0.8838    251891\n",
      "           1     0.6290    0.7310    0.6762     81442\n",
      "\n",
      "    accuracy                         0.8290    333333\n",
      "   macro avg     0.7686    0.7958    0.7800    333333\n",
      "weighted avg     0.8400    0.8290    0.8331    333333\n",
      "\n",
      "===========fold 2================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "Number of features 100\n",
      "active_day              0\n",
      "not_active_day          0\n",
      "age_group_unknown       0\n",
      "gender_unknown          0\n",
      "signin_count            0\n",
      "                       ..\n",
      "province_Đắk Lắk        0\n",
      "province_Hưng Yên       0\n",
      "province_Bình Phước     0\n",
      "province_Tuyên Quang    0\n",
      "province_Hà Tĩnh        0\n",
      "Length: 100, dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7641329531223646\n",
      "0.8786111954029292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8888    0.8754    0.8821    251890\n",
      "           1     0.6319    0.6612    0.6462     81443\n",
      "\n",
      "    accuracy                         0.8231    333333\n",
      "   macro avg     0.7603    0.7683    0.7641    333333\n",
      "weighted avg     0.8260    0.8231    0.8244    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.34999999999999987 best_score 0.76842078782698\n",
      "0.889761377367259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9085    0.8421    0.8740    251890\n",
      "           1     0.6017    0.7377    0.6628     81443\n",
      "\n",
      "    accuracy                         0.8166    333333\n",
      "   macro avg     0.7551    0.7899    0.7684    333333\n",
      "weighted avg     0.8335    0.8166    0.8224    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7449\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 100\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244327 -> initscore=-1.129099\n",
      "[LightGBM] [Info] Start training from score -1.129099\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.358499\ttraining's auc: 0.898678\tvalid_1's binary_logloss: 0.358824\tvalid_1's auc: 0.898168\n",
      "[100]\ttraining's binary_logloss: 0.333825\ttraining's auc: 0.900067\tvalid_1's binary_logloss: 0.334452\tvalid_1's auc: 0.899459\n",
      "[150]\ttraining's binary_logloss: 0.328349\ttraining's auc: 0.901143\tvalid_1's binary_logloss: 0.329375\tvalid_1's auc: 0.900339\n",
      "[200]\ttraining's binary_logloss: 0.326412\ttraining's auc: 0.901919\tvalid_1's binary_logloss: 0.327973\tvalid_1's auc: 0.900792\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326412\ttraining's auc: 0.901919\tvalid_1's binary_logloss: 0.327973\tvalid_1's auc: 0.900792\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7823931903353373\n",
      "0.9007918379502735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9057    0.8692    0.8870    251890\n",
      "           1     0.6402    0.7200    0.6777     81443\n",
      "\n",
      "    accuracy                         0.8327    333333\n",
      "   macro avg     0.7729    0.7946    0.7824    333333\n",
      "weighted avg     0.8408    0.8327    0.8359    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54574\tvalidation_0-auc:0.89282\tvalidation_1-logloss:0.54578\tvalidation_1-auc:0.89164\n",
      "[50]\tvalidation_0-logloss:0.36274\tvalidation_0-auc:0.89830\tvalidation_1-logloss:0.36379\tvalidation_1-auc:0.89694\n",
      "[100]\tvalidation_0-logloss:0.33385\tvalidation_0-auc:0.90161\tvalidation_1-logloss:0.33601\tvalidation_1-auc:0.89967\n",
      "[150]\tvalidation_0-logloss:0.32648\tvalidation_0-auc:0.90324\tvalidation_1-logloss:0.32958\tvalidation_1-auc:0.90078\n",
      "[199]\tvalidation_0-logloss:0.32338\tvalidation_0-auc:0.90441\tvalidation_1-logloss:0.32742\tvalidation_1-auc:0.90138\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7831936309337635\n",
      "0.9013830196852032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9022    0.8772    0.8895    251890\n",
      "           1     0.6502    0.7058    0.6769     81443\n",
      "\n",
      "    accuracy                         0.8353    333333\n",
      "   macro avg     0.7762    0.7915    0.7832    333333\n",
      "weighted avg     0.8406    0.8353    0.8376    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7790064956660595\n",
      "0.8973427661677273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9076    0.8603    0.8833    251890\n",
      "           1     0.6279    0.7290    0.6747     81443\n",
      "\n",
      "    accuracy                         0.8282    333333\n",
      "   macro avg     0.7677    0.7947    0.7790    333333\n",
      "weighted avg     0.8392    0.8282    0.8323    333333\n",
      "\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.4099999999999998 0.7638129653085594\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3599999999999999 0.7681340292679028\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7824448215041773\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7829910438517023\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7790676220342521\n",
      "LOGREG--------------\n",
      "accuracy 0.822205\n",
      "f1_score 0.7637427931606957\n",
      "auc 0.8787615204831318\n",
      "sensitivity 0.6637779503740343 specificity 0.873512318466447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8892    0.8735    0.8813    151074\n",
      "           1     0.6296    0.6638    0.6462     48926\n",
      "\n",
      "    accuracy                         0.8222    200000\n",
      "   macro avg     0.7594    0.7686    0.7637    200000\n",
      "weighted avg     0.8257    0.8222    0.8238    200000\n",
      "\n",
      "Random Forest--------------\n",
      "accuracy 0.819345\n",
      "f1_score 0.7698460998997572\n",
      "auc 0.8901866475845452\n",
      "sensitivity 0.7267914810121407 specificity 0.8493188768418126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9057    0.8493    0.8766    151074\n",
      "           1     0.6097    0.7268    0.6631     48926\n",
      "\n",
      "    accuracy                         0.8193    200000\n",
      "   macro avg     0.7577    0.7881    0.7698    200000\n",
      "weighted avg     0.8333    0.8193    0.8244    200000\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 244328, number of negative: 755672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7455\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000000, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129096\n",
      "[LightGBM] [Info] Start training from score -1.129096\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "accuracy 0.83111\n",
      "f1_score 0.7825216563621793\n",
      "auc 0.9005887312295191\n",
      "sensitivity 0.7326166046682745 specificity 0.8630075327323034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9088    0.8630    0.8853    151074\n",
      "           1     0.6340    0.7326    0.6797     48926\n",
      "\n",
      "    accuracy                         0.8311    200000\n",
      "   macro avg     0.7714    0.7978    0.7825    200000\n",
      "weighted avg     0.8416    0.8311    0.8350    200000\n",
      "\n",
      "XGBoost--------------\n",
      "{'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 8, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 8, 'reg_lambda': 32, 'seed': 42, 'enable_categorical': True}\n",
      "accuracy 0.83253\n",
      "f1_score 0.7838386503979161\n",
      "auc 0.9011999326344582\n",
      "sensitivity 0.7315537750889097 specificity 0.8652316083508744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9087    0.8652    0.8864    151074\n",
      "           1     0.6374    0.7316    0.6812     48926\n",
      "\n",
      "    accuracy                         0.8325    200000\n",
      "   macro avg     0.7731    0.7984    0.7838    200000\n",
      "weighted avg     0.8423    0.8325    0.8362    200000\n",
      "\n",
      "MLP--------------\n",
      "accuracy 0.8297\n",
      "f1_score 0.7787355351972958\n",
      "auc 0.8968112288273385\n",
      "sensitivity 0.7148959653354044 specificity 0.8668798072467797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9037    0.8669    0.8849    151074\n",
      "           1     0.6349    0.7149    0.6725     48926\n",
      "\n",
      "    accuracy                         0.8297    200000\n",
      "   macro avg     0.7693    0.7909    0.7787    200000\n",
      "weighted avg     0.8380    0.8297    0.8330    200000\n",
      "\n",
      "['log_reg', 'randomforest', 'lightgbm', 'xgboost', 'mlp']\n",
      "[0.822205, 0.819345, 0.83111, 0.83253, 0.8297]\n",
      "[0.7637427931606957, 0.7698460998997572, 0.7825216563621793, 0.7838386503979161, 0.7787355351972958]\n",
      "[0.8787615204831318, 0.8901866475845452, 0.9005887312295191, 0.9011999326344582, 0.8968112288273385]\n",
      "[0.873512318466447, 0.8493188768418126, 0.8630075327323034, 0.8652316083508744, 0.8668798072467797]\n",
      "[0.6637779503740343, 0.7267914810121407, 0.7326166046682745, 0.7315537750889097, 0.7148959653354044]\n"
     ]
    }
   ],
   "source": [
    "nothing_score_dfs = []\n",
    "for n_features in [20,30,40,50,60,100]:\n",
    "    print(n_features)\n",
    "    nothing_oofs_ = cross_validate(train,FEATURES=top_features[:n_features])\n",
    "    nothing_score_df_, nothing_models_, nothing_predictions_ = train_model(nothing_oofs_,X_train[top_features[:n_features]], y_train, X_test[top_features[:n_features]], y_test)\n",
    "    nothing_score_dfs.append(nothing_score_df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>sensitivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.824080</td>\n",
       "      <td>0.763896</td>\n",
       "      <td>0.879435</td>\n",
       "      <td>0.879675</td>\n",
       "      <td>0.652414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.827780</td>\n",
       "      <td>0.779592</td>\n",
       "      <td>0.896402</td>\n",
       "      <td>0.857434</td>\n",
       "      <td>0.736214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.832790</td>\n",
       "      <td>0.782566</td>\n",
       "      <td>0.900184</td>\n",
       "      <td>0.869375</td>\n",
       "      <td>0.719822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.831520</td>\n",
       "      <td>0.782166</td>\n",
       "      <td>0.900118</td>\n",
       "      <td>0.865477</td>\n",
       "      <td>0.726669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.826385</td>\n",
       "      <td>0.778190</td>\n",
       "      <td>0.896955</td>\n",
       "      <td>0.855554</td>\n",
       "      <td>0.736316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy_score  f1_score  auc_score  specificity_score  \\\n",
       "0       log_reg        0.824080  0.763896   0.879435           0.879675   \n",
       "1  randomforest        0.827780  0.779592   0.896402           0.857434   \n",
       "2      lightgbm        0.832790  0.782566   0.900184           0.869375   \n",
       "3       xgboost        0.831520  0.782166   0.900118           0.865477   \n",
       "4           mlp        0.826385  0.778190   0.896955           0.855554   \n",
       "\n",
       "   sensitivity_score  \n",
       "0           0.652414  \n",
       "1           0.736214  \n",
       "2           0.719822  \n",
       "3           0.726669  \n",
       "4           0.736316  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_score_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>sensitivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>0.763073</td>\n",
       "      <td>0.879034</td>\n",
       "      <td>0.871176</td>\n",
       "      <td>0.666578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.825135</td>\n",
       "      <td>0.777650</td>\n",
       "      <td>0.894999</td>\n",
       "      <td>0.852072</td>\n",
       "      <td>0.741957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.832850</td>\n",
       "      <td>0.782706</td>\n",
       "      <td>0.900272</td>\n",
       "      <td>0.869263</td>\n",
       "      <td>0.720415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.830220</td>\n",
       "      <td>0.782616</td>\n",
       "      <td>0.900520</td>\n",
       "      <td>0.859301</td>\n",
       "      <td>0.740424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.822840</td>\n",
       "      <td>0.776885</td>\n",
       "      <td>0.896754</td>\n",
       "      <td>0.845069</td>\n",
       "      <td>0.754200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy_score  f1_score  auc_score  specificity_score  \\\n",
       "0       log_reg        0.821125  0.763073   0.879034           0.871176   \n",
       "1  randomforest        0.825135  0.777650   0.894999           0.852072   \n",
       "2      lightgbm        0.832850  0.782706   0.900272           0.869263   \n",
       "3       xgboost        0.830220  0.782616   0.900520           0.859301   \n",
       "4           mlp        0.822840  0.776885   0.896754           0.845069   \n",
       "\n",
       "   sensitivity_score  \n",
       "0           0.666578  \n",
       "1           0.741957  \n",
       "2           0.720415  \n",
       "3           0.740424  \n",
       "4           0.754200  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_score_dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>sensitivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.821710</td>\n",
       "      <td>0.763040</td>\n",
       "      <td>0.878179</td>\n",
       "      <td>0.873281</td>\n",
       "      <td>0.662470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.822810</td>\n",
       "      <td>0.776609</td>\n",
       "      <td>0.894238</td>\n",
       "      <td>0.845665</td>\n",
       "      <td>0.752238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.830990</td>\n",
       "      <td>0.782136</td>\n",
       "      <td>0.900495</td>\n",
       "      <td>0.863504</td>\n",
       "      <td>0.730593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.831610</td>\n",
       "      <td>0.782664</td>\n",
       "      <td>0.900900</td>\n",
       "      <td>0.864590</td>\n",
       "      <td>0.729776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.825605</td>\n",
       "      <td>0.777771</td>\n",
       "      <td>0.895912</td>\n",
       "      <td>0.853588</td>\n",
       "      <td>0.739198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy_score  f1_score  auc_score  specificity_score  \\\n",
       "0       log_reg        0.821710  0.763040   0.878179           0.873281   \n",
       "1  randomforest        0.822810  0.776609   0.894238           0.845665   \n",
       "2      lightgbm        0.830990  0.782136   0.900495           0.863504   \n",
       "3       xgboost        0.831610  0.782664   0.900900           0.864590   \n",
       "4           mlp        0.825605  0.777771   0.895912           0.853588   \n",
       "\n",
       "   sensitivity_score  \n",
       "0           0.662470  \n",
       "1           0.752238  \n",
       "2           0.730593  \n",
       "3           0.729776  \n",
       "4           0.739198  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_score_dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>sensitivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.825115</td>\n",
       "      <td>0.764974</td>\n",
       "      <td>0.878411</td>\n",
       "      <td>0.881005</td>\n",
       "      <td>0.652536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.824105</td>\n",
       "      <td>0.775613</td>\n",
       "      <td>0.893649</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>0.734231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.831355</td>\n",
       "      <td>0.782650</td>\n",
       "      <td>0.900551</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.731676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.832345</td>\n",
       "      <td>0.783407</td>\n",
       "      <td>0.900940</td>\n",
       "      <td>0.865589</td>\n",
       "      <td>0.729694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.824540</td>\n",
       "      <td>0.777274</td>\n",
       "      <td>0.896408</td>\n",
       "      <td>0.850716</td>\n",
       "      <td>0.743715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy_score  f1_score  auc_score  specificity_score  \\\n",
       "0       log_reg        0.825115  0.764974   0.878411           0.881005   \n",
       "1  randomforest        0.824105  0.775613   0.893649           0.853211   \n",
       "2      lightgbm        0.831355  0.782650   0.900551           0.863636   \n",
       "3       xgboost        0.832345  0.783407   0.900940           0.865589   \n",
       "4           mlp        0.824540  0.777274   0.896408           0.850716   \n",
       "\n",
       "   sensitivity_score  \n",
       "0           0.652536  \n",
       "1           0.734231  \n",
       "2           0.731676  \n",
       "3           0.729694  \n",
       "4           0.743715  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_score_dfs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>sensitivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.822205</td>\n",
       "      <td>0.763743</td>\n",
       "      <td>0.878762</td>\n",
       "      <td>0.873512</td>\n",
       "      <td>0.663778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.819345</td>\n",
       "      <td>0.769846</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.849319</td>\n",
       "      <td>0.726791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.831110</td>\n",
       "      <td>0.782522</td>\n",
       "      <td>0.900589</td>\n",
       "      <td>0.863008</td>\n",
       "      <td>0.732617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.832530</td>\n",
       "      <td>0.783839</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.865232</td>\n",
       "      <td>0.731554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>0.778736</td>\n",
       "      <td>0.896811</td>\n",
       "      <td>0.866880</td>\n",
       "      <td>0.714896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy_score  f1_score  auc_score  specificity_score  \\\n",
       "0       log_reg        0.822205  0.763743   0.878762           0.873512   \n",
       "1  randomforest        0.819345  0.769846   0.890187           0.849319   \n",
       "2      lightgbm        0.831110  0.782522   0.900589           0.863008   \n",
       "3       xgboost        0.832530  0.783839   0.901200           0.865232   \n",
       "4           mlp        0.829700  0.778736   0.896811           0.866880   \n",
       "\n",
       "   sensitivity_score  \n",
       "0           0.663778  \n",
       "1           0.726791  \n",
       "2           0.732617  \n",
       "3           0.731554  \n",
       "4           0.714896  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_score_dfs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========fold 0================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "os_name_macos          0\n",
      "os_name_windows        0\n",
      "age_group_15-17        0\n",
      "age_group_18-24        0\n",
      "age_group_25-34        0\n",
      "                      ..\n",
      "work_count             0\n",
      "social_count           0\n",
      "news_count             0\n",
      "entertainment_count    0\n",
      "ecommerce_count        0\n",
      "Length: 123, dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.762850413679721\n",
      "0.8784913614450465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8882    0.8747    0.8814    251891\n",
      "           1     0.6299    0.6594    0.6443     81443\n",
      "\n",
      "    accuracy                         0.8221    333334\n",
      "   macro avg     0.7590    0.7671    0.7629    333334\n",
      "weighted avg     0.8251    0.8221    0.8235    333334\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7645270174030648\n",
      "0.8873169551326421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8934    0.8660    0.8795    251891\n",
      "           1     0.6214    0.6804    0.6496     81443\n",
      "\n",
      "    accuracy                         0.8206    333334\n",
      "   macro avg     0.7574    0.7732    0.7645    333334\n",
      "weighted avg     0.8269    0.8206    0.8233    333334\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7501\n",
      "[LightGBM] [Info] Number of data points in the train set: 666666, number of used features: 123\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129097\n",
      "[LightGBM] [Info] Start training from score -1.129097\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.359047\ttraining's auc: 0.898425\tvalid_1's binary_logloss: 0.359689\tvalid_1's auc: 0.897717\n",
      "[100]\ttraining's binary_logloss: 0.333859\ttraining's auc: 0.900119\tvalid_1's binary_logloss: 0.334948\tvalid_1's auc: 0.899165\n",
      "[150]\ttraining's binary_logloss: 0.328221\ttraining's auc: 0.901264\tvalid_1's binary_logloss: 0.329814\tvalid_1's auc: 0.900025\n",
      "[200]\ttraining's binary_logloss: 0.326332\ttraining's auc: 0.902026\tvalid_1's binary_logloss: 0.328475\tvalid_1's auc: 0.90046\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326332\ttraining's auc: 0.902026\tvalid_1's binary_logloss: 0.328475\tvalid_1's auc: 0.90046\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7825293008789149\n",
      "0.9004602974098844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9058    0.8690    0.8871    251891\n",
      "           1     0.6401    0.7206    0.6780     81443\n",
      "\n",
      "    accuracy                         0.8328    333334\n",
      "   macro avg     0.7730    0.7948    0.7825    333334\n",
      "weighted avg     0.8409    0.8328    0.8360    333334\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54569\tvalidation_0-auc:0.89401\tvalidation_1-logloss:0.54574\tvalidation_1-auc:0.89273\n",
      "[50]\tvalidation_0-logloss:0.36356\tvalidation_0-auc:0.89829\tvalidation_1-logloss:0.36521\tvalidation_1-auc:0.89641\n",
      "[100]\tvalidation_0-logloss:0.33542\tvalidation_0-auc:0.90088\tvalidation_1-logloss:0.33831\tvalidation_1-auc:0.89837\n",
      "[150]\tvalidation_0-logloss:0.32654\tvalidation_0-auc:0.90329\tvalidation_1-logloss:0.33052\tvalidation_1-auc:0.90019\n",
      "[199]\tvalidation_0-logloss:0.32330\tvalidation_0-auc:0.90452\tvalidation_1-logloss:0.32826\tvalidation_1-auc:0.90085\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7826739056300246\n",
      "0.9008473100777434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9052    0.8706    0.8875    251891\n",
      "           1     0.6420    0.7179    0.6778     81443\n",
      "\n",
      "    accuracy                         0.8333    333334\n",
      "   macro avg     0.7736    0.7942    0.7827    333334\n",
      "weighted avg     0.8409    0.8333    0.8363    333334\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7786760026103212\n",
      "0.8966987782236463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9060    0.8628    0.8839    251891\n",
      "           1     0.6302    0.7232    0.6735     81443\n",
      "\n",
      "    accuracy                         0.8287    333334\n",
      "   macro avg     0.7681    0.7930    0.7787    333334\n",
      "weighted avg     0.8386    0.8287    0.8325    333334\n",
      "\n",
      "===========fold 1================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "os_name_macos          0\n",
      "os_name_windows        0\n",
      "age_group_15-17        0\n",
      "age_group_18-24        0\n",
      "age_group_25-34        0\n",
      "                      ..\n",
      "work_count             0\n",
      "social_count           0\n",
      "news_count             0\n",
      "entertainment_count    0\n",
      "ecommerce_count        0\n",
      "Length: 123, dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7639968544278193\n",
      "0.8785318706113031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8884    0.8761    0.8822    251891\n",
      "           1     0.6325    0.6597    0.6458     81442\n",
      "\n",
      "    accuracy                         0.8232    333333\n",
      "   macro avg     0.7605    0.7679    0.7640    333333\n",
      "weighted avg     0.8259    0.8232    0.8244    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7634021795288022\n",
      "0.8867952980956141\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8924    0.8662    0.8791    251891\n",
      "           1     0.6207    0.6771    0.6477     81442\n",
      "\n",
      "    accuracy                         0.8200    333333\n",
      "   macro avg     0.7566    0.7717    0.7634    333333\n",
      "weighted avg     0.8260    0.8200    0.8226    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162886, number of negative: 503781\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7505\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 123\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244329 -> initscore=-1.129091\n",
      "[LightGBM] [Info] Start training from score -1.129091\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.359245\ttraining's auc: 0.898244\tvalid_1's binary_logloss: 0.359505\tvalid_1's auc: 0.898129\n",
      "[100]\ttraining's binary_logloss: 0.334032\ttraining's auc: 0.899922\tvalid_1's binary_logloss: 0.334537\tvalid_1's auc: 0.899624\n",
      "[150]\ttraining's binary_logloss: 0.328455\ttraining's auc: 0.901052\tvalid_1's binary_logloss: 0.329253\tvalid_1's auc: 0.900559\n",
      "[200]\ttraining's binary_logloss: 0.326491\ttraining's auc: 0.901851\tvalid_1's binary_logloss: 0.327789\tvalid_1's auc: 0.901027\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326491\ttraining's auc: 0.901851\tvalid_1's binary_logloss: 0.327789\tvalid_1's auc: 0.901027\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3999999999999998 best_score 0.7825773759221477\n",
      "0.9010267328570343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9053    0.8701    0.8874    251891\n",
      "           1     0.6414    0.7186    0.6778     81442\n",
      "\n",
      "    accuracy                         0.8331    333333\n",
      "   macro avg     0.7734    0.7943    0.7826    333333\n",
      "weighted avg     0.8408    0.8331    0.8362    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54567\tvalidation_0-auc:0.89398\tvalidation_1-logloss:0.54571\tvalidation_1-auc:0.89332\n",
      "[50]\tvalidation_0-logloss:0.36373\tvalidation_0-auc:0.89802\tvalidation_1-logloss:0.36522\tvalidation_1-auc:0.89643\n",
      "[100]\tvalidation_0-logloss:0.33562\tvalidation_0-auc:0.90068\tvalidation_1-logloss:0.33813\tvalidation_1-auc:0.89856\n",
      "[150]\tvalidation_0-logloss:0.32679\tvalidation_0-auc:0.90307\tvalidation_1-logloss:0.33012\tvalidation_1-auc:0.90055\n",
      "[199]\tvalidation_0-logloss:0.32362\tvalidation_0-auc:0.90426\tvalidation_1-logloss:0.32768\tvalidation_1-auc:0.90133\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7832328630411484\n",
      "0.9013321077829028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9111    0.8603    0.8849    251891\n",
      "           1     0.6314    0.7403    0.6815     81442\n",
      "\n",
      "    accuracy                         0.8310    333333\n",
      "   macro avg     0.7712    0.8003    0.7832    333333\n",
      "weighted avg     0.8427    0.8310    0.8352    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3799999999999999 best_score 0.7797923789949586\n",
      "0.8969078913594952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9036    0.8692    0.8861    251891\n",
      "           1     0.6381    0.7132    0.6735     81442\n",
      "\n",
      "    accuracy                         0.8311    333333\n",
      "   macro avg     0.7708    0.7912    0.7798    333333\n",
      "weighted avg     0.8387    0.8311    0.8341    333333\n",
      "\n",
      "===========fold 2================\n",
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n",
      "os_name_macos          0\n",
      "os_name_windows        0\n",
      "age_group_15-17        0\n",
      "age_group_18-24        0\n",
      "age_group_25-34        0\n",
      "                      ..\n",
      "work_count             0\n",
      "social_count           0\n",
      "news_count             0\n",
      "entertainment_count    0\n",
      "ecommerce_count        0\n",
      "Length: 123, dtype: int64\n",
      "LOGREG--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.4099999999999998 best_score 0.7642386201223011\n",
      "0.8787499328767164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8886    0.8759    0.8822    251890\n",
      "           1     0.6326    0.6605    0.6462     81443\n",
      "\n",
      "    accuracy                         0.8233    333333\n",
      "   macro avg     0.7606    0.7682    0.7642    333333\n",
      "weighted avg     0.8261    0.8233    0.8246    333333\n",
      "\n",
      "Random Forest--------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3699999999999999 best_score 0.7642324360114396\n",
      "0.8869192866664093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8970    0.8579    0.8770    251890\n",
      "           1     0.6128    0.6953    0.6514     81443\n",
      "\n",
      "    accuracy                         0.8182    333333\n",
      "   macro avg     0.7549    0.7766    0.7642    333333\n",
      "weighted avg     0.8276    0.8182    0.8219    333333\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 162885, number of negative: 503782\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7495\n",
      "[LightGBM] [Info] Number of data points in the train set: 666667, number of used features: 123\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244327 -> initscore=-1.129099\n",
      "[LightGBM] [Info] Start training from score -1.129099\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.359187\ttraining's auc: 0.898383\tvalid_1's binary_logloss: 0.359506\tvalid_1's auc: 0.897878\n",
      "[100]\ttraining's binary_logloss: 0.33395\ttraining's auc: 0.90001\tvalid_1's binary_logloss: 0.334589\tvalid_1's auc: 0.899399\n",
      "[150]\ttraining's binary_logloss: 0.328301\ttraining's auc: 0.901158\tvalid_1's binary_logloss: 0.329327\tvalid_1's auc: 0.900365\n",
      "[200]\ttraining's binary_logloss: 0.326381\ttraining's auc: 0.90194\tvalid_1's binary_logloss: 0.327909\tvalid_1's auc: 0.900848\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.326381\ttraining's auc: 0.90194\tvalid_1's binary_logloss: 0.327909\tvalid_1's auc: 0.900848\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7823223459182826\n",
      "0.9008478137028962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9086    0.8634    0.8854    251890\n",
      "           1     0.6339    0.7315    0.6792     81443\n",
      "\n",
      "    accuracy                         0.8312    333333\n",
      "   macro avg     0.7713    0.7974    0.7823    333333\n",
      "weighted avg     0.8415    0.8312    0.8351    333333\n",
      "\n",
      "XGBoost--------------\n",
      "[0]\tvalidation_0-logloss:0.54566\tvalidation_0-auc:0.89402\tvalidation_1-logloss:0.54568\tvalidation_1-auc:0.89314\n",
      "[50]\tvalidation_0-logloss:0.36385\tvalidation_0-auc:0.89810\tvalidation_1-logloss:0.36492\tvalidation_1-auc:0.89668\n",
      "[100]\tvalidation_0-logloss:0.33570\tvalidation_0-auc:0.90071\tvalidation_1-logloss:0.33780\tvalidation_1-auc:0.89876\n",
      "[150]\tvalidation_0-logloss:0.32683\tvalidation_0-auc:0.90309\tvalidation_1-logloss:0.32997\tvalidation_1-auc:0.90058\n",
      "[199]\tvalidation_0-logloss:0.32368\tvalidation_0-auc:0.90426\tvalidation_1-logloss:0.32767\tvalidation_1-auc:0.90126\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7830879041429555\n",
      "0.901259752525466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9082    0.8654    0.8863    251890\n",
      "           1     0.6367    0.7294    0.6799     81443\n",
      "\n",
      "    accuracy                         0.8322    333333\n",
      "   macro avg     0.7724    0.7974    0.7831    333333\n",
      "weighted avg     0.8418    0.8322    0.8359    333333\n",
      "\n",
      "MLP------------------\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " best_threshold 0.3899999999999999 best_score 0.7806161107039254\n",
      "0.8976676218996644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9091    0.8599    0.8838    251890\n",
      "           1     0.6289    0.7340    0.6774     81443\n",
      "\n",
      "    accuracy                         0.8292    333333\n",
      "   macro avg     0.7690    0.7970    0.7806    333333\n",
      "weighted avg     0.8406    0.8292    0.8334    333333\n",
      "\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.4099999999999998 0.7636950549463077\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3699999999999999 0.7640324634570222\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3999999999999998 0.7824690838834609\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.782825105889072\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3899999999999999 0.7796264171999093\n",
      "LOGREG--------------\n",
      "accuracy 0.822345\n",
      "f1_score 0.763644220895972\n",
      "auc 0.8786879139166455\n",
      "sensitivity 0.6622041450353595 specificity 0.8742073420972504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8888    0.8742    0.8814    151074\n",
      "           1     0.6303    0.6622    0.6459     48926\n",
      "\n",
      "    accuracy                         0.8223    200000\n",
      "   macro avg     0.7595    0.7682    0.7636    200000\n",
      "weighted avg     0.8255    0.8223    0.8238    200000\n",
      "\n",
      "Random Forest--------------\n",
      "accuracy 0.817675\n",
      "f1_score 0.7641391113827506\n",
      "auc 0.8872835725328181\n",
      "sensitivity 0.6974819114581204 specificity 0.856600076783563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8974    0.8566    0.8765    151074\n",
      "           1     0.6117    0.6975    0.6518     48926\n",
      "\n",
      "    accuracy                         0.8177    200000\n",
      "   macro avg     0.7545    0.7770    0.7641    200000\n",
      "weighted avg     0.8275    0.8177    0.8215    200000\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 244328, number of negative: 755672\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7501\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000000, number of used features: 123\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.244328 -> initscore=-1.129096\n",
      "[LightGBM] [Info] Start training from score -1.129096\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "accuracy 0.83301\n",
      "f1_score 0.7828409576505698\n",
      "auc 0.9005739509020629\n",
      "sensitivity 0.7201896742018559 specificity 0.8695473741345301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9056    0.8695    0.8872    151074\n",
      "           1     0.6413    0.7202    0.6785     48926\n",
      "\n",
      "    accuracy                         0.8330    200000\n",
      "   macro avg     0.7735    0.7949    0.7828    200000\n",
      "weighted avg     0.8410    0.8330    0.8362    200000\n",
      "\n",
      "XGBoost--------------\n",
      "{'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 8, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 8, 'reg_lambda': 32, 'seed': 42, 'enable_categorical': True}\n",
      "accuracy 0.8323\n",
      "f1_score 0.7835152520957938\n",
      "auc 0.901102642205898\n",
      "sensitivity 0.7308792870866206 specificity 0.8651455578061082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9085    0.8651    0.8863    151074\n",
      "           1     0.6371    0.7309    0.6807     48926\n",
      "\n",
      "    accuracy                         0.8323    200000\n",
      "   macro avg     0.7728    0.7980    0.7835    200000\n",
      "weighted avg     0.8421    0.8323    0.8360    200000\n",
      "\n",
      "MLP--------------\n",
      "accuracy 0.827505\n",
      "f1_score 0.7792783081677626\n",
      "auc 0.8974009389721453\n",
      "sensitivity 0.7359481666189756 specificity 0.8571560956882058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9093    0.8572    0.8825    151074\n",
      "           1     0.6253    0.7359    0.6761     48926\n",
      "\n",
      "    accuracy                         0.8275    200000\n",
      "   macro avg     0.7673    0.7966    0.7793    200000\n",
      "weighted avg     0.8398    0.8275    0.8320    200000\n",
      "\n",
      "['log_reg', 'randomforest', 'lightgbm', 'xgboost', 'mlp']\n",
      "[0.822345, 0.817675, 0.83301, 0.8323, 0.827505]\n",
      "[0.763644220895972, 0.7641391113827506, 0.7828409576505698, 0.7835152520957938, 0.7792783081677626]\n",
      "[0.8786879139166455, 0.8872835725328181, 0.9005739509020629, 0.901102642205898, 0.8974009389721453]\n",
      "[0.8742073420972504, 0.856600076783563, 0.8695473741345301, 0.8651455578061082, 0.8571560956882058]\n",
      "[0.6622041450353595, 0.6974819114581204, 0.7201896742018559, 0.7308792870866206, 0.7359481666189756]\n"
     ]
    }
   ],
   "source": [
    "final_nothing_oofs_ = cross_validate(train)\n",
    "final_nothing_score_df_, final_nothing_models_, final_nothing_predictions_ = train_model(final_nothing_oofs_,X_train, y_train, \n",
    "                                                                                         X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>sensitivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.822345</td>\n",
       "      <td>0.763644</td>\n",
       "      <td>0.878688</td>\n",
       "      <td>0.874207</td>\n",
       "      <td>0.662204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.817675</td>\n",
       "      <td>0.764139</td>\n",
       "      <td>0.887284</td>\n",
       "      <td>0.856600</td>\n",
       "      <td>0.697482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.833010</td>\n",
       "      <td>0.782841</td>\n",
       "      <td>0.900574</td>\n",
       "      <td>0.869547</td>\n",
       "      <td>0.720190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.832300</td>\n",
       "      <td>0.783515</td>\n",
       "      <td>0.901103</td>\n",
       "      <td>0.865146</td>\n",
       "      <td>0.730879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.827505</td>\n",
       "      <td>0.779278</td>\n",
       "      <td>0.897401</td>\n",
       "      <td>0.857156</td>\n",
       "      <td>0.735948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy_score  f1_score  auc_score  specificity_score  \\\n",
       "0       log_reg        0.822345  0.763644   0.878688           0.874207   \n",
       "1  randomforest        0.817675  0.764139   0.887284           0.856600   \n",
       "2      lightgbm        0.833010  0.782841   0.900574           0.869547   \n",
       "3       xgboost        0.832300  0.783515   0.901103           0.865146   \n",
       "4           mlp        0.827505  0.779278   0.897401           0.857156   \n",
       "\n",
       "   sensitivity_score  \n",
       "0           0.662204  \n",
       "1           0.697482  \n",
       "2           0.720190  \n",
       "3           0.730879  \n",
       "4           0.735948  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_nothing_score_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [nothing_score_df] + nothing_score_dfs + [final_nothing_score_df_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n_features in enumerate([10,20,30,40,50,60,100, 'all']):\n",
    "    outputs[i]['n_features'] = str(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.concat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name            object\n",
      "accuracy_score       float64\n",
      "f1_score             float64\n",
      "auc_score            float64\n",
      "specificity_score    float64\n",
      "sensitivity_score    float64\n",
      "n_features            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(t.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.to_csv('/Users/natalie/Desktop/DS Thesis/user-churn-prediction/outputs/random_forest_feature_selection.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
