{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalie/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, roc_auc_score ,classification_report\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_f1_score(train_labels, oofs, average='macro'):\n",
    "    scores = []\n",
    "    thresholds = []\n",
    "    best_score = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "        print(f'{threshold:.02f}, ', end='')\n",
    "        preds = (oofs > threshold).astype('int')\n",
    "        m = f1_score(train_labels, preds, average=average)\n",
    "        scores.append(m)\n",
    "        thresholds.append(threshold)\n",
    "        if m > best_score:\n",
    "            best_score = m\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../checkpoints/nothing_model_2_estimators.pkl\", \"rb\") as f:\n",
    "    nothing_loadded = pickle.load(f)\n",
    "with open(f\"../checkpoints/smote_model_2_estimators.pkl\", \"rb\") as f:\n",
    "    smote_loadded = pickle.load(f)\n",
    "with open(f\"../checkpoints/class_weight_model_2_estimators.pkl\", \"rb\") as f:\n",
    "    class_weight_loadded = pickle.load(f)\n",
    "with open(f\"../checkpoints/under_sampling_model_2_estimators.pkl\", \"rb\") as f:\n",
    "    under_sampling_loadded = pickle.load(f)\n",
    "test = pd.read_parquet(\"../data/test.parquet\")\n",
    "train = pd.read_parquet(\"../data/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = nothing_loadded['model_names']\n",
    "nothing_score_df = nothing_loadded['score_df']\n",
    "nothing_oofs = nothing_loadded['oofs']\n",
    "nothing_models = nothing_loadded['models']\n",
    "nothing_predictions = nothing_loadded['predictions']\n",
    "\n",
    "smote_score_df = smote_loadded['score_df']\n",
    "smote_oofs = smote_loadded['oofs']\n",
    "smote_models = smote_loadded['models']\n",
    "smote_predictions = smote_loadded['predictions']\n",
    "\n",
    "class_weight_score_df = class_weight_loadded['score_df']\n",
    "class_weight_oofs = class_weight_loadded['oofs']\n",
    "class_weight_df_models = class_weight_loadded['models']\n",
    "class_weight_predictions = class_weight_loadded['predictions']\n",
    "\n",
    "under_sampling_score_df = under_sampling_loadded['score_df']\n",
    "under_sampling_oofs = under_sampling_loadded['oofs']\n",
    "under_sampling_models = under_sampling_loadded['models']\n",
    "under_sampling_predictions = under_sampling_loadded['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scoring(y_test,y_pred_proba, best_threshold):\n",
    "#     y_pred = [1 if y_hat >= best_threshold else 0 for y_hat in y_pred_proba]\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "#     _f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "#     auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#     specificity = tn / (tn+fp)\n",
    "#     sensitivity = tp / (tp+fn)\n",
    "#     print(\"accuracy\", acc)\n",
    "#     print(\"f1_score\", _f1_score)\n",
    "#     print(\"auc\", auc_score)\n",
    "#     print(\"sensitivity\", sensitivity, \"specificity\", specificity)\n",
    "#     print(classification_report(y_test, y_pred, digits=4))\n",
    "#     return acc, _f1_score, auc_score, specificity, sensitivity\n",
    "def scoring(y_test,y_pred_proba, best_threshold):\n",
    "    y_pred = [1 if y_hat >= best_threshold else 0 for y_hat in y_pred_proba]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    _f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    print(\"accuracy\", acc)\n",
    "    print(\"f1_score\", _f1_score)\n",
    "    print(\"auc\", auc_score)\n",
    "    print(\"sensitivity\", sensitivity, \"specificity\", specificity)\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    return acc, _f1_score, auc_score, specificity, sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "N_ESTIMATORS=200\n",
    "SEED=42\n",
    "XGBoost_Hyperparameters = {\n",
    "    'objective' : 'binary:logistic',\n",
    "     'eval_metric':['logloss', 'auc'],\n",
    "     'n_estimators':N_ESTIMATORS,\n",
    "     'learning_rate':0.03,\n",
    "     'max_depth':8,\n",
    "     'colsample_bytree':0.5,\n",
    "     'subsample':0.8,\n",
    "     'reg_alpha':8,\n",
    "     'reg_lambda':32,\n",
    "     'seed':SEED,\n",
    "     'scale_pos_weight':3,\n",
    "     'enable_categorical':True,\n",
    "     'early_stopping_rounds': 50,\n",
    "     'tree_method':'gpu_hist'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "def stacking(step_1_oofs,step_1_predictions):\n",
    "    oofs = np.zeros(step_1_oofs.shape[0])\n",
    "    for i, (train_index, valid_index) in enumerate(kfold.split(class_weight_oofs, train['churn_user'])):\n",
    "        X_train = step_1_oofs[train_index]\n",
    "        X_valid = step_1_oofs[valid_index]\n",
    "        y_train = train.iloc[train_index]['churn_user']\n",
    "        y_valid = train.iloc[valid_index]['churn_user']\n",
    "        xgb_model = XGBClassifier(**XGBoost_Hyperparameters)\n",
    "        xgb_model.fit(X_train, y_train,\n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                    verbose=50)\n",
    "        oofs[valid_index] = xgb_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, oofs[valid_index])\n",
    "        acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_valid,oofs[valid_index],best_threshold)\n",
    "    best_threshold, best_score = find_best_threshold_f1_score(train['churn_user'], oofs)\n",
    "    xgboost_hyperparameters = XGBoost_Hyperparameters.copy()\n",
    "    del xgboost_hyperparameters['early_stopping_rounds']\n",
    "    xgb_model = XGBClassifier(**xgboost_hyperparameters)\n",
    "    xgb_model.fit(step_1_oofs, train['churn_user'])\n",
    "    X_test = np.vstack(step_1_predictions).transpose()\n",
    "    y_test = test['churn_user']\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,y_pred_proba,best_threshold)\n",
    "    return acc, _f1_score, auc_score, specificity, sensitivity, y_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(stage_1_oofs, stage_1_predictions):\n",
    "    y_pred_proba = stage_1_oofs.mean(axis=1)\n",
    "    best_threshold, best_score = find_best_threshold_f1_score(train['churn_user'], y_pred_proba)\n",
    "    X_test = np.vstack(stage_1_predictions).transpose()\n",
    "    y_test = test['churn_user']\n",
    "    y_pred_proba= X_test.mean(axis=1)\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,y_pred_proba,best_threshold)\n",
    "    print(\"accuracy\", acc)\n",
    "    print(\"f1_score\", _f1_score)\n",
    "    print(\"auc\", auc_score)\n",
    "    print(\"specificity\", specificity)\n",
    "    print(\"sensitivity\", sensitivity)\n",
    "    return acc, _f1_score, auc_score, specificity, sensitivity, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>sensitivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.745775</td>\n",
       "      <td>0.685649</td>\n",
       "      <td>0.793355</td>\n",
       "      <td>0.783139</td>\n",
       "      <td>0.630401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.811820</td>\n",
       "      <td>0.761158</td>\n",
       "      <td>0.881464</td>\n",
       "      <td>0.842223</td>\n",
       "      <td>0.717941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.817375</td>\n",
       "      <td>0.774742</td>\n",
       "      <td>0.892746</td>\n",
       "      <td>0.829011</td>\n",
       "      <td>0.781445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.823165</td>\n",
       "      <td>0.775703</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.849365</td>\n",
       "      <td>0.742264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.825600</td>\n",
       "      <td>0.776368</td>\n",
       "      <td>0.895700</td>\n",
       "      <td>0.857063</td>\n",
       "      <td>0.728447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy_score  f1_score  auc_score  specificity_score  \\\n",
       "0       log_reg        0.745775  0.685649   0.793355           0.783139   \n",
       "1  randomforest        0.811820  0.761158   0.881464           0.842223   \n",
       "2      lightgbm        0.817375  0.774742   0.892746           0.829011   \n",
       "3       xgboost        0.823165  0.775703   0.894444           0.849365   \n",
       "4           mlp        0.825600  0.776368   0.895700           0.857063   \n",
       "\n",
       "   sensitivity_score  \n",
       "0           0.630401  \n",
       "1           0.717941  \n",
       "2           0.781445  \n",
       "3           0.742264  \n",
       "4           0.728447  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>sensitivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.745775</td>\n",
       "      <td>0.685649</td>\n",
       "      <td>0.793355</td>\n",
       "      <td>0.783139</td>\n",
       "      <td>0.630401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>randomforest</td>\n",
       "      <td>0.811820</td>\n",
       "      <td>0.761158</td>\n",
       "      <td>0.881464</td>\n",
       "      <td>0.842223</td>\n",
       "      <td>0.717941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.817375</td>\n",
       "      <td>0.774742</td>\n",
       "      <td>0.892746</td>\n",
       "      <td>0.829011</td>\n",
       "      <td>0.781445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.823165</td>\n",
       "      <td>0.775703</td>\n",
       "      <td>0.894444</td>\n",
       "      <td>0.849365</td>\n",
       "      <td>0.742264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0.825600</td>\n",
       "      <td>0.776368</td>\n",
       "      <td>0.895700</td>\n",
       "      <td>0.857063</td>\n",
       "      <td>0.728447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy_score  f1_score  auc_score  specificity_score  \\\n",
       "0       log_reg        0.745775  0.685649   0.793355           0.783139   \n",
       "1  randomforest        0.811820  0.761158   0.881464           0.842223   \n",
       "2      lightgbm        0.817375  0.774742   0.892746           0.829011   \n",
       "3       xgboost        0.823165  0.775703   0.894444           0.849365   \n",
       "4           mlp        0.825600  0.776368   0.895700           0.857063   \n",
       "\n",
       "   sensitivity_score  \n",
       "0           0.630401  \n",
       "1           0.717941  \n",
       "2           0.781445  \n",
       "3           0.742264  \n",
       "4           0.728447  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(stage_1_oofs, stage_1_predictions):\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "    specificity_scores = []\n",
    "    sensitivity_scores = []\n",
    "    predictions = []\n",
    "   \n",
    "\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity, y_pred_proba = blend(stage_1_oofs, stage_1_predictions)\n",
    "    print(\"accuracy\", acc)\n",
    "    print(\"f1_score\", _f1_score)\n",
    "    print(\"auc\", auc_score)\n",
    "    print(\"specificity\", specificity)\n",
    "    print(\"sensitivity\", sensitivity)\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_scores)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(y_pred_proba)\n",
    "\n",
    "\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity, y_pred_proba = stacking(stage_1_oofs, stage_1_predictions)\n",
    "    print(\"accuracy\", acc)\n",
    "    print(\"f1_score\", _f1_score)\n",
    "    print(\"auc\", auc_score)\n",
    "    print(\"specificity\", specificity)\n",
    "    print(\"sensitivity\", sensitivity)\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(y_pred_proba)\n",
    "\n",
    "    score_df = pd.DataFrame({'model_name': ['blend', 'stack'],\n",
    "                         'accuracy_score':accuracy_scores, \n",
    "                         'f1_score': f1_scores, \n",
    "                         'auc_score': auc_scores, \n",
    "                         'specificity_score': specificity_scores, \n",
    "                         'sensitivity_score': sensitivity_scores})\n",
    "    return score_df, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, accuracy 0.82144\n",
      "f1_score 0.7728461745986004\n",
      "auc 0.88954296234857\n",
      "sensitivity 0.7335976781261497 specificity 0.849888134291804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9078    0.8499    0.8779    151074\n",
      "           1     0.6128    0.7336    0.6678     48926\n",
      "\n",
      "    accuracy                         0.8214    200000\n",
      "   macro avg     0.7603    0.7917    0.7728    200000\n",
      "weighted avg     0.8357    0.8214    0.8265    200000\n",
      "\n",
      "accuracy 0.82144\n",
      "f1_score 0.7728461745986004\n",
      "auc 0.88954296234857\n",
      "specificity 0.849888134291804\n",
      "sensitivity 0.7335976781261497\n",
      "accuracy 0.82144\n",
      "f1_score 0.7728461745986004\n",
      "auc 0.88954296234857\n",
      "specificity 0.849888134291804\n",
      "sensitivity 0.7335976781261497\n",
      "[0]\tvalidation_0-logloss:0.54618\tvalidation_0-auc:0.88498\tvalidation_1-logloss:0.54599\tvalidation_1-auc:0.88391\n",
      "[50]\tvalidation_0-logloss:0.35582\tvalidation_0-auc:0.89975\tvalidation_1-logloss:0.35785\tvalidation_1-auc:0.89938\n",
      "[100]\tvalidation_0-logloss:0.33265\tvalidation_0-auc:0.90046\tvalidation_1-logloss:0.33465\tvalidation_1-auc:0.89973\n",
      "[150]\tvalidation_0-logloss:0.32871\tvalidation_0-auc:0.90091\tvalidation_1-logloss:0.33097\tvalidation_1-auc:0.89984\n",
      "[199]\tvalidation_0-logloss:0.32763\tvalidation_0-auc:0.90122\tvalidation_1-logloss:0.33026\tvalidation_1-auc:0.89988\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, accuracy 0.831484337031326\n",
      "f1_score 0.7822097995852276\n",
      "auc 0.8998830616175623\n",
      "sensitivity 0.7281779895141387 specificity 0.8648860022787634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9078    0.8649    0.8858    251891\n",
      "           1     0.6354    0.7282    0.6786     81443\n",
      "\n",
      "    accuracy                         0.8315    333334\n",
      "   macro avg     0.7716    0.7965    0.7822    333334\n",
      "weighted avg     0.8412    0.8315    0.8352    333334\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.54614\tvalidation_0-auc:0.88671\tvalidation_1-logloss:0.54676\tvalidation_1-auc:0.88456\n",
      "[50]\tvalidation_0-logloss:0.35558\tvalidation_0-auc:0.89996\tvalidation_1-logloss:0.35692\tvalidation_1-auc:0.89884\n",
      "[100]\tvalidation_0-logloss:0.33240\tvalidation_0-auc:0.90066\tvalidation_1-logloss:0.33468\tvalidation_1-auc:0.89917\n",
      "[150]\tvalidation_0-logloss:0.32842\tvalidation_0-auc:0.90107\tvalidation_1-logloss:0.33113\tvalidation_1-auc:0.89933\n",
      "[199]\tvalidation_0-logloss:0.32735\tvalidation_0-auc:0.90136\tvalidation_1-logloss:0.33038\tvalidation_1-auc:0.89943\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, accuracy 0.8328908328908329\n",
      "f1_score 0.7817566115797481\n",
      "auc 0.8994305735009203\n",
      "sensitivity 0.7138945507232141 specificity 0.871364995176485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9040    0.8714    0.8874    251891\n",
      "           1     0.6421    0.7139    0.6761     81442\n",
      "\n",
      "    accuracy                         0.8329    333333\n",
      "   macro avg     0.7731    0.7926    0.7818    333333\n",
      "weighted avg     0.8400    0.8329    0.8358    333333\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.54611\tvalidation_0-auc:0.88702\tvalidation_1-logloss:0.54621\tvalidation_1-auc:0.88439\n",
      "[50]\tvalidation_0-logloss:0.35531\tvalidation_0-auc:0.90029\tvalidation_1-logloss:0.35700\tvalidation_1-auc:0.89848\n",
      "[100]\tvalidation_0-logloss:0.33191\tvalidation_0-auc:0.90102\tvalidation_1-logloss:0.33455\tvalidation_1-auc:0.89882\n",
      "[150]\tvalidation_0-logloss:0.32783\tvalidation_0-auc:0.90145\tvalidation_1-logloss:0.33156\tvalidation_1-auc:0.89896\n",
      "[199]\tvalidation_0-logloss:0.32675\tvalidation_0-auc:0.90173\tvalidation_1-logloss:0.33131\tvalidation_1-auc:0.89901\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, accuracy 0.8318798318798318\n",
      "f1_score 0.7821900287585716\n",
      "auc 0.899007827604007\n",
      "sensitivity 0.7249364586275063 specificity 0.8664575806899837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9069    0.8665    0.8862    251890\n",
      "           1     0.6370    0.7249    0.6782     81443\n",
      "\n",
      "    accuracy                         0.8319    333333\n",
      "   macro avg     0.7720    0.7957    0.7822    333333\n",
      "weighted avg     0.8410    0.8319    0.8354    333333\n",
      "\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, accuracy 0.829935\n",
      "f1_score 0.7820980146853604\n",
      "auc 0.8999744691922769\n",
      "sensitivity 0.7386461186281322 specificity 0.8594993182149145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9104    0.8595    0.8842    151074\n",
      "           1     0.6300    0.7386    0.6800     48926\n",
      "\n",
      "    accuracy                         0.8299    200000\n",
      "   macro avg     0.7702    0.7991    0.7821    200000\n",
      "weighted avg     0.8418    0.8299    0.8342    200000\n",
      "\n",
      "accuracy 0.829935\n",
      "f1_score 0.7820980146853604\n",
      "auc 0.8999744691922769\n",
      "specificity 0.8594993182149145\n",
      "sensitivity 0.7386461186281322\n"
     ]
    }
   ],
   "source": [
    "nothing_ensemble_df, nothing_ensemble_predictions = ensemble(nothing_oofs, nothing_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>specificity_score</th>\n",
       "      <th>sensitivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blend</td>\n",
       "      <td>0.821440</td>\n",
       "      <td>0.772846</td>\n",
       "      <td>[[[[[...], [...]], [[...], [...]]], [[[...], [...</td>\n",
       "      <td>0.849888</td>\n",
       "      <td>0.733598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stack</td>\n",
       "      <td>0.829935</td>\n",
       "      <td>0.782098</td>\n",
       "      <td>[[[[[...], [...]], [[...], [...]]], [[[...], [...</td>\n",
       "      <td>0.859499</td>\n",
       "      <td>0.738646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  accuracy_score  f1_score  \\\n",
       "0      blend        0.821440  0.772846   \n",
       "1      stack        0.829935  0.782098   \n",
       "\n",
       "                                           auc_score  specificity_score  \\\n",
       "0  [[[[[...], [...]], [[...], [...]]], [[[...], [...           0.849888   \n",
       "1  [[[[[...], [...]], [[...], [...]]], [[[...], [...           0.859499   \n",
       "\n",
       "   sensitivity_score  \n",
       "0           0.733598  \n",
       "1           0.738646  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_ensemble_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
