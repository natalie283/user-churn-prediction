{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalie/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, accuracy_score,confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "   \n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# calculate class weights based on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet('/Users/natalie/Desktop/DS Thesis/Code/data/test.parquet')\n",
    "train = pd.read_parquet('/Users/natalie/Desktop/DS Thesis/Code/data/train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET ='churn_user'\n",
    "CATEGORICAL_FEATURES  = ['os_name', 'age_group','gender', 'country', 'region', 'province_type',\n",
    "                         'province']\n",
    "DATETIME_FEATURES  = ['first_date', 'lastest_active_day']\n",
    "SEARCH_CC_FEATURES = [ 'clicks', 'search_volume', 'dating_search', 'videoclip_search', 'technical_search', 'housekeeping_family_search', 'marketing_search', 'other_search']\n",
    "SEARCH_GG_FEATURES = [ 'serp_click', 'search_volume_gg', 'search_clicks_gg', 'other_search_gg','housekeeping_family_search_gg','videoclip_search_gg', 'dating_search_gg', 'marketing_search_gg', 'technical_search_gg']\n",
    "ACTIVE_FEATURES = ['active_day', 'life_time',  'not_active_day', 'total_active_time']\n",
    "ADS_FEATURES =  ['ads_impression', 'ads_click', 'ads_revenue']\n",
    "OTHERS_FEATURES =[ 'newtab_count', 'download_count', 'pip_count', 'sidebar_count', 'incognito_count', 'signin_count', 'youtube_count',\n",
    "                    'work_count', 'social_count', 'news_count', 'entertainment_count', 'ecommerce_count']\n",
    "NUMERICAL_FEATURES = SEARCH_CC_FEATURES + SEARCH_GG_FEATURES + ACTIVE_FEATURES + ADS_FEATURES + OTHERS_FEATURES\n",
    "MODEL_NAMES = ['log_reg', 'randomforest','lightgbm', 'xgboost', 'mlp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_f1_score(train_labels, oofs, average='macro'):\n",
    "    scores = []\n",
    "    thresholds = []\n",
    "    best_score = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "        print(f'{threshold:.02f}, ', end='')\n",
    "        preds = (oofs > threshold).astype('int')\n",
    "        m = f1_score(train_labels, preds, average=average)\n",
    "        scores.append(m)\n",
    "        thresholds.append(threshold)\n",
    "        if m > best_score:\n",
    "            best_score = m\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_feature_engineer(df):\n",
    "    temp = pd.DataFrame()\n",
    "    temp['OTHERS_FEATURES_SUM'] = df[OTHERS_FEATURES].sum(axis=1)\n",
    "    temp['OTHERS_FEATURES_MIN'] = df[OTHERS_FEATURES].min(axis=1)\n",
    "    temp['OTHERS_FEATURES_MAX'] = df[OTHERS_FEATURES].max(axis=1)\n",
    "    temp['OTHERS_FEATURES_MEAN'] = df[OTHERS_FEATURES].mean(axis=1)\n",
    "    temp['ADS_CTR'] = df['ads_click'] / df['ads_impression']\n",
    "    temp['SEARCH_CC_FEATURES_SUM'] = df[SEARCH_CC_FEATURES[1:]].sum(axis=1)\n",
    "    temp['SEARCH_CC_FEATURES_MIN'] = df[SEARCH_CC_FEATURES[1:]].min(axis=1)\n",
    "    temp['SEARCH_CC_FEATURES_MAX'] = df[SEARCH_CC_FEATURES[1:]].max(axis=1)\n",
    "    temp['SEARCH_CC_FEATURES_MEAN'] = df[SEARCH_CC_FEATURES[1:]].mean(axis=1)\n",
    "    temp['SEARCH_GG_FEATURES_SUM'] = df[SEARCH_GG_FEATURES[1:]].sum(axis=1)\n",
    "    temp['SEARCH_GG_FEATURES_MIN'] = df[SEARCH_GG_FEATURES[1:]].min(axis=1)\n",
    "    temp['SEARCH_GG_FEATURES_MAX'] = df[SEARCH_GG_FEATURES[1:]].max(axis=1)\n",
    "    temp['SEARCH_GG_FEATURES_MEAN'] = df[SEARCH_GG_FEATURES[1:]].mean(axis=1)\n",
    "    temp['not_active_day_per_active_day'] = df['not_active_day'] / df['active_day']\n",
    "    temp['life_time_per_active_day'] = df['life_time'] / df['active_day']\n",
    "    return temp, list(temp.columns)\n",
    "\n",
    "def fillna(df):\n",
    "    df['total_active_time'] = df['total_active_time'].fillna(0)\n",
    "    df['ads_impression'] = df['ads_impression'].fillna(0)\n",
    "    df['ads_click'] = df['ads_click'].fillna(0)\n",
    "    df['ads_revenue'] = df['ads_revenue'].fillna(0)\n",
    "    df['clicks'] = df['clicks'].fillna(0)\n",
    "    for c in OTHERS_FEATURES:\n",
    "        df[c] = df[c].fillna(0)\n",
    "    return df\n",
    "\n",
    "def process_data(df,oh_encoder=None, robust_scaler=None,agg_features=None):\n",
    "    if not oh_encoder:\n",
    "        print(\"fit train OneHotEncoder\")\n",
    "        oh_encoder = OneHotEncoder()\n",
    "        oh_encoder.fit(df[CATEGORICAL_FEATURES])\n",
    "    else:\n",
    "        print(\"loadd onehot encoder\")\n",
    "    if not robust_scaler:\n",
    "        print(\"fit train RobustScaler\")\n",
    "        robust_scaler = RobustScaler()\n",
    "        robust_scaler.fit(df[NUMERICAL_FEATURES])\n",
    "    else:\n",
    "        print(\"loadd robust scaler\")\n",
    "    df_cat = pd.DataFrame(oh_encoder.transform(df[CATEGORICAL_FEATURES]).toarray())\n",
    "    new_cat_cols = oh_encoder.get_feature_names_out(CATEGORICAL_FEATURES)\n",
    "    df_cat.columns = new_cat_cols\n",
    "    df_num = pd.DataFrame(robust_scaler.transform(df[NUMERICAL_FEATURES]))\n",
    "    df_num.columns = NUMERICAL_FEATURES\n",
    "    new_df = pd.concat([df_cat.reset_index(drop=True), df_num.reset_index(drop=True)], axis=1)\n",
    "    new_df = fillna(new_df)\n",
    "    return new_df, oh_encoder, robust_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESTIMATORS = 200\n",
    "SEED=42\n",
    "LGBM_Hyperparameters =  {\n",
    "    \"n_estimators\": N_ESTIMATORS,\n",
    "    'learning_rate':0.03,\n",
    "     'max_depth':8,\n",
    "     'colsample_bytree':0.8,\n",
    "     'subsample':0.8,\n",
    "     # 'reg_alpha':8,\n",
    "     # 'reg_lambda':32,\n",
    "\n",
    "    \"random_state\":SEED,\n",
    "    'device':'gpu',\n",
    "#     \"class_weight\": \"balanced\"\n",
    "}\n",
    "\n",
    "XGBoost_Hyperparameters = {\n",
    "    'objective' : 'binary:logistic',\n",
    "     'eval_metric':['logloss', 'auc'],\n",
    "     'n_estimators':N_ESTIMATORS,\n",
    "     'learning_rate':0.03,\n",
    "     'max_depth':8,\n",
    "     'colsample_bytree':0.5,\n",
    "     'subsample':0.8,\n",
    "     'reg_alpha':8,\n",
    "     'reg_lambda':32,\n",
    "     'seed':SEED,\n",
    "     # 'scale_pos_weight':3,\n",
    "     'enable_categorical':True,\n",
    "     'early_stopping_rounds': 50,\n",
    "     'tree_method':'gpu_hist'}\n",
    "RF_Hyperparameters = {\n",
    "    'n_estimators': N_ESTIMATORS,\n",
    "    'max_depth':8,\n",
    "    'random_state':SEED,\n",
    "    'max_features': 'sqrt', \n",
    "    'n_jobs': -1\n",
    "}\n",
    "Logreg_Hyperparameters = {'max_iter':N_ESTIMATORS,'random_state':SEED} \n",
    "MLP_Hyperparametesr = {'hidden_layer_sizes':(3,125), 'random_state':SEED, 'max_iter':min(N_ESTIMATORS,100)}\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "def cross_validate(train, USE_SMOTE=False, USE_CLASS_WEIGHT=False, USE_UNDER_SAMPLING=False):\n",
    "    oofs = np.zeros((train.shape[0], len(MODEL_NAMES)))\n",
    "    for i, (train_index, valid_index) in enumerate(kfold.split(train, train[TARGET])):\n",
    "        print(f\"===========fold {i}================\")\n",
    "        X_train, oh_encoder, robust_scaler = process_data(train.iloc[train_index])\n",
    "        X_valid, _, _  = process_data(train.iloc[valid_index], oh_encoder,robust_scaler)\n",
    "        print(X_train.isnull().sum())\n",
    "        y_train = train.iloc[train_index][TARGET].values\n",
    "        y_valid = train.iloc[valid_index][TARGET].values\n",
    "        logreg_hyperparameters = Logreg_Hyperparameters.copy()\n",
    "        lgb_hyperparameters = LGBM_Hyperparameters.copy()\n",
    "        xgboost_hyperparameters = XGBoost_Hyperparameters.copy()\n",
    "        rf_hyperparameters = RF_Hyperparameters.copy()\n",
    "        mlp_hyperparameters = MLP_Hyperparametesr.copy()\n",
    "        if USE_SMOTE:\n",
    "            print(\"SMOTEEEE\")\n",
    "            sm = SMOTE(random_state=42)\n",
    "            X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        elif USE_CLASS_WEIGHT:\n",
    "            print(\"CLASS_WEIGHTTTT\")\n",
    "           \n",
    "            class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train)\n",
    "            class_weights =  {0: class_weights[0], 1: class_weights[1]}\n",
    "            lgb_hyperparameters['class_weight'] = class_weights\n",
    "            logreg_hyperparameters['class_weight'] = class_weights\n",
    "            xgboost_hyperparameters['scale_pos_weight'] = class_weights[1] /  class_weights[0]\n",
    "            rf_hyperparameters['class_weight'] = class_weights\n",
    "        elif USE_UNDER_SAMPLING:\n",
    "            print(\"UNDER SAMPLING\")\n",
    "            rus = RandomUnderSampler(random_state=42)\n",
    "            X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "        print(\"LOGREG--------------\")\n",
    "        logreg_model = LogisticRegression(**logreg_hyperparameters)\n",
    "        logreg_model.fit(X_train, y_train)\n",
    "        logreg_y_pred_proba = logreg_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, logreg_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in logreg_y_pred_proba]\n",
    "\n",
    "        print(roc_auc_score(y_valid, logreg_y_pred_proba))\n",
    "\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index,0] = logreg_y_pred_proba\n",
    "\n",
    "        print(\"Random Forest--------------\")\n",
    "        rf_model = RandomForestClassifier(**rf_hyperparameters)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        rf_y_pred_proba = rf_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, rf_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in rf_y_pred_proba]\n",
    "\n",
    "        print(roc_auc_score(y_valid, rf_y_pred_proba))\n",
    "\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index,1] = rf_y_pred_proba\n",
    "    #     models.append(model)\n",
    "        print(\"LGBModel--------------\")\n",
    "        lgb_model = LGBMClassifier(**lgb_hyperparameters)\n",
    "        callbacks = [lgb.early_stopping(200, verbose=50), lgb.log_evaluation(period=50)]\n",
    "        lgb_model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                  eval_metric=[\"logloss\", \"auc\"],\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "        lgb_y_pred_proba = lgb_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, lgb_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in lgb_y_pred_proba]\n",
    "        print(roc_auc_score(y_valid, lgb_y_pred_proba))\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index,2] = lgb_y_pred_proba\n",
    "    #     models.append(model)\n",
    "        # display(pd.DataFrame({'score': lgb_model.feature_importances_, 'feature': lgb_model.feature_name_}).sort_values('score',ascending=False))\n",
    "\n",
    "        print(\"XGBoost--------------\")\n",
    "        xgb_model = XGBClassifier(**xgboost_hyperparameters)\n",
    "        xgb_model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                  verbose=50)\n",
    "        xgb_y_pred_proba = xgb_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, xgb_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in xgb_y_pred_proba]\n",
    "        print(roc_auc_score(y_valid, xgb_y_pred_proba))\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index, 3] = xgb_y_pred_proba\n",
    "        \n",
    "        print(\"MLP------------------\")\n",
    "        mlp_model = MLPClassifier(**mlp_hyperparameters)\n",
    "        mlp_model.fit(X_train, y_train)\n",
    "        mlp_y_pred_proba = mlp_model.predict_proba(X_valid)[:,1]\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(y_valid, mlp_y_pred_proba)\n",
    "        print(f\"\\n best_threshold {best_threshold} best_score {best_score}\")\n",
    "        y_pred = [1 if y_hat >=best_threshold else 0 for y_hat in mlp_y_pred_proba]\n",
    "        print(roc_auc_score(y_valid, mlp_y_pred_proba))\n",
    "        print(classification_report(y_valid, y_pred, digits=4))\n",
    "        oofs[valid_index, 4] = mlp_y_pred_proba\n",
    "    return oofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "specificity_scores = []\n",
    "sensitivity_scores = []\n",
    "def scoring(y_test,y_pred_proba, best_threshold):\n",
    "    y_pred = [1 if y_hat >= best_threshold else 0 for y_hat in y_pred_proba]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    _f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    print(\"accuracy\", acc)\n",
    "    print(\"f1_score\", _f1_score)\n",
    "    print(\"auc\", auc_score)\n",
    "    print(\"sensitivity\", sensitivity, \"specificity\", specificity)\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    return acc, _f1_score, auc_score, specificity, sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(oofs,X_train, y_train, X_test, y_test, USE_SMOTE=False,USE_CLASS_WEIGHT=False, USE_UNDER_SAMPLING=False):\n",
    "    models = []\n",
    "    predictions = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "    specificity_scores = []\n",
    "    sensitivity_scores = []\n",
    "    best_thresholds = []\n",
    "    for i in range(len(MODEL_NAMES)):\n",
    "        best_threshold, best_score = find_best_threshold_f1_score(train[TARGET].values, oofs[:,i])\n",
    "        best_thresholds.append(best_threshold)\n",
    "        print('\\n',best_threshold, best_score)\n",
    "    logreg_hyperparameters = Logreg_Hyperparameters.copy()\n",
    "    lgb_hyperparameters = LGBM_Hyperparameters.copy()\n",
    "    xgboost_hyperparameters = XGBoost_Hyperparameters.copy()\n",
    "    del xgboost_hyperparameters['early_stopping_rounds']\n",
    "    rf_hyperparameters = RF_Hyperparameters.copy()\n",
    "    mlp_hyperparameters = MLP_Hyperparametesr.copy()\n",
    "    if USE_SMOTE:\n",
    "        print(\"SMOTEEEE\")\n",
    "        sm = SMOTE(random_state=42)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    elif USE_CLASS_WEIGHT:\n",
    "        print(\"CLASS_WEIGHTTTT\")\n",
    "        class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train)\n",
    "        class_weights =  {0: class_weights[0], 1: class_weights[1]}\n",
    "        lgb_hyperparameters['class_weight'] = class_weights\n",
    "        logreg_hyperparameters['class_weight'] = class_weights\n",
    "        xgboost_hyperparameters['scale_pos_weight'] = class_weights[1]/ class_weights[0]\n",
    "        rf_hyperparameters['class_weight'] = class_weights\n",
    "    elif USE_UNDER_SAMPLING:\n",
    "        print(\"UNDER SAMPLING\")\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "    print(\"LOGREG--------------\")\n",
    "    logreg_model = LogisticRegression(**logreg_hyperparameters)\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    logreg_y_pred_proba = logreg_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,logreg_y_pred_proba,best_thresholds[0])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(logreg_y_pred_proba)\n",
    "    models.append(logreg_model)\n",
    "\n",
    "    print(\"Random Forest--------------\")\n",
    "    rf_model = RandomForestClassifier(**rf_hyperparameters)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_y_pred_proba = rf_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,rf_y_pred_proba,best_thresholds[1])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(rf_y_pred_proba)\n",
    "    models.append(rf_model)\n",
    "\n",
    "    print(\"LGBModel--------------\")\n",
    "    lgb_model = LGBMClassifier(**lgb_hyperparameters)\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "    lgb_y_pred_proba = lgb_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,lgb_y_pred_proba,best_thresholds[2])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(lgb_y_pred_proba)\n",
    "    models.append(lgb_model)\n",
    "\n",
    "    print(\"XGBoost--------------\")\n",
    "    print(xgboost_hyperparameters)\n",
    "    xgb_model = XGBClassifier(**xgboost_hyperparameters)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    xgb_y_pred_proba = xgb_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,xgb_y_pred_proba,best_thresholds[3])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(xgb_y_pred_proba)\n",
    "    models.append(xgb_model)\n",
    "    \n",
    "    print(\"MLP--------------\")\n",
    "    mlp_model = MLPClassifier(**mlp_hyperparameters)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "    mlp_y_pred_proba = mlp_model.predict_proba(X_test)[:,1]\n",
    "    acc, _f1_score, auc_score, specificity, sensitivity = scoring(y_test,mlp_y_pred_proba,best_thresholds[4])\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(_f1_score)\n",
    "    auc_scores.append(auc_score)\n",
    "    specificity_scores.append(specificity)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    predictions.append(mlp_y_pred_proba)\n",
    "    models.append(mlp_model)\n",
    "\n",
    "    print(MODEL_NAMES)\n",
    "    print(accuracy_scores)\n",
    "    print(f1_scores)\n",
    "    print(auc_scores)\n",
    "    print(specificity_scores)\n",
    "    print(sensitivity_scores)\n",
    "    score_df = pd.DataFrame({'model_name': MODEL_NAMES,\n",
    "                         'accuracy_score':accuracy_scores, \n",
    "                         'f1_score': f1_scores, \n",
    "                         'auc_score': auc_scores, \n",
    "                         'specificity_score': specificity_scores, \n",
    "                         'sensitivity_score': sensitivity_scores})\n",
    "    return score_df,models, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit train OneHotEncoder\n",
      "fit train RobustScaler\n",
      "loadd onehot encoder\n",
      "loadd robust scaler\n"
     ]
    }
   ],
   "source": [
    "X_train,oh_encoder,robust_scaler = process_data(train)\n",
    "X_test, _,_ = process_data(test,oh_encoder,robust_scaler)\n",
    "y_train = train[TARGET].values\n",
    "y_test = test[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Class weight\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.6899999999999997 0.7681388619721978\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.6399999999999997 0.7663670402386513\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.6699999999999997 0.7872708855369563\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.6699999999999997 0.7876108586907486\n",
      "0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.70, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, \n",
      " 0.3999999999999998 0.78365673035903\n",
      "CLASS_WEIGHTTTT\n",
      "LOGREG--------------\n",
      "accuracy 0.82606\n",
      "f1_score 0.7683607998023443\n",
      "auc 0.8821362047102325\n",
      "sensitivity 0.6682949760863345 specificity 0.8771529184373221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8909    0.8772    0.8840    151074\n",
      "           1     0.6379    0.6683    0.6528     48926\n",
      "\n",
      "    accuracy                         0.8261    200000\n",
      "   macro avg     0.7644    0.7727    0.7684    200000\n",
      "weighted avg     0.8290    0.8261    0.8274    200000\n",
      "\n",
      "Random Forest--------------\n",
      "accuracy 0.820115\n",
      "f1_score 0.7659855679918712\n",
      "auc 0.8893254684527838\n",
      "sensitivity 0.6932305931406614 specificity 0.8612070905648888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8966    0.8612    0.8785    151074\n",
      "           1     0.6180    0.6932    0.6534     48926\n",
      "\n",
      "    accuracy                         0.8201    200000\n",
      "   macro avg     0.7573    0.7772    0.7660    200000\n",
      "weighted avg     0.8284    0.8201    0.8235    200000\n",
      "\n",
      "LGBModel--------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 244328, number of negative: 755672\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 7203\n",
      "[LightGBM] [Info] Number of data points in the train set: 1000000, number of used features: 123\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 21 dense feature groups (22.89 MB) transferred to GPU in 0.018727 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "accuracy 0.835305\n",
      "f1_score 0.7867959016949747\n",
      "auc 0.9048454503842664\n",
      "sensitivity 0.7323508972734334 specificity 0.8686471530508227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9093    0.8686    0.8885    151074\n",
      "           1     0.6436    0.7324    0.6851     48926\n",
      "\n",
      "    accuracy                         0.8353    200000\n",
      "   macro avg     0.7764    0.8005    0.7868    200000\n",
      "weighted avg     0.8443    0.8353    0.8387    200000\n",
      "\n",
      "XGBoost--------------\n",
      "{'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'n_estimators': 200, 'learning_rate': 0.03, 'max_depth': 8, 'colsample_bytree': 0.5, 'subsample': 0.8, 'reg_alpha': 8, 'reg_lambda': 32, 'seed': 42, 'enable_categorical': True, 'tree_method': 'gpu_hist', 'scale_pos_weight': 3.092858780000655}\n",
      "accuracy 0.83632\n",
      "f1_score 0.7873366553205718\n",
      "auc 0.9052439012139433\n",
      "sensitivity 0.7284266034419327 specificity 0.8712617657571786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9083    0.8713    0.8894    151074\n",
      "           1     0.6469    0.7284    0.6853     48926\n",
      "\n",
      "    accuracy                         0.8363    200000\n",
      "   macro avg     0.7776    0.7998    0.7873    200000\n",
      "weighted avg     0.8444    0.8363    0.8395    200000\n",
      "\n",
      "MLP--------------\n",
      "accuracy 0.83191\n",
      "f1_score 0.7829186448184171\n",
      "auc 0.9009633141330158\n",
      "sensitivity 0.7293667988390631 specificity 0.865119080715411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9080    0.8651    0.8860    151074\n",
      "           1     0.6365    0.7294    0.6798     48926\n",
      "\n",
      "    accuracy                         0.8319    200000\n",
      "   macro avg     0.7723    0.7972    0.7829    200000\n",
      "weighted avg     0.8416    0.8319    0.8356    200000\n",
      "\n",
      "['log_reg', 'randomforest', 'lightgbm', 'xgboost', 'mlp']\n",
      "[0.82606, 0.820115, 0.835305, 0.83632, 0.83191]\n",
      "[0.7683607998023443, 0.7659855679918712, 0.7867959016949747, 0.7873366553205718, 0.7829186448184171]\n",
      "[0.8821362047102325, 0.8893254684527838, 0.9048454503842664, 0.9052439012139433, 0.9009633141330158]\n",
      "[0.8771529184373221, 0.8612070905648888, 0.8686471530508227, 0.8712617657571786, 0.865119080715411]\n",
      "[0.6682949760863345, 0.6932305931406614, 0.7323508972734334, 0.7284266034419327, 0.7293667988390631]\n"
     ]
    }
   ],
   "source": [
    "# print(\"Not handle Balanced\")\n",
    "# nothing_oofs = cross_validate(train)\n",
    "# nothing_score_df, nothing_models, nothing_predictions = train_model(nothing_oofs,X_train, y_train, X_test, y_test)\n",
    "\n",
    "# print(\"Use SMOTE\")\n",
    "# smote_oofs = cross_validate(train, USE_SMOTE=True)\n",
    "# smote_score_df, smote_models, smote_predictions = train_model(smote_oofs,X_train, y_train, X_test, y_test, USE_SMOTE=True)\n",
    "\n",
    "print(\"Use Class weight\")\n",
    "# class_weight_oofs = cross_validate(train, USE_CLASS_WEIGHT=True)\n",
    "class_weight_score_df, class_weight_models, class_weight_predictions = train_model(class_weight_oofs,X_train, y_train, X_test, y_test, USE_CLASS_WEIGHT=True)\n",
    "\n",
    "# print(\"Use Under sampling\")\n",
    "# under_sampling_oofs = cross_validate(train, USE_UNDER_SAMPLING=True)\n",
    "# under_sampling_score_df, under_sampling_models, under_sampling_predictions = train_model(under_sampling_oofs,X_train, y_train, X_test, y_test, USE_UNDER_SAMPLING=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"../checkpoints/nothing_model_{N_ESTIMATORS}_estimators.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\n",
    "#         \"score_df\": nothing_score_df,\n",
    "#         \"oofs\": nothing_oofs,\n",
    "#         \"models\": nothing_models,\n",
    "#         \"model_names\": MODEL_NAMES,\n",
    "#         \"predictions\":nothing_predictions},f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# with open(f\"../checkpoints/smote_model_{N_ESTIMATORS}_estimators.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\n",
    "#             \"score_df\":smote_score_df,\n",
    "#             \"oofs\": smote_oofs,\n",
    "#             \"models\": smote_models,\n",
    "#             \"model_names\": MODEL_NAMES,\n",
    "#             \"predictions\":smote_predictions},f,protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "\n",
    "with open(f\"../checkpoints/class_weight_model_{N_ESTIMATORS}_estimators.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "            \"score_df\":class_weight_score_df,\n",
    "            \"oofs\": class_weight_oofs,\n",
    "            \"models\": class_weight_models,\n",
    "            \"model_names\": MODEL_NAMES,\n",
    "            \"predictions\":class_weight_predictions},f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# with open(f\"../checkpoints/under_sampling_model_{N_ESTIMATORS}_estimators.pkl\", \"wb\") as f:\n",
    "#     pickle.dump({\n",
    "#             \"score_df\":under_sampling_score_df,\n",
    "#             \"oofs\": under_sampling_oofs,\n",
    "#             \"models\": under_sampling_models,\n",
    "#             \"model_names\": MODEL_NAMES,\n",
    "#             \"predictions\":under_sampling_predictions},f,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
